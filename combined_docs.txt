This page is for formatting only

Custom resources allow you to integrate any AWS service into an Amplify backend. You are responsible for ensuring that your custom resources are secure, adhere to best practices, and work with the resources that Amplify creates for your app.

With Amplify Gen 2, you can add custom AWS resources to an Amplify app using the AWS Cloud Development Kit (AWS CDK), which is installed by default as part of the create-amplify workflow. The AWS CDK is an open source software development framework that defines your cloud application resources using familiar programming languages, such as TypeScript.

The AWS CDK can be used within an Amplify app to add custom resources and configurations beyond what Amplify supports out of the box. For example, a developer could use CDK to hook up a Redis cache, implement custom security rules, deploy containers on AWS Fargate, or use any other AWS service.

The infrastructure defined through the AWS CDK code is deployed along with the Amplify app backend. This provides the simplicity of Amplify combined with the flexibility of CDK for situations where you need more customization.

AWS CDK apps are composed of building blocks known as constructs, which are composed together to form stacks and apps. You can learn more in the Concepts section of the AWS Cloud Development Kit (AWS CDK) v2 Developer Guide.

With the Amplify code-first DX, you can add existing or custom CDK constructs to the backend of your Amplify app.

To add an existing CDK construct, you can use the many existing constructs that come with the AWS CDK. For example, to add an Amazon Simple Queue Service (Amazon SQS) queue and an Amazon Simple Notification Service (Amazon SNS) topic to your backend, you can add the following code to your amplify/backend.ts file.

```typescript
import * as sns from 'aws-cdk-lib/aws-sns';
import * as sqs from 'aws-cdk-lib/aws-sqs';
import { defineBackend } from '@aws-amplify/backend';

const backend = defineBackend({
  // your existing backend configuration
});

const customResourceStack = backend.createStack('MyCustomResources');

new sqs.Queue(customResourceStack, 'CustomQueue');
new sns.Topic(customResourceStack, 'CustomTopic');
```

Note the use of backend.createStack(). This method instructs the backend to create a new CloudFormation Stack for your custom resources to live in. You can create multiple custom stacks and you can place multiple resources in any given stack.

You can also define a custom CDK construct to encapsulate common patterns into reusable components. A common use case is creating a custom notification construct that combines a Lambda function with Amazon SNS and Amazon Simple Email Service (Amazon SES).

Here's an example of a custom CDK construct that implements a decoupled notification system using Amazon SNS and Lambda.

```typescript
import * as lambda from 'aws-cdk-lib/aws-lambda-nodejs';
import * as sns from 'aws-cdk-lib/aws-sns';
import * as subscriptions from 'aws-cdk-lib/aws-sns-subscriptions';
import { Construct } from 'constructs';

export type Message = {
  subject: string;
  body: string;
  recipient: string;
};

type CustomNotificationsProps = {
  /**
   * The source email address to use for sending emails
   */
  sourceAddress: string;
};

export class CustomNotifications extends Construct {
  public readonly topic: sns.Topic;
  constructor(scope: Construct, id: string, props: CustomNotificationsProps) {
    super(scope, id);

    const { sourceAddress } = props;

    // Create SNS topic
    this.topic = new sns.Topic(this, 'NotificationTopic');

    // Create Lambda to publish messages to SNS topic
    const publisher = new lambda.NodejsFunction(this, 'Publisher', {
      entry: 'publisher.ts',
      environment: {
        SNS_TOPIC_ARN: this.topic.topicArn
      },
      runtime: lambda.Runtime.NODEJS_18_X
    });

    // Create Lambda to process messages from SNS topic
    const emailer = new lambda.NodejsFunction(this, 'Emailer', {
      entry: 'emailer.ts',
      environment: {
        SOURCE_ADDRESS: sourceAddress
      },
      runtime: lambda.Runtime.NODEJS_18_X
    });

    // Subscribe emailer Lambda to SNS topic
    this.topic.addSubscription(new subscriptions.LambdaSubscription(emailer));

    // Allow publisher to publish to SNS topic
    this.topic.grantPublish(publisher);
  }
}
```

The Lambda function code for the publisher is:

```typescript
import { PublishCommand, SNSClient } from '@aws-sdk/client-sns';
import type { Handler } from 'aws-lambda';
import type { Message } from './resource';

const client = new SNSClient({ region: process.env.AWS_REGION });

// define the handler that will publish messages to the SNS Topic
export const handler: Handler<Message, void> = async (event) => {
  const { subject, body, recipient } = event;
  const command = new PublishCommand({
    TopicArn: process.env.SNS_TOPIC_ARN,
    Message: JSON.stringify({
      subject,
      body,
      recipient
    })
  });
  try {
    const response = await client.send(command);
    console.log('published', response);
  } catch (error) {
    console.log('failed to publish message', error);
    throw new Error('Failed to publish message', { cause: error });
  }
};
```

The Lambda function code for the emailer is:

```typescript
import { SESClient, SendEmailCommand } from '@aws-sdk/client-ses';
import type { SNSHandler } from 'aws-lambda';
import type { Message } from './resource';

const sesClient = new SESClient({ region: process.env.AWS_REGION });

// define the handler to process messages from the SNS topic and send via SES
export const handler: SNSHandler = async (event) => {
  for (const record of event.Records) {
    const message: Message = JSON.parse(record.Sns.Message);

    // send the message via email
    await sendEmail(message);
  }
};

const sendEmail = async (message: Message) => {
  const { recipient, subject, body } = message;

  const command = new SendEmailCommand({
    Source: process.env.SOURCE_ADDRESS,
    Destination: {
      ToAddresses: [recipient]
    },
    Message: {
      Body: {
        Text: { Data: body }
      },
      Subject: { Data: subject }
    }
  });

  try {
    const result = await sesClient.send(command);
    console.log(`Email sent to ${recipient}: ${result.MessageId}`);
  } catch (error) {
    console.error(`Error sending email to ${recipient}: ${error}`);
    throw new Error(`Failed to send email to ${recipient}`, { cause: error });
  }
};
```

The CustomNotifications CDK construct can then be added to the Amplify backend one or more times, with different properties for each instance.

```typescript
import { defineBackend } from '@aws-amplify/backend';
import { CustomNotifications } from './custom/CustomNotifications/resource';

const backend = defineBackend({
  // your existing backend configuration
});

const customNotifications = new CustomNotifications(
  backend.createStack('CustomNotifications'),
  'CustomNotifications',
  { sourceAddress: 'sender@example.com' }
);

backend.addOutput({
  custom: {
    topicArn: customNotifications.topic.topicArn,
    topicName: customNotifications.topic.topicName,
  },
});
```

You can also use community-driven resources such as the Construct Hub, which is a catalog of reusable infrastructure components, and the example projects using the AWS CDK repository, which contains a number of examples of reusable CDK constructs.

Deleting an Amplify sandbox with a resource enabled with deletion protection will cause the deploy process to fail, and the resource will need to be manually deleted on the AWS console.

You can configure Amplify generated resources to enable deletion protection and backups on supported resources using the AWS Cloud Development Kit (CDK). For example, you can use CDK to enable point-in-time recovery for DynamoDB tables or use AWS Backup for advanced backup options.

You can modify resource configurations using underlying CDK construct properties, which allows you to customize backend resources beyond what is offered via the define functions.

To enable deletion protection on an Auth resource, such as a Cognito user pool resource created by Amplify Auth, you can set the deletionProtection property to "ACTIVE". 

To enable deletion protection on a Data resource, such as all DynamoDB tables created by a GraphQL API, you can set the deletionProtectionEnabled property to true for each table.

You can also enable point-in-time recovery for DynamoDB tables by setting the pointInTimeRecoveryEnabled property to true. This will retain backups for 35 days by default.

If you need backups that extend the default 35 days point-in-time recovery, you can use the AWS Backup service to centralize and automate backups for DynamoDB tables. You can configure a backup plan to run daily at midnight, for example.

To retain resources on stack deletion, you can use the applyRemovalPolicy property on the resource to add a retention policy. However, note that `amplify sandbox delete` ignores any resource removal policy and always deletes all resources.

Here is an example of how you can enable deletion protection and backups in a React application using Amplify:
```javascript
// amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';

const backend = defineBackend({
  auth,
  data
});

// Enable deletion protection on Auth resource
const { cfnUserPool } = backend.auth.resources.cfnResources
cfnUserPool.deletionProtection = "ACTIVE";

// Enable deletion protection on Data resource
const { amplifyDynamoDbTables } = backend.data.resources.cfnResources;
for (const table of Object.values(amplifyDynamoDbTables)) {
  table.deletionProtectionEnabled = true;
}

// Enable point-in-time recovery for DynamoDB tables
for (const table of Object.values(amplifyDynamoDbTables)) {
  table.pointInTimeRecoveryEnabled = true;
}

// Enable backups for DynamoDB tables
import {
  BackupPlan,
  BackupPlanRule,
  BackupResource,
  BackupVault,
} from "aws-cdk-lib/aws-backup";
import { Schedule } from "aws-cdk-lib/aws-events";
import { Duration } from "aws-cdk-lib/core";

const backupStack = backend.createStack("backup-stack");
const myTables = Object.values(backend.data.resources.tables);

const vault = new BackupVault(backupStack, "BackupVault", {
  backupVaultName: "backup-vault",
});

const plan = new BackupPlan(backupStack, "BackupPlan", {
  backupPlanName: "backup-plan",
  backupVault: vault,
});

plan.addRule(
  new BackupPlanRule({
    deleteAfter: Duration.days(60),
    ruleName: "backup-plan-rule",
    scheduleExpression: Schedule.cron({
      minute: "0",
      hour: "0",
      day: "*",
      month: "*",
      year: "*",
    }),
  })
);

plan.addSelection("BackupPlanSelection", {
  resources: myTables.map((table) => BackupResource.fromDynamoDbTable(table)),
  allowRestores: true,
});

// Retain resources on stack deletion
backend.storage.resources.bucket.applyRemovalPolicy(RemovalPolicy.RETAIN);
backend.auth.resources.userPool.applyRemovalPolicy(RemovalPolicy.RETAIN);
backend.data.resources.cfnResources.amplifyDynamoDbTables["Todo"].applyRemovalPolicy(RemovalPolicy.RETAIN);
```

To interact with bots in your React application using AWS Amplify, you can send messages to the chatbot backend using the send command. This method returns a promise that includes the chatbot response. 

To send a message, provide a bot name and user input. For example, if a user wants to reserve a hotel for tonight, you can send this input to the chatbot and log the response. 

Here is an example of how to send a message to a bot in React:
```javascript
const userInput = "I want to reserve a hotel for tonight";
const response = await Interactions.send({
  botName: "TheBotName",
  message: userInput
});
console.log(response.message);
```

You can also display an end of chat message by registering a function to catch errors or chatbot confirmations when the session successfully ends. This can be done using the onComplete method. 

Here is an example of how to display an end of chat message in React:
```javascript
Interactions.onComplete({
  botName: "TheBotName",
  callback: (error, completion) => {
    if (error) {
      alert('bot conversation failed');
    } else if (completion) {
      console.debug('done: ' + JSON.stringify(completion, null, 2));
      alert('Trip booked. Thank you! What would you like to do next?');
    }
  }
});
```

AWS Amplify Interactions enables AI-powered chatbots in your web or mobile apps. You can use Interactions to configure your backend chatbot provider and to integrate a chatbot UI into your app with just a single line of code.

Interactions with AWS Amplify supports Amazon Lex as the default chatbots service. Amazon Lex supports creating conversational bots with the same deep learning technologies that power Amazon Alexa.

To set up an Amazon Lex V2 bot, you can create it in the Amazon Lex console by following the steps shown in the Amazon Lex V2 Developer Guide.

After creating your bot, you need to update your IAM policy to use the interactions APIs. The policy should include the following:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["lex:RecognizeText", "lex:RecognizeUtterance"],
      "Resource": "arn:aws:lex:<your-app-region>:<your-account-id>:bot-alias/<your-bot-id>/<your-bot-alias-id>"
    }
  ]
}
```

To configure your frontend, you need to add the aws-amplify and interactions package to your project:
```bash
npm add --save @aws-amplify/interactions aws-amplify
```

For React Native, you need to install additional dependencies:
```bash
npm add aws-amplify \
  @aws-amplify/react-native \
  @aws-amplify/interactions \
  @react-native-community/netinfo \
  @react-native-async-storage/async-storage \
  react-native-get-random-values
```

Make sure that the `@aws-amplify/interactions` package has the same version number as the `aws-amplify` package in your `package.json` file.

To configure Amplify, import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example, **App.js** (Expo) or **index.js** (React Native CLI).
```javascript
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
Amplify.configure({
  ...Amplify.getConfig(),
  Interactions: {
    LexV2: {
      '<your-bot-name>': {
        aliasId: '<your-bot-alias-id>',
        botId: '<your-bot-id>',
        localeId: '<your-bot-locale-id>',
        region: '<your-bot-region>'
      }
    }
  }
});
```

For React Native, you need to add the `crypto.getRandomValues` polyfills to your application's entry point file:
```javascript
import 'react-native-get-random-values';
```

Make sure you call `Amplify.configure` as early as possible in your application’s life-cycle. A missing configuration or `NoCredentials` error is thrown if `Amplify.configure` has not been called before other Amplify JavaScript APIs. 

Note: For React Native, you may encounter an error when starting the bundler. This is a known issue and can be resolved by following the steps outlined in the linked issue.

When using AWS Amplify, you can override resources to customize the backend configuration. However, be aware that using overrides can create a backend that Amplify libraries or client config may not be able to interpret properly. Always test changes in a staging environment.

To override resources, you can access underlying AWS Cloud Development Kit (CDK) construct properties in the `amplify/backend.ts` file after the `defineBackend` call has been made. The `backend` object exposes a `resources` property with objects for each component passed into the `defineBackend` function. Each resource object exposes underlying L1 and L2 AWS CDK constructs that you can modify.

For example, to access the Cognito user pool created by `defineAuth` and set a custom removal policy on the resource, you can use the following code:
```typescript
const userPool = backend.auth.resources.userPool;
userPool.applyRemovalPolicy(RemovalPolicy.RETAIN_ON_UPDATE_OR_DELETE);
```
Most L1 and L2 AWS CDK constructs used by the `define*` functions are accessible in this way.

You can also grant access permissions between resources. For instance, to grant a function created by `defineFunction` access to call the Cognito user pool created by `defineAuth`, you can use the following code:
```typescript
const userPool = backend.auth.resources.userPool;
const lambdaFunction = backend.authAuditorFunction.resources.lambda;
userPool.grant(lambdaFunction, 'cognito:AdminListUserAuthEvents');
backend.authAuditorFunction.addEnvironment('USER_POOL_ID', userPool.userPoolId);
```
Additionally, you can modify L1 CDK constructs by using `addPropertyOverride` on an AWS CDK construct. To edit the password policies of the Cognito user pool in `defineAuth`, you can use the following code:
```typescript
const { cfnUserPool } = backend.auth.resources.cfnResources;
cfnUserPool.policies = {
  passwordPolicy: {
    minimumLength: 10,
    requireLowercase: true,
    requireNumbers: true,
    requireSymbols: true,
    requireUppercase: true,
    temporaryPasswordValidityDays: 20,
  },
};
```
Note that `auth.resources.cfnResources` exposes L1 CDK constructs that map one-to-one with the underlying CloudFormation properties, whereas `auth.resources.userPool` is an L2 CDK construct that provides a convenient interface around several related L1 constructs.

For further customization, you can refer to the documentation on custom resources.

Tags are a key-value pair that are applied to AWS resources to hold metadata. Tags are often used to decorate resources with metadata that helps categorize resources for billing or viewing purposes. Learn more about tags by visiting the AWS documentation for best practices for tagging resources.

Amplify applies the following tags by default:

* For sandbox deployments, tags include `created-by` with the value `amplify` and `amplify:deployment-type` with the value `sandbox`.
* For branch deployments, tags include `created-by` with the value `amplify`, `amplify:deployment-type` with the value `branch`, `amplify:app-id` with the value of your Amplify app ID, and `amplify:branch-name` with the value of your Git branch name.

To apply custom tags in your Amplify backend, you can use the AWS Cloud Development Kit (CDK) to add tags at the root level, which then cascades to child resources. Here's an example of how to do this in a React project:

```javascript
import { Tags } from 'aws-cdk-lib';
import { defineBackend } from '@aws-amplify/backend';

const backend = defineBackend({
  // add your resources here, such as auth and data
});

const tags = Tags.of(backend.stack);
// add a new tag
tags.add('my-key', 'my-value');
// remove tags
tags.remove('my-key');
```

The Amplify AI Kit is built around the concept of routes, which are similar to API endpoints for interacting with backend AI functionality. These routes are configured in the Amplify backend, where you can define authorization rules, route type, AI model, and other settings. There are two types of AI routes: 

Conversation routes are asynchronous and multi-turn, meaning they involve multiple interactions between the user and the AI. These conversations are automatically stored in a database. Examples of conversation routes include chat-based AI experiences or conversational user interfaces.

Generation routes, on the other hand, are single, synchronous requests that generate structured data based on the route definition. These routes are often used for tasks such as generating structured data from unstructured input or summarization.

When you create an AI route with the Amplify AI Kit, it uses several cloud infrastructure services, including:

AWS AppSync, a serverless API layer that authorizes and routes requests from the browser to AWS services.
Amazon DynamoDB, a serverless database that stores conversation history.
AWS Lambda, a serverless execution environment for conversations.
Amazon Bedrock, a serverless foundation model. 

In a React application, you might interact with these AI routes using the Amplify AI Kit, which provides a simple and intuitive way to integrate AI functionality into your app. For example, you might use the `Amplify` library to send a request to a conversation route, like this:
```
import Amplify from 'aws-amplify';

// Send a message to a conversation route
Amplify.AI.converse(message, (response) => {
  // Handle the response
});
```
Or, you might use the `Amplify` library to send a request to a generation route, like this:
```
import Amplify from 'aws-amplify';

// Send a request to a generation route
Amplify.AI.generate(input, (response) => {
  // Handle the response
});
```

Inference configuration refers to the parameters that can be adjusted to change how a Large Language Model (LLM) behaves. These models predict text based on the input they receive, and this prediction is probabilistic. By tweaking the inference configuration, you can influence the model to produce more creative or deterministic outputs. The optimal configuration will depend on your specific use case.

Inference refers to the process of using a trained model to generate or predict output based on input data. This is a crucial step in using generative AI models.

In Amplify, you can set inference configuration as optional parameters for all generative AI routes. If you don't provide any configuration options, the model will use its default settings. To set the inference configuration, you can pass an options object with the desired parameters. For example, in a React application, you might use the following code:
```
const inferenceConfiguration = {
  temperature: 0.2,
  topP: 0.2,
  maxTokens: 1000,
}
```
Then, you can pass this configuration to the generative AI route:
```
a.generation({
  aiModel: a.ai.model("Claude 3.5 Haiku"),
  systemPrompt: `You are a helpful assistant`,
  inferenceConfiguration: inferenceConfiguration
})
```
There are several parameters that can be adjusted in the inference configuration:

* Temperature: This affects the shape of the probability distribution for the predicted output and influences the likelihood of the model selecting lower-probability outputs. A lower value will result in more deterministic responses, while a higher value will allow for more creative outputs.
* Top P: This refers to the percentage of token candidates the model can choose from for the next token in the response. A lower value will decrease the size of the pool and limit the options to more likely outputs, while a higher value will increase the size of the pool and allow for lower-probability tokens.
* Max Tokens: This parameter is used to limit the maximum response a model can give.

Each model has its own default inference configuration settings. These settings can be found in the Bedrock documentation for each model. For example:

* AI21 Labs Jamba: temperature = 1.0, top P = 0.5, max tokens = 4096
* Meta Llama: temperature = 0.5, top P = 0.9, max tokens = 512
* Amazon Titan: temperature = 0.7, top P = 0.9, max tokens = 512
* Anthropic Claude: temperature = 1, top P = 0.999, max tokens = 512
* Cohere Command R: temperature = 0.3, top P = 0.75, max tokens = 512
* Mistral Large: temperature = 0.7, top P = 1, max tokens = 8192

Note that some models, such as AI21 Labs Jamba, use a different temperature range (0-2.0) than the standard range (0-1).

A foundation model is a large, general-purpose machine learning model that has been pre-trained on a vast amount of data. These models are trained in an unsupervised or self-supervised manner, meaning they learn patterns and representations from the unlabeled training data without being given specific instructions or labels.

Foundation models are useful because they are general-purpose and you don't need to train the models yourself, but are powerful enough to take on a range of applications. They are inherently stateless, taking input in the form of text or images and generating text or images, and are also inherently non-deterministic, meaning providing the same input can generate different output.

To use foundation models on Bedrock, you need to request access to the models in the AWS console. Be sure to check the region you are building your Amplify app in, as not all models are available in all regions.

Each foundation model in Amazon Bedrock has its own pricing and throughput limits for on-demand use. On-demand use is serverless, and you only pay for what you use. The cost for using foundation models is calculated by token usage, where a token refers to chunks of data that were sent as input and how much data was generated.

The Amplify AI Kit uses Bedrock's Converse API to leverage a unified API across models. The supported models for Amplify AI kit include AI21 Labs, Amazon, Anthropic, Cohere, Meta, and Mistral AI. Each model has its own strengths and weaknesses, and you should try different models for different use-cases to find the right fit.

When choosing a model, consider the context window, latency, cost, and use-case fit. The context window refers to the amount of information you can send to the model, and is defined by the number of tokens it can receive. Smaller models tend to have a lower latency than larger models, but can also sometimes be less powerful.

To use different models in your Amplify AI backend, update the aiModel attribute in your schema using the a.ai.model() function. This function gives you access to friendly names for the Bedrock models, and can be used to define different models for different functionality in your application.

For example, to use the Claude 3.5 Haiku model, you can define your schema like this:
```javascript
const schema = a.schema({
  summarizer: a.generation({
    aiModel: a.ai.model("Claude 3.5 Haiku")
  })
})
```
Alternatively, you can use the model ID, which can be found in the Bedrock console or documentation:
```javascript
const schema = a.schema({
  summarizer: a.generation({
    aiModel: {
      resourcePath: 'meta.llama3-1-405b-instruct-v1:0'
    }
  })
})
```

LLM prompting is the process of giving a language model specific input to generate a desired output. The input, or "prompt," can be a sentence, paragraph, or sequence of instructions that guides the model to produce content that aligns with the user's intent. The way the prompt is structured and worded can significantly influence the model's response.

To get the best results from an LLM, you need to understand its strengths and limitations and experiment with different prompt formats, styles, and techniques. This can include using specific keywords, providing context, breaking down tasks into steps, and incorporating formatting elements like bullet points or code blocks.

The Amplify AI kit uses the Converse API, which has a structured input and output rather than just text in and text out. The prompt structure consists of three parts: system prompt, messages, and tool configuration. The system prompt provides high-level instructions to the LLM, messages are the conversation history, and tool configuration is information about the tools the model can invoke.

To customize the system prompt in the Amplify AI kit, you need to provide a system prompt for all AI routes. This will be used in all requests to the LLM. For example, you can define a system prompt like this:
```javascript
const reviewSummarizer = a.generation({
  aiModel: a.ai.model("Claude 3.5 Haiku"),
  systemPrompt: `
  You are a helpful assistant that summarizes reviews
  for an ecommerce site. 
  `
})
```
Here are some tips for effective prompting: be as detailed as possible, give the LLM a role and scope, say what it should and shouldn't do, use multiple routes, and don't put everything into the system prompt. Additionally, prompting strategies differ based on the model, so it's essential to read up on the model itself and what works well with it.

For more information on prompting, you can refer to the following resources: What is a prompt, What is prompt engineering, Design a prompt, and the Anthropic prompt library.

When a large language model generates a lot of text, typically over 100 words, it can take some time to produce the entire response. Instead of waiting for the complete response, the generated text can be sent back in chunks as it is created. 

Model providers like Amazon Bedrock usually have an HTTP streaming API that sends responses back in pieces. 

The Amplify AI kit handles streaming differently than other frameworks, it doesn't use HTTP streaming from the server to the client. Instead, it uses a WebSocket connection to AWS AppSync to send updates to the browser.

Here's how it works: the Amplify AI kit provisions a Lambda function that calls Bedrock with a streaming API request. The Lambda function receives chunks from the HTTP streaming response and sends updates to AppSync. The client then subscribes to these updates.

If you're using the `useAIConversation` React hook, you don't need to worry about the details, as it takes care of everything and provides conversation messages as React state that updates as chunks are received. 

For example, you can use the hook in your React component like this:
```javascript
function Conversation() {
  const { messages } = useAIConversation();
  return (
    <div>
      {messages.map((message, index) => (
        <p key={index}>{message}</p>
      ))}
    </div>
  );
}
```

Large language models are stateless text generators that have no knowledge of the real world and cannot access data on their own. For instance, if you asked a large language model "what is the weather in San Jose?" it would not be able to tell you because it does not know what the weather is today. Tools, also known as function calling, are functions or APIs that large language models can invoke to get information about the world. This allows the large language model to answer questions with information not included in their training data, such as the weather, application-specific data, and even user-specific data.

When a large language model is prompted with tools, it can choose to respond by saying that it wants to call a tool to get some data or take an action on the user's behalf. The data returned by the tool is then added to the conversation history, allowing the large language model to see what data was returned.

Here is an example of how this works:
1. A user asks "what is the weather in San Jose?"
2. The large language model is called with this message and is told it has access to a tool called `getWeather` that takes an input like `{ city: string }`.
3. The large language model responds with a message saying it wants to call the `getWeather` tool with the input `{ city: 'San Jose' }`.
4. The `getWeather` function is called with the input `{ city: 'San Jose' }` and the results are appended to the conversation history.
5. The large language model is called again with the updated conversation history and responds with a message like "In San Jose, it is 72 degrees and sunny".

It's worth noting that the large language model itself is not actually executing any function or code. Instead, it responds with a special message saying that it wants to call a specific tool with certain input. The tool then needs to be called and the results returned to the large language model in a message history. 

In a React application, you might implement a tool like `getWeather` as a function that makes an API call to retrieve the current weather for a given city. For example:
```javascript
function getWeather(city) {
  // Make an API call to retrieve the current weather for the given city
  // Return the weather data
}
```
The large language model would then be called with a message like "what is the weather in San Jose?" and would respond with a message saying it wants to call the `getWeather` tool with the input `{ city: 'San Jose' }`. The `getWeather` function would then be called with this input and the results would be appended to the conversation history. The large language model would then be called again with the updated conversation history and would respond with a message like "In San Jose, it is 72 degrees and sunny".

The AIConversation component is a customizable chat interface built for the Amplify AI kit. It is highly customizable to fit into any application and works with the useAIConversation hook, which manages the state and lifecycle of the component. The component requires some props, including messages, an array of the messages in the conversation, and handleSendMessage, a handler that is called when a user message is sent.

To get started, you need to follow the getting started guide for the Amplify AI kit to set up your Amplify AI backend. Conversations require a logged-in user, so it is recommended to use the Authenticator component to easily add authentication flows to your app.

Here is an example of how to use the AIConversation component:
```tsx
import { Amplify } from 'aws-amplify';
import { generateClient } from "aws-amplify/api";
import { Authenticator } from "@aws-amplify/ui-react";
import { AIConversation, createAIHooks } from '@aws-amplify/ui-react-ai';
import '@aws-amplify/ui-react/styles.css';
import outputs from "../amplify_outputs.json";
import { Schema } from "../amplify/data/resource";

Amplify.configure(outputs);

const client = generateClient<Schema>({ authMode: "userPool" });
const { useAIConversation } = createAIHooks(client);

export default function App() {
  const [
    {
      data: { messages },
      isLoading,
    },
    handleSendMessage,
  ] = useAIConversation('chat');
  // 'chat' is based on the key for the conversation route in your schema.

  return (
    <Authenticator>
      <AIConversation
        messages={messages}
        isLoading={isLoading}
        handleSendMessage={handleSendMessage}
      />
    </Authenticator>
  );
}
```

The AIConversation component also supports markdown rendering, image rendering, and customizing the timestamp display. You can customize the usernames and avatars used in the component by using the avatars prop.

Response components are a way to define custom UI components that the LLM can respond with in the conversation. You can define a response component by giving it a name, description, and defining the props the LLM should know.

Here is an example of how to define a response component:
```tsx
<AIConversation
  responseComponents={{
    WeatherCard: {
      description: 'Used to display the weather of a given city to the user',
      component: ({ city }) => {
        return <Card>{city}</Card>;
      },
      props: {
        city: {
          type: 'string',
          required: true,
        },
      },
    },
  }}
/>
```

You can also add a fallback component if no component is found based on the name by using the FallbackResponseComponent prop.
```tsx
<AIConversation
  FallbackResponseComponent={(props) => (
    <Card variation="outlined">{JSON.stringify(props, null, 2)}</Card>
  )}
/>
```

In this guide, you will learn how to create, update, and delete conversations, as well as send messages and subscribe to assistant responses in your React application using AWS Amplify Gen 2.

Conversations and their associated messages are persisted in Amazon DynamoDB. This means the previous messages for a conversation are automatically included in the history sent to the LLM. Access to conversations and messages are scoped to individual users through the owner-based authorization strategy.

There are two main types within the conversation flow, Conversation and Message. 
A Conversation is an instance of a chat session between an application user and an LLM. It contains data and methods for interacting with the conversation. 
A conversation has a one-to-many relationship with its messages.

The Conversation type has the following properties and methods:
- id: a unique identifier for the conversation
- name: the name of the conversation
- metadata: metadata associated with the conversation
- createdAt: the date and time when the conversation was created
- updatedAt: the date and time when the last user message was sent
- sendMessage(): sends a message to the AI assistant
- listMessages(): lists all messages for the conversation
- onStreamEvent(): subscribes to assistant responses

A Message is a single chat message between an application user and an LLM. Each message has a role property that indicates whether the message is from the user or the assistant. 
The Message type has the following properties:
- id: a unique identifier for the message
- conversationId: the ID of the conversation this message belongs to
- associatedUserMessageId: for assistant messages, the ID of the user message that triggered the response
- content: the content of the message
- role: whether the message is from the user or assistant
- createdAt: the date and time when the message was created

To interact with conversations, follow these steps:
1. Create a new conversation with the create method or get an existing one with the get method.
2. Subscribe to assistant responses for a conversation with the onStreamEvent method.
3. Send messages to the conversation with the sendMessage method.

Here is an example of how to create a conversation, subscribe to assistant responses, and send a message:
```javascript
const client = // initialize your client

// Create a conversation
const { data: chat, errors } = await client.conversations.chat.create();

// Subscribe to assistant responses
const subscription = chat.onStreamEvent({
  next: (event) => {
    console.log(event);
  },
  error: (error) => {
    console.error(error);
  },
});

// Send a message to the conversation
const { data: message, errors } = await chat.sendMessage('Hello, world!');
```

Conversations can be managed by creating, getting, listing, updating, and deleting them. 
- Create a conversation by calling the create method on your conversation route.
- Get an existing conversation by calling the get method on your conversation route with the conversation's id.
- List conversations by calling the list method on your conversation route.
- Update a conversation by calling the update method on your conversation route.
- Delete a conversation by calling the delete method on your conversation route.

Once you have a conversation instance, you can interact with it by calling methods on the instance. 
- Send a message to the AI assistant by calling the sendMessage method.
- Subscribe to assistant responses by calling the onStreamEvent method.
- List messages for a conversation by calling the listMessages method.

The sendMessage method can be customized by passing additional arguments. 
- You can pass a content object with a content property to send different types of content to the AI assistant.
- You can pass an aiContext object to attach arbitrary data to the message.
- You can pass a toolConfiguration object to pass a client tool configuration to the AI assistant with a user message.

Assistant responses are streamed back to the client as they are generated. 
- Subscribe to assistant responses by calling the onStreamEvent method on your conversation instance.
- The onStreamEvent method takes two callback functions as arguments: next and error.
- The next callback is invoked with each assistant response.
- The error callback is invoked if there's an error while processing messages.

The next callback is invoked with a ConversationStreamEvent object. 
- There are several types of ConversationStreamEvent objects, including ConversationStreamTextEvent, ConversationStreamDoneAtIndexEvent, ConversationStreamTurnDoneEvent, and ConversationStreamToolUseEvent.
- Each type of ConversationStreamEvent object has its own set of properties.

You can list messages for a conversation by calling the listMessages method on your conversation instance. 
- Retrieved messages are paginated, so you can use the nextToken value to paginate through messages.
- You can optionally specify a limit to limit the number of messages returned.

To provide high-quality answers to users' questions, large language models (LLMs) need the right information. This information can be contextual, based on the user or the state of the application. You can send client-side context to the LLM with any user message, which can be any unstructured or structured data that might be useful.

In React, you can pass this context using the `aiContext` property when sending a message to the LLM. For example, you can pass a simple object with a username:
```tsx
conversation.sendMessage({
  content: [{ text: "hello" }],
  aiContext: {
    username: "danny"
  }
})
```

In a React application, you can use the `useAIConversation` hook to send messages to the LLM. You can pass the `aiContext` property when calling the `sendMessage` function:
```tsx
function handleSendMessage(message) {
  sendMessage({
    ...message,
    aiContext: {
      currentTime: new Date().toLocaleTimeString()
    }
  })
}
```

Alternatively, you can pass a function to the `aiContext` property that returns the context data. This function will be run immediately before the request is sent, ensuring that the LLM receives the most up-to-date information:
```tsx
<AIConversation
  messages={messages}
  isLoading={isLoading}
  handleSendMessage={sendMessage}
  aiContext={() => {
    return {
      currentTime: new Date().toLocaleTimeString(),
    };
  }}
/>
```

You can use React context or other state management systems to update the data passed to `aiContext`. For example, you can create a context to share state across components:
```tsx
const DataContext = React.createContext<{
  data: any;
  setData: (value: React.SetStateAction<any>) => void;
}>({ data: {}, setData: () => {} });
```

Then, you can create a component that updates the shared state:
```tsx
function Counter() {
  const { data, setData } = React.useContext(DataContext);
  const count = data.count ?? 0;
  return (
    <Button onClick={() => setData({ ...data, count: count + 1 })}>
      {count}
    </Button>
  );
}
```

Finally, you can reference the shared data in the `aiContext` property:
```tsx
function Chat() {
  const { data } = React.useContext(DataContext);
  const [
    {
      data: { messages },
      isLoading,
    },
    sendMessage,
  ] = useAIConversation('pirateChat');

  return (
    <AIConversation
      messages={messages}
      isLoading={isLoading}
      handleSendMessage={sendMessage}
      aiContext={() => {
        return {
          ...data,
          currentTime: new Date().toLocaleTimeString(),
        };
      }}
    />
  );
}
```

The Amplify AI kit automatically and securely stores conversation history per user so you can easily resume past conversations. 

If you are looking for a quick way to get started with conversation history, an example project has a similar interface to ChatGPT or Claude where users see past conversations in a sidebar they can manage. 

When you define a conversation route in your Amplify data schema, the Amplify AI kit turns that into two data models: Conversation and Message. The Conversation model functions mostly the same way as other data models defined in your schema. You can list and filter them and you can get a specific conversation by ID. Then once you have a conversation instance you can load the messages in it if there are any, send messages to it, and subscribe to the stream events being sent back.

To list all the conversations a user has you can use the list method. It works the same way as any other Amplify data model would. You can optionally pass a limit or nextToken. 
```javascript
const { data: conversations } = await client.conversations.chat.list()
```
The updatedAt field gets updated when new messages are sent, so you can use that to see which conversation had the most recent message. Conversations retrieved via list are sorted in descending order by updatedAt.

For pagination, the result of list contains a nextToken property. This can be used to retrieve subsequent pages of conversations.
```javascript
const { data: conversations, nextToken } = await client.conversations.chat.list();

// retrieve next page
if (nextToken) { 
  const { data: nextPageConversations } = await client.conversations.chat.list({ 
    nextToken 
  });
}
```
Conversations also have name and metadata fields you can use to more easily find and resume past conversations. Name is a string and metadata is a JSON object so you can store any extra information you need.

You can resume a conversation by calling the get method with a conversation ID. Both create and get return the conversation instance. 

To list all conversations a user has, make sure the user has been authenticated with Amplify Auth, then
```javascript
const conversationList = await client.conversations.conversation.list();

// Retrieve a specific conversation
const { data: conversation } = await client.conversations.chat.get({ id: conversationList[0].id });

// list the existing messages in the conversation
const { data: messages } = await conversation.listMessages();

// You can now send a message to the conversation
conversation.sendMessage({
  content: [
    {text: "hello"}
  ]
})
```
For a react component, you can use the useAIConversation hook to get the conversation data and handle sending messages
```javascript
export function Chat({ id }) {
  const [
    data: { messages },
    handleSendMessage,
  ] = useAIConversation('chat', { id })
}
```

The conversation feature in AWS Amplify simplifies the creation of AI-powered conversation interfaces in your application. It automatically sets up the necessary components, including an AppSync API and Lambda functions, to handle streaming multi-turn interactions with Amazon Bedrock foundation models.

The key components of this feature are:
1. AppSync API - this is the gateway to the conversation feature, allowing you to create new conversation instances, send messages, and subscribe to real-time updates for assistant responses.
2. Lambda Function - this acts as a bridge between AppSync and Amazon Bedrock, retrieving conversation history, invoking Bedrock's converse endpoint, and handling tool use responses.
3. DynamoDB - this stores conversation and message data, with conversations scoped to a specific application user.

The authentication flow for this feature involves the following steps:
1. The user's OIDC access token is passed from the client to AppSync.
2. AppSync forwards this token to the Lambda function.
3. The Lambda function uses the token to authenticate requests back to AppSync.

This feature can be used in various scenarios, with safeguards in place to mitigate risks, including:
- Redacting OIDC access tokens from logs.
- Limiting the Lambda function's ability to access other resources through IAM policies.

The data flow for this feature is as follows:
1. The user sends a message via the AppSync mutation.
2. AppSync triggers the Lambda function.
3. The Lambda function processes the message and invokes Bedrock's converse endpoint.
4. If the response is a tool use, the Lambda function invokes the applicable AppSync query.
5. The Lambda function sends the assistant response back to AppSync.
6. AppSync sends the response to subscribed clients.

This design allows for real-time, scalable conversations while ensuring that the Lambda function's data access matches that of the application user. 

Here is an example of how you might use this feature in a React application:
```javascript
import { API } from '@aws-amplify/api';

// Create a new conversation instance
const conversationInstance = await API.graphql({
  query: 'createConversation',
  variables: {
    input: {
      // Conversation input data
    }
  }
});

// Send a message to the conversation instance
const message = await API.graphql({
  query: 'sendMessage',
  variables: {
    input: {
      conversationId: conversationInstance.id,
      message: 'Hello, world!'
    }
  }
});

// Subscribe to real-time updates for assistant responses
API.graphql({
  query: 'subscribeToConversation',
  variables: {
    conversationId: conversationInstance.id
  }
}).subscribe({
  next: (response) => {
    // Handle assistant response
  }
});
```

Amazon Bedrock knowledge bases are a great way to implement Retrieval Augmented Generation, or RAG for short. RAG is a common pattern in building generative AI applications that involves storing a lot of content, like documentation, in a vector database. 

When setting up an Amazon Bedrock knowledge base, be aware that the default setup uses OpenSearch Serverless, which can incur costs even if you're not using it. If you're just testing this out, make sure to turn off the OpenSearch Serverless instance when you're done to avoid getting a large AWS bill.

To integrate a Bedrock knowledge base with your conversation route in a React application, first create an Amazon Bedrock knowledge base in the AWS console, CLI, or with CDK. 

Then, create a custom query and tool to interact with the knowledge base. This can be done by defining a schema for the knowledge base and creating a query that allows you to search the knowledge base. 

```javascript
const schema = {
  knowledgeBase: {
    query: (input) => {
      // handler to interact with the knowledge base
    },
    returns: (result) => {
      // return the result of the query
    },
    authorization: (allow) => {
      // authorization rules for the query
    },
  },
  chat: {
    aiModel: "Claude 3.5 Haiku",
    systemPrompt: `You are a helpful assistant.`,
    tools: [
      {
        name: 'searchDocumentation',
        description: 'Performs a similarity search over the documentation for ...',
        query: (input) => {
          // reference to the knowledgeBase query
        },
      },
    ]
  }
}
```

Next, write an AWS AppSync resolver to connect the query to the knowledge base. You'll need to know the ID of the knowledge base you want to use. 

```javascript
export function request(ctx) {
  const { input } = ctx.args;
  return {
    resourcePath: "/knowledgebases/[KNOWLEDGE_BASE_ID]/retrieve",
    method: "POST",
    params: {
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        retrievalQuery: {
          text: input,
        },
      }),
    },
  };
}

export function response(ctx) {
  return JSON.stringify(ctx.result.body);
}
```

Finally, define the data source for the knowledge base query and give it permission to call the knowledge base. This can be done in the Amplify backend file. 

```javascript
const KnowledgeBaseDataSource = {
  // configuration for the knowledge base data source
};

KnowledgeBaseDataSource.grantPrincipal.addToPrincipalPolicy(
  {
    resources: [
      `arn:aws:bedrock:[region]:[account ID]:knowledge-base/[knowledge base ID]`
    ],
    actions: ["bedrock:Retrieve"],
  },
);
```

Response components are custom UI components that can be defined to allow an AI assistant to respond with more than just text. These components enable the creation of rich conversational interfaces. 

The AIConversation component takes response components and turns them into tool configurations to send to the LLM. When a user sends a message to the backend, the backend Lambda merges the tools coming from the client and any schema tools. The LLM sees that it can invoke a UI component tool with certain input/props. If the LLM chooses to use a response component tool, a message gets sent to the client with the response component name and props. The AIConversation component will then try to render the provided React component with the props the LLM sends.

It's essential to know that the LLM is not writing raw code that gets sent to the browser and evaluated.

A response component has a description, a React component to render, and props in JSONSchema format. For example, you can define a WeatherCard response component that displays the weather to the user. 

To pass context back to the assistant, you can send aiContext with the message. aiContext is any information about the current state of the client application that might be useful for the AI assistant to know to help it respond better. You can use the aiContext to let the AI assistant know what was rendered in the response component so it can have more context to respond with.

To share state across components, you can create a context using React.createContext. For instance, you can create a DataContext to share state across components and use it to set the data context when the WeatherCard component is rendered. 

In some cases, there may be times when there is a message in the conversation history that has a response component you no longer have. To handle these situations, you can use the FallbackResponseComponent prop. This prop allows you to define a fallback component to render when a response component is not found. 

For example, you can define a fallback component that displays the props of the missing response component. 

To use response components, you need to define them in the responseComponents prop of the AIConversation component. You can define multiple response components and use them to create a rich conversational interface. 

You can also use the aiContext prop to pass context back to the assistant and use the FallbackResponseComponent prop to handle situations where a response component is not found. 

Here is an example of how to use response components:
```typescript
<AIConversation
  responseComponents={{
    WeatherCard: {
      description: "Used to display the weather to the user",
      component: ({ city }) => {
        return (
          <div>{city}</div>
        )
      },
      props: {
        city: {
          type: "string",
          required: true,
          description: "The name of the city to display the weather for",
        },
      },
    },
  }}
/>
```
And here is an example of how to use the aiContext prop:
```typescript
<AIConversation
  aiContext={() => {
    return {
      // data to pass to the assistant
    };
  }}
/>
```
And here is an example of how to use the FallbackResponseComponent prop:
```typescript
<AIConversation
  FallBackResponseComponent={(props) => {
    return <>{JSON.stringify(props)}</>
  }}
/>
```

Tools allow LLMs to query information to respond with current and relevant information. They are invoked only if the LLM requests to use one based on the user's message and the tool's description.

There are a few different ways to define LLM tools in the Amplify AI kit: 
1. Model tools 
2. Query tools 
3. Lambda tools

The easiest way to define tools for your conversation route is with `a.ai.dataTool()` for data models and custom queries in your data schema. When you define a tool for a conversation route, Amplify takes care of the heavy lifting, describing the tools to the LLM, invoking the tool with the right parameters, and maintaining the caller identity and authorization.

Model tools give the LLM access to your data models by referencing them in an `a.ai.dataTool()` with a reference to a model in your data schema. This requires that the model uses at least one of the following authorization strategies: 
- Per user data access, using `owner()`, `ownerDefinedIn()`, or `ownersDefinedIn()`
- Any signed-in user data access, using `authenticated()`
- Per user group data access, using `group()`, `groupsDefinedIn()`, `groups()`, or `groupsDefinedIn()`

For example, you can define a model tool like this:
```typescript
const schema = a.schema({
  Post: a.model({
    title: a.string(),
    body: a.string(),
  })
  .authorization(allow => allow.owner()),

  chat: a.conversation({
    aiModel: a.ai.model('Claude 3.5 Haiku'),
    systemPrompt: 'Hello, world!',
    tools: [
      a.ai.dataTool({
        name: 'PostQuery',
        description: 'Searches for Post records',
        model: a.ref('Post'),
        modelOperation: 'list',
      }),
    ],
  }),
})
```

Query tools give the LLM access to custom queries defined in your data schema. To do so, define a custom query with a function or custom handler and then reference that custom query as a tool. This requires that the custom query uses the `allow.authenticated()` authorization strategy.

For example, you can define a query tool like this:
```typescript
export const getWeather = defineFunction({
  name: 'getWeather',
  entry: './getWeather.ts',
  environment: {
    API_ENDPOINT: 'MY_API_ENDPOINT',
    API_KEY: secret('MY_API_KEY'),
  },
});

const schema = a.schema({
  getWeather: a.query()
    .arguments({ city: a.string() })
    .returns(a.customType({
      value: a.integer(),
      unit: a.string()
    }))
    .handler(a.handler.function(getWeather))
    .authorization((allow) => allow.authenticated()),

  chat: a.conversation({
    aiModel: a.ai.model('Claude 3.5 Haiku'),
    systemPrompt: 'You are a helpful assistant',
    tools: [
      a.ai.dataTool({
        name: 'get_weather',
        description: 'Gets the weather for a given city',
        query: a.ref('getWeather'),
      }),
    ]
  })
    .authorization((allow) => allow.owner()),
})
```

You can also define a Lambda function handler for the custom query. For example:
```typescript
export const handler: Schema["getWeather"]["functionHandler"] = async (
  event
) => {
  const { city } = event.arguments;
  if (!city) {
    throw new Error('City is required');
  }

  const url = `${env.API_ENDPOINT}?city=${encodeURIComponent(city)}`;
  const request = new Request(url, {
    headers: {
      Authorization: `Bearer ${env.API_KEY}`
    }
  });

  const response = await fetch(request);
  const weather = await response.json();
  return weather;
}
```

You can connect to any AWS service by defining a custom query and calling that service in the function handler. To properly authorize the custom query function to call the AWS service, you will need to provide the Lambda with the proper permissions.

Custom Lambda tools can be defined to execute in the conversation handler AWS Lambda function. This is useful if you want to define a tool that is not related to your data schema or that does simple tasks within the Lambda function runtime.

To define a custom Lambda tool, first install the `@aws-amplify/backend-ai` package. Then, define a custom conversation handler function in your data schema and reference the function in the `handler` property of the `a.conversation()` definition.

For example:
```typescript
export const chatHandler = defineConversationHandlerFunction({
  entry: './chatHandler.ts',
  name: 'customChatHandler',
  models: [
    { modelId: a.ai.model("Claude 3.5 Haiku") }
  ]
});

const schema = a.schema({
  chat: a.conversation({
    aiModel: a.ai.model('Claude 3.5 Haiku'),
    systemPrompt: "You are a helpful assistant",
    handler: chatHandler,
  })
    .authorization((allow) => allow.owner()),
})
```

Next, define the executable tool(s) and handler. For example:
```typescript
const jsonSchema = {
  json: {
    type: 'object',
    properties: {
      'operator': {
        'type': 'string',
        'enum': ['+', '-', '*', '/'],
        'description': 'The arithmetic operator to use'
      },
      'operands': {
        'type': 'array',
        'items': {
          'type': 'number'
        },
        'minItems': 2,
        'maxItems': 2,
        'description': 'Two numbers to perform the operation on'
      }
    },
    required: ['operator', 'operands']
  }
} as const;

const calculator = createExecutableTool(
  'calculator',
  'Returns the result of a simple calculation',
  jsonSchema,
  (input) => {
    const [a, b] = input.operands;
    switch (input.operator) {
      case '+': return Promise.resolve({ text: (a + b).toString() });
      case '-': return Promise.resolve({ text: (a - b).toString() });
      case '*': return Promise.resolve({ text: (a * b).toString() });
      case '/':
        if (b === 0) throw new Error('Division by zero');
        return Promise.resolve({ text: (a / b).toString() });
      default:
        throw new Error('Invalid operator');
    }
  },
);

export const handler = async (event: ConversationTurnEvent) => {
  await handleConversationTurnEvent(event, {
    tools: [calculator],
  });
};
```

Finally, update your backend definition to include the newly defined `chatHandler` function.

Best practices for using tools include:
- Validate and sanitize any input from the LLM before using it in your application
- Handle errors gracefully and provide meaningful error messages
- Log and monitor tool usage to detect potential misuse or issues

Data extraction allows you to parse unstructured text and extract structured data using artificial intelligence. This is useful for converting free-form text into typed objects that can be used in your application.

The following example shows how to extract product details from an unstructured product description in a React application. The AI model will analyze the text and return a structured object containing the product name, summary, price, and category.

To achieve this, you need to define a schema that includes a custom type for the product details and a generation that uses the AI model to extract the details. 

In your React component, you can use the `useAIGeneration` hook from `@aws-amplify/ui-react-ai` to generate the product details. This hook returns a function to extract the product details and a state object with the generated data and a loading indicator.

Here is an example of how to use it:
```javascript
import { generateClient } from "aws-amplify/api";
import { createAIHooks } from "@aws-amplify/ui-react-ai";

const client = generateClient({ authMode: "userPool" });
const { useAIGeneration } = createAIHooks(client);

function Example() {
  const productDescription = `The NBA Official Game Basketball is a premium
  regulation-size basketball crafted with genuine leather and featuring
  official NBA specifications. This professional-grade ball offers superior grip
  and durability, with deep channels and a moisture-wicking surface that ensures
  consistent performance during intense game play. Priced at $159.99, this high-end
  basketball belongs in our Professional Sports Equipment category and is the same model
  used in NBA games.`

  const [{ data, isLoading }, extractProductDetails] =
    useAIGeneration("extractProductDetails");

  const productDetails = async () => {
    extractProductDetails({
      productDescription
    });
  };
}
```

When you call the `extractProductDetails` function, it will generate the product details and update the `data` state with the result. The response will be a structured object containing the product name, summary, price, and category, like this:
```json
{
  "name": "NBA Official Game Basketball",
  "summary": "Premium regulation-size NBA basketball made with genuine leather. Features official NBA specifications, superior grip, deep channels, and moisture-wicking surface for consistent game play performance.",
  "price": 159.99,
  "category": "Professional Sports Equipment"
}
```

AI generation routes are a request-response API used to generate structured output from AI models. These routes can be used for various tasks such as generating structured data from unstructured input, summarization, and more.

To use AI generation routes, you need to define a schema that includes a generation route. A generation route is an AWS AppSync query that ensures the AI model responds with the response type defined for the route.

### Generating Typed Objects

To generate typed objects, you can define a schema with a generation route that returns a custom type. For example, you can define a schema that generates a recipe based on a description. 

In React, you can use the `useAIGeneration` hook from `@aws-amplify/ui-react-ai` to generate a recipe. Here's an example:
```tsx
import { generateClient } from "aws-amplify/api";
import { createAIHooks } from "@aws-amplify/ui-react-ai";

const client = generateClient({ authMode: "userPool" });
const { useAIGeneration } = createAIHooks(client);

export default function Example() {
  const [{ data, isLoading }, generateRecipe] = useAIGeneration("generateRecipe");

  const generateSummary = async () => {
    generateRecipe({
      description: 'I would like to bake a birthday cake for my friend. She has celiac disease and loves chocolate.',
    });
  };
}
```

### Generating Scalar Types

To generate scalar types, you can define a schema with a generation route that returns a scalar type. For example, you can define a schema that summarizes a piece of text. 

In React, you can use the `useAIGeneration` hook to generate a summary. Here's an example:
```tsx
import { generateClient } from "aws-amplify/api";
import { createAIHooks } from "@aws-amplify/ui-react-ai";

const client = generateClient({ authMode: "userPool" });
const { useAIGeneration } = createAIHooks(client);

export default function Example() {
  const [{ data, isLoading }, summarize] = useAIGeneration("summarize");

  const generateSummary = async () => {
    summarize({
      input: 'This is a piece of text that needs to be summarized.',
    });
  };
}
```

### Setting Inference Parameters

You can influence response generation by setting inference parameters for the AI model. Inference parameters allow you to control the randomness and diversity of responses, which is useful for generating responses tailored to your needs.

For example, you can define a schema that generates a haiku with specific inference parameters. 
```tsx
import { generateClient } from "aws-amplify/api";
import { createAIHooks } from "@aws-amplify/ui-react-ai";

const client = generateClient({ authMode: "userPool" });
const { useAIGeneration } = createAIHooks(client);

export default function Example() {
  const [{ data, isLoading }, generateHaiku] = useAIGeneration("generateHaiku");

  const generateHaikuExample = async () => {
    generateHaiku({
      description: 'Generate a haiku about nature.',
      inferenceConfiguration: {
        maxTokens: 1000,
        temperature: 0.5,
        topP: 0.9,
      }
    });
  };
}
```

### Limitations

There are some limitations to using AI generation routes. 

1. Generation routes do not support referencing models. However, you can reference custom types. 

2. Generation routes do not support some required types. The following AppSync scalar types are not supported as required fields in response types:
- `AWSEmail`
- `AWSDate`
- `AWSTime`
- `AWSDateTime`
- `AWSTimestamp`
- `AWSPhone`
- `AWSURL`
- `AWSIPAddress`

For example, the following schema defines a custom type that can be used as the return type of a generation route:
```tsx
import { generateClient } from "aws-amplify/api";
import { createAIHooks } from "@aws-amplify/ui-react-ai";

const client = generateClient({ authMode: "userPool" });
const { useAIGeneration } = createAIHooks(client);

export default function Example() {
  const [{ data, isLoading }, generateRecipe] = useAIGeneration("generateRecipe");

  const generateRecipeExample = async () => {
    generateRecipe({
      description: 'I would like to bake a birthday cake for my friend. She has celiac disease and loves chocolate.',
    });
  };
}
```

In this guide, you will learn how to get started with the Amplify AI kit. This includes defining your AI backend with Conversation and Generation routes, and securely connecting to them from your frontend application.

To get started, you can use one of the samples provided by AWS. 

Before you begin, you will need Node.js version 18.16.0 or later, npm version 6.14.4 or later, and git version 2.14.1 or later. You will also need an AWS account that is set up for local development and has access to the Bedrock Foundation Model(s) you want to use.

Running inference on large language models can be costly. However, Amazon Bedrock is a serverless service, so you only pay for what you use. Be mindful of the costs associated with building generative AI applications.

To create an Amplify backend, run the create amplify script in your project directory using the command `npm create amplify@latest`. Then, run the Amplify sandbox using the command `npx ampx sandbox`. This will provision the cloud resources you define in your amplify folder and watch for updates and redeploy them.

To build an AI backend, you define AI 'routes' in your Amplify Data schema. An AI route is like an API endpoint for interacting with backend AI functionality. There are currently two types of routes: Conversation and Generation. 

A conversation route is a streaming, multi-turn API. Conversations and messages are automatically stored in DynamoDB, so users can resume conversations. Examples of this include chat-based AI experiences or conversational UI.

A generation route is a single synchronous request-response API. A generation route is just an AppSync Query. Examples of this include generating alt text for an image, generating structured data from unstructured input, summarization, etc.

To define AI routes, open your `amplify/data/resource.ts` file and use `a.generation()` and `a.conversation()` in your schema. For example:

```typescript
import { a, defineData, type ClientSchema } from '@aws-amplify/backend';

const schema = a.schema({
  chat: a.conversation({
    aiModel: a.ai.model('Claude 3.5 Haiku'),
    systemPrompt: 'You are a helpful assistant',
  })
  .authorization((allow) => allow.owner()),

  generateRecipe: a.generation({
    aiModel: a.ai.model('Claude 3.5 Haiku'),
    systemPrompt: 'You are a helpful assistant that generates recipes.',
  })
  .arguments({
    description: a.string(),
  })
  .returns(
    a.customType({
      name: a.string(),
      ingredients: a.string().array(),
      instructions: a.string(),
    })
  )
  .authorization((allow) => allow.authenticated()),
});
```

Once the cloud sandbox is up and running, it will also create an `amplify_outputs.json` file, which includes relevant connection information to your AI routes and other Amplify configuration.

To connect your frontend code to your backend, you need to configure the Amplify library with the Amplify client configuration file, generate a new API client from the Amplify library, and make an API request with end-to-end type-safety.

First, install the Amplify client library to your project using the command `npm add aws-amplify @aws-amplify/ui-react @aws-amplify/ui-react-ai` for React, Next.js, or React Native, or `npm add aws-amplify` for JavaScript, Vue, or Angular.

Then, configure the Amplify library with the `amplify_outputs.json` file. For React, you can do this in the file where the React application is mounted:

```tsx
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
```

For Next.js, you can do this in the `pages/_app.tsx` file for the Pages router or in the `app/ConfigureAmplify.tsx` file for the App router.

Next, generate a type-safe frontend client to talk to your backend using your backend data schema and the `generateClient()` function provided by the Amplify libraries. For React, you can do this in a `client.ts` file:

```typescript
import { generateClient } from "aws-amplify/api";
import { Schema } from "../amplify/data/resource";
import { createAIHooks } from "@aws-amplify/ui-react-ai";

export const client = generateClient<Schema>({ authMode: "userPool" });
export const { useAIConversation, useAIGeneration } = createAIHooks(client);
```

Finally, you can use the `useAIGeneration` hook to make a request to your generation route. For example:

```tsx
import * as React from 'react';
import { Flex, TextAreaField, Loader, Text, View, Button } from "@aws-amplify/ui-react"
import { useAIGeneration } from "./client";

export default function App() {
  const [description, setDescription] = React.useState("");
  const [{ data, isLoading }, generateRecipe] =
    useAIGeneration("generateRecipe");

  const handleClick = async () => {
    generateRecipe({ description });
  };

  return (
    <Flex direction="column">
      <Flex direction="row">
        <TextAreaField
          autoResize
          value={description}
          onChange={(e) => setDescription(e.target.value)}
          label="Description"
        />
        <Button onClick={handleClick}>Generate recipe</Button>
      </Flex>
      {isLoading ? (
        <Loader variation="linear" />
      ) : (
        <>
          <Text fontWeight="bold">{data?.name}</Text>
          <View as="ul">
            {data?.ingredients?.map((ingredient) => (
              <View as="li" key={ingredient}>
                {ingredient}
              </View>
            ))}
          </View>
          <Text>{data?.instructions}</Text>
        </>
      )}
    </Flex>
  );
}
```

You can also use the `useAIConversation` hook to make a request to your conversation route. For example:

```tsx
import { Authenticator } from "@aws-amplify/ui-react";
import { AIConversation } from '@aws-amplify/ui-react-ai';
import { useAIConversation } from './client';

export default function App() {
  const [
    {
      data: { messages },
      isLoading,
    },
    handleSendMessage,
  ] = useAIConversation('chat');

  return (
    <Authenticator>
      <AIConversation
        messages={messages}
        isLoading={isLoading}
        handleSendMessage={handleSendMessage}
      />
    </Authenticator>
  );
}
```

When a user uninstalls an application that uses AWS Amplify, some data may persist on the device. This is because certain Amplify categories, such as Analytics and Auth, store data locally on the device.

For Android devices, if the Android Auto Backup for Apps service is enabled, it may attempt to restore application data when the app is reinstalled. However, Amplify Auth uses EncryptedSharedPreferences to store auth data, which is encrypted using keys stored in the Android Keystore. When an app is uninstalled, these keys are deleted, making it impossible to restore the auth data when the app is reinstalled. As a result, users will have to re-authenticate after reinstalling the app.

For iOS devices, Amplify stores auth information in the local system keychain, but it does not guarantee that this data will be removed when an app is uninstalled. Instead, app developers should decide when to clear this auth information by signing out. One way to do this is to use the UserDefaults API to detect whether the app is launching for the first time, and if so, invoke the Auth.signOut() method. 

For example, in React, you could use the following code to detect whether the app is launching for the first time and sign out if necessary:
```
import { Auth } from 'aws-amplify';

useEffect(() => {
  const isFirstLaunch = localStorage.getItem('isFirstLaunch');
  if (!isFirstLaunch) {
    Auth.signOut();
    localStorage.setItem('isFirstLaunch', 'true');
  }
}, []);
```
This code checks whether the 'isFirstLaunch' key exists in local storage, and if not, signs out the user and sets the key to 'true'. This ensures that the user is signed out when the app is launched for the first time after installation.

Analytics auto tracking helps you to automatically track user behaviors like sessions' start/stop, page view change and web events like clicking or mouseover.

Session Tracking is available in both web and React Native apps using Analytics. A web session is active when the page is not hidden and inactive when the page is hidden. In a React Native app, a session is active when the app is in the foreground and inactive when the app is in the background.

To track sessions in a React app, you can use the `configureAutoTrack` function from `aws-amplify/analytics`. This function takes an options object with the following properties: 
- `enable`: a boolean to turn on or off the auto tracking
- `type`: the event type, which can be 'event', 'pageView', or 'session'
- `options`: additional options for the tracked event, including attributes and other settings

For example, to track sessions in a React app, you can use the following code:
```javascript
import { configureAutoTrack } from 'aws-amplify/analytics';

configureAutoTrack({
  enable: true,
  type: 'session',
  options: {
    attributes: {
      customizableField: 'attr'
    }
  }
});
```

By default, when the page or app transitions to the foreground, the Analytics module will send an event to the Amazon Pinpoint Service. This behavior can be disabled by calling `configureAutoTrack` with `enable` set to `false`.

Page View Tracking is used to track the most frequently viewed pages or URLs in your web app. It automatically sends events containing URL information when a page is visited. This can be enabled or disabled using the `configureAutoTrack` function with `type` set to 'pageView'.

For example:
```javascript
import { configureAutoTrack } from 'aws-amplify/analytics';

configureAutoTrack({
  enable: true,
  type: 'pageView',
  options: {
    attributes: {
      customizableField: 'attr'
    },
    eventName: 'pageView',
    appType: 'singlePageApp',
    urlProvider: () => {
      return window.location.origin + window.location.pathname;
    }
  }
});
```

Page Event Tracking is used to track user interactions with specific elements on a page. This can be enabled or disabled using the `configureAutoTrack` function with `type` set to 'event'.

For example:
```javascript
import { configureAutoTrack } from 'aws-amplify/analytics';

configureAutoTrack({
  enable: true,
  type: 'event',
  options: {
    attributes: {
      customizableField: 'attr'
    },
    events: ['click'],
    selectorPrefix: 'data-amplify-analytics-'
  }
});
```

You can then add attributes to your HTML elements using the `data-amplify-analytics-` prefix. For example:
```html
<button
  data-amplify-analytics-on="click"
  data-amplify-analytics-name="click"
  data-amplify-analytics-attrs="attr1:attr1_value,attr2:attr2_value"
/>
```

Note that Amplify does not capture location automatically. Instead, you can add location information in the default config when you configure Analytics or while updating the endpoint.

When submitting an app to the App Store, Apple requires developers to provide a data usage policy. The Amplify Library gathers API usage metrics from AWS services accessed, which involves adding a user agent to the request made to the AWS service. This user-agent header includes information about the Amplify Library version, operating system name, and version. AWS collects this data to generate metrics related to library usage, but it is not linked to the user's identity and not used for tracking purposes.

The Amplify Library collects various types of data, including name, email address, phone number, photos or videos, audio data, user ID, device ID, OS version, OS name, locale info, app version, and other device information. The purpose of collecting this data is for app functionality, analytics, or authentication. Some of this data is linked to the user's identity, but it is not used for tracking purposes.

Some Amplify categories, such as Analytics and Auth, persist data to the local device. When a user uninstalls the app from the device, some of this data is automatically removed. However, Auth information is stored in the local system keychain, which does not guarantee that the data will be removed when the app is uninstalled.

To clear Auth information, app developers should decide when to clear the data by signing out. One strategy for accomplishing this is to use a mechanism to detect whether the app is launching for the first time and invoke a sign-out function if the app has not been launched before. In a React app, this could be achieved by using a state management system or a local storage solution to store a flag indicating whether the app has been launched before, and then calling the `Auth.signOut()` function if the flag is not set.

For example, in a React app, you could use the `useState` hook to store a flag indicating whether the app has been launched before, and then call the `Auth.signOut()` function if the flag is not set:
```javascript
import { useState, useEffect } from 'react';
import { Auth } from 'aws-amplify';

function App() {
  const [hasLaunchedBefore, setHasLaunchedBefore] = useState(false);

  useEffect(() => {
    const hasLaunchedBeforeFlag = localStorage.getItem('hasLaunchedBefore');
    if (!hasLaunchedBeforeFlag) {
      Auth.signOut();
    }
    setHasLaunchedBefore(true);
    localStorage.setItem('hasLaunchedBefore', 'true');
  }, []);

  return <div>App content</div>;
}
```

To disable analytics in your app, you can use the disable function. By default, analytics are enabled when you configure it in your app. 

To disable analytics in a React app, you can use the following code:
```javascript
import { disable } from 'aws-amplify/analytics';

disable();
```

To enable analytics, you can use the enable function in your app. 

To enable analytics in a React app, you can use the following code:
```javascript
import { enable } from 'aws-amplify/analytics';

enable();
```

To use existing Amazon Pinpoint resources with your Amplify backend or frontend application, you need to surface the backend resource outputs to the `amplify_outputs.json` file. You can do this by using the `addOutput` method.

For example, in your `amplify/backend.ts` file, you would add the following code:
```javascript
import { defineBackend } from "@aws-amplify/backend"

const backend = defineBackend({})

backend.addOutput({
  analytics: {
    amazon_pinpoint: {
      aws_region: "your-aws-region",
      app_id: "your-pinpoint-app-id",
    },
  },
})
```
Alternatively, you can configure the client library directly using `Amplify.configure()`. This manual setup enables you to use your existing Amazon Pinpoint resource in your app.

For example, in your React application, you would add the following code:
```javascript
import { Amplify } from 'aws-amplify';

Amplify.configure({
  Analytics: {
    Pinpoint: {
      appId: 'your-pinpoint-app-id',
      region: 'your-aws-region',
      bufferSize: 1000,
      flushSize: 100,
      flushInterval: 5000,
      resendLimit: 5
    }
  }
});
```
Note that you need to replace `your-aws-region` and `your-pinpoint-app-id` with your actual AWS region and Pinpoint app ID.

Additionally, Amazon Pinpoint requires an AWS Identity and Access Management (IAM) policy to use the `record` and `identifyUser` APIs. You need to update your IAM policy to include the following:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["mobiletargeting:UpdateEndpoint", "mobiletargeting:PutEvents"],
      "Resource": ["arn:aws:mobiletargeting:*:your-account-id:apps/your-pinpoint-app-id*"]
    }
  ]
}
```
Make sure to replace `your-account-id` and `your-pinpoint-app-id` with your actual AWS account ID and Pinpoint app ID.

This call sends information that you have specified about the user to Amazon Pinpoint. This could be for an unauthenticated or an authenticated user. 

In addition, customProperties and userAttributes can also be provided when invoking identifyUser. The Amazon Pinpoint console makes that data available as part of the criteria for segment creation. Attributes passed in via customProperties will appear under Custom Endpoint Attributes, while userAttributes will appear under Custom User Attributes.

You can get the current user's ID from the Amplify Auth category. Be sure you have it added and setup per the Auth category documentation.

If you have asked for location access and received permission, you can also provide that in UserProfile.Location.

To identify a user in React, you can use the following code:
```javascript
import { identifyUser } from 'aws-amplify/analytics';
import { getCurrentUser } from 'aws-amplify/auth';

const location = {
  latitude: 47.606209,
  longitude: -122.332069,
  postalCode: '98122',
  city: 'Seattle',
  region: 'WA',
  country: 'USA'
};

const customProperties = {
  plan: ['plan'],
  phoneNumber: ['+11234567890'],
  age: ['25']
};

const userProfile = {
  location,
  name: 'username',
  email: 'name@example.com',
  customProperties
};

async function sendUserData() {
  const user = await getCurrentUser();

  identifyUser({
    userId: user.userId,
    userProfile
  });
}
```
Sending user information allows you to associate a user to their user profile and activities or actions in your app. The user's actions and attributes can also be tracked across devices and platforms by using the same userId. 

Some scenarios for identifying a user and their associated app activities are:
* When a user completes app sign up
* When a user completes sign in process
* When a user launches your app
* When a user modifies or updates their user profile

Amazon Personalize can create recommendations by using event data, historical data, or a combination of both. The event data can then be used to create recommendations.

To record event data, you need the following:
* A dataset group
* An event tracker

For more information, see Record Events.

After creating the Amazon Personalize dataset group, you need to add the personalize:PutEvents permission to your AWS Identity and Access Management (IAM) user roles. An example IAM policy is:
```
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": "personalize:PutEvents",
    "Resource": "arn:aws:personalize:<your-aws-region>:<your-account-id>:event-tracker/<your-resource-name>"
  }]
}
```
You need the tracking ID of your event tracker. 

Configure Amazon Personalize in your React application:
```javascript
import { Amplify } from 'aws-amplify';
Amplify.configure({
  Analytics: {
    Personalize: {
      trackingId: '<tracking-id>',
      region: 'us-east-1',
      flushSize: 10,
      flushInterval: 5000 
    }
  }
});
```
You can use the Identify event type to track a user identity by specifying a unique identifier for the userId property. Consider recording Identify events after a user registers, logs in, updates their information, or loads pages accessible by a logged-in user.
```javascript
import { record } from 'aws-amplify/analytics/personalize';

record({
  eventType: 'Identify',
  properties: {
    userId: '<user-id>'
  }
});
```
You can send events to Amazon Personalize by calling the record operation. If you already use Identify to track end-user data, you can skip the userId.
```javascript
import { record } from 'aws-amplify/analytics/personalize';

record({
  eventType: '<event-type>',
  properties: {
    itemId: '<item-id>',
    eventValue: '<event-value>'
  }
});
```
You can track iframe and HTML5 media types by using the MediaAutoTrack event type.
```javascript
import { record } from 'aws-amplify/analytics/personalize';

record({
  eventType: 'MediaAutoTrack',
  properties: {
    domElementId: 'media-dom-element-id',
    itemId: '<item-d>'
  }
});
```
The recorded events are saved in a buffer and sent to the remote server periodically. If needed, you have the option to manually clear all the events from the buffer by using the flushEvents API.
```javascript
import { flushEvents } from 'aws-amplify/analytics/personalize';

flushEvents();
```

To record events in Amplify, you can use the `recordEvent` API. This API allows you to record custom events within your app, and it handles retry logic in case the device loses network connectivity. It also automatically batches requests to reduce network bandwidth.

Here is an example of how to record a custom event in React:
```javascript
import Amplify from 'aws-amplify';
import Analytics from '@aws-amplify/analytics';

const recordEvent = async () => {
  const event = {
    name: 'PasswordReset',
    attributes: {
      Channel: 'SMS',
      Successful: true,
    },
    metrics: {
      ProcessDuration: 792,
      UserAge: 120.3,
    },
  };

  await Analytics.record(event);
};
```

You can also record authentication events, such as sign-ins, sign-ups, and authentication failures. To do this, you can use the following event types:
- `_userauth.sign_in`
- `_userauth.sign_up`
- `_userauth.auth_fail`

Here is an example of how to record an authentication event in React:
```javascript
import Amplify from 'aws-amplify';
import Analytics from '@aws-amplify/analytics';

const recordAuthenticationEvent = async () => {
  const event = {
    name: '_userauth.sign_in',
  };

  await Analytics.record(event);
};
```

You can also register global properties that will be sent along with all recorded events. To do this, you can use the `registerGlobalProperties` API.

Here is an example of how to register global properties in React:
```javascript
import Amplify from 'aws-amplify';
import Analytics from '@aws-amplify/analytics';

const registerGlobalProperties = async () => {
  const properties = {
    AppStyle: 'DarkMode',
  };

  await Analytics.registerGlobalProperties(properties);
};
```

To unregister global properties, you can use the `unregisterGlobalProperties` API.

Here is an example of how to unregister global properties in React:
```javascript
import Amplify from 'aws-amplify';
import Analytics from '@aws-amplify/analytics';

const unregisterGlobalProperties = async () => {
  await Analytics.unregisterGlobalProperties(['AppStyle', 'OtherProperty']);
};
```

Note that the Amazon Pinpoint event count updates in minutes after recording your event. However, it can take upwards of 30 minutes for the event to display in the Filter section, and for its custom attributes to appear in Pinpoint.

You can also manually flush events using the `flushEvents` API.

Here is an example of how to flush events in React:
```javascript
import Amplify from 'aws-amplify';
import Analytics from '@aws-amplify/analytics';

const flushEvents = async () => {
  await Analytics.flushEvents();
};
```

This page is for formatting only

To set up Amplify Analytics, you need to enable Amazon Kinesis or Amazon Pinpoint using the AWS Cloud Development Kit (AWS CDK). The Analytics category uses Amazon Cognito identity pools to identify users in your app. Cognito allows you to receive data from authenticated and unauthenticated users in your app.

First, you need to set up the analytics backend. You can do this by using the AWS CDK to create an analytics resource powered by Amazon Pinpoint.

Next, you need to install the Amplify libraries. The installation process varies depending on the platform you are using. For JavaScript, Angular, React, Vue, React Native, and Next.js, you can install the `aws-amplify` library using npm. For Swift, you need to add the Amplify Library for Swift to your project using Xcode. For Android, you need to add the Amplify API dependencies to your build.gradle.kts file. For Flutter, you need to add the Amplify Analytics Pinpoint and Amplify Auth Cognito libraries to your pubspec.yaml file.

After installing the Amplify libraries, you need to initialize Amplify Analytics. You can do this by importing and loading the configuration file in your app. You should add the Amplify configuration step to your app's root entry point.

To initialize Amplify Analytics in a React app, you can use the following code:
```javascript
import { Amplify } from 'aws-amplify';
import { record } from 'aws-amplify/analytics';
import outputs from '../amplify_outputs.json';

Amplify.configure({
  ...Amplify.getConfig(),
  Analytics: amplifyconfig.Analytics,
});
```
Make sure to replace `amplifyconfig` with your actual Amplify configuration.

For a Next.js app, you can use the following code:
```javascript
import { Amplify } from 'aws-amplify';
import { record } from 'aws-amplify/analytics';
import outputs from '@/amplify_outputs.json';

Amplify.configure({
  ...Amplify.getConfig(),
  Analytics: amplifyconfig.Analytics,
});
```
Again, replace `amplifyconfig` with your actual Amplify configuration.

After initializing Amplify Analytics, you can start recording events and tracking sessions. You can find more information on how to do this in the Amplify Analytics documentation.

It's also important to note that there may be known issues when using certain features, such as Amazon Kinesis or Amazon Kinesis Data Firehose. You can find more information on how to resolve these issues in the Amplify Analytics documentation.

In summary, to set up Amplify Analytics, you need to:

1. Set up the analytics backend using the AWS CDK.
2. Install the Amplify libraries.
3. Initialize Amplify Analytics in your app.
4. Record events and track sessions using Amplify Analytics.

You can find more information on how to do this in the Amplify Analytics documentation.

The Amazon Data Firehose analytics provider allows you to send analytics data to an Amazon Data Firehose stream for reliably storing data. 

To set up a Firehose stream, you need to create a storage bucket to store the data from the Firehose stream and then create the Firehose resource. 

You can use the AWS Cloud Development Kit (AWS CDK) to create the Analytics resource powered by Amazon Data Firehose. 

First, create a storage bucket to store the data from the Firehose stream. 

Then, create the Firehose resource. You need to create a new IAM role for the Firehose, grant the Firehose role read/write permissions to the S3 bucket, and create a new Firehose delivery stream. 

You also need to create a new IAM policy to allow users to write to the Firehose and attach the policy to the authenticated and unauthenticated IAM roles. 

To install and configure the Firehose, ensure you have set up IAM permissions for firehose:PutRecordBatch. 

Here is an example IAM policy for Amazon Data Firehose:

```javascript
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": "firehose:PutRecordBatch",
    "Resource": "arn:aws:firehose:<your-aws-region>:<your-aws-account-id>:deliverystream/<your-stream-name>"
  }]
}
```

Configure Firehose by importing Amplify from 'aws-amplify' and calling Amplify.configure with the Analytics configuration:

```javascript
import { Amplify } from 'aws-amplify';

Amplify.configure({
  Analytics: {
    KinesisFirehose: {
      region: 'us-east-1',
      bufferSize: 1000,
      flushSize: 100,
      flushInterval: 5000,
      resendLimit: 5
    }
  }
});
```

To store data, you can send data to a Firehose stream with the standard record method:

```javascript
import { record } from 'aws-amplify/analytics/kinesis-firehose';

record({
  data: {
    // The data blob to put into the record
  },
  streamName: 'myFirehose'
});
```

You can also manually clear all the events from the buffer by using the 'flushEvents' API:

```javascript
import { flushEvents } from 'aws-amplify/analytics/kinesis-firehose';

flushEvents();
```

The Amazon Kinesis analytics provider allows you to send analytics data to an Amazon Kinesis stream for real-time processing.

To set up a Kinesis stream, you can use the AWS Cloud Development Kit (AWS CDK) to create the Analytics resource powered by Amazon Kinesis. Here's an example of how to create a new Kinesis stream with one shard:
 
You would create a new stack for the Kinesis stream, then create a new Kinesis stream. After that, you would create a new policy to allow PutRecords to the Kinesis stream and apply the policy to the authenticated and unauthenticated roles.

If you did not use the CLI, ensure you have setup IAM permissions for kinesis:PutRecords. You can add the following policy to your IAM role:
 
```javascript
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": "kinesis:PutRecords",
    "Resource": "arn:aws:kinesis:<your-aws-region>:<your-aws-account-id>:stream/<your-stream-name>"
  }]
}
```
 
Replace the template fields with your actual AWS region, account ID, and stream name.

To configure Kinesis in your React application, you can use the following code:
```javascript
import { Amplify } from 'aws-amplify';

Amplify.configure({
  Analytics: {
    Kinesis: {
      region: 'us-east-1',
      bufferSize: 1000,
      flushSize: 100,
      flushInterval: 5000,
      resendLimit: 5
    }
  }
});
```
You can send data to a Kinesis stream using the record method:
```javascript
import { record } from 'aws-amplify/analytics/kinesis';

record({
  data: {
    // The data blob to put into the record
  },
  partitionKey: 'myPartitionKey',
  streamName: 'myKinesisStream'
});
```
The recorded events are saved in a buffer and sent to the remote server periodically. You can manually clear all the events from the buffer by using the flushEvents API:
```javascript
import { flushEvents } from 'aws-amplify/analytics/kinesis';

flushEvents();
```

## Advanced Workflows

Advanced workflows in the Amplify auth category include subscribing to events, identity pool federation, auth-related Lambda triggers, and working with AWS service objects.

### Identity Pool Federation

Identity pool federation allows users to sign in using a well-known external identity provider (IdP), such as Login with Amazon, Facebook, Google, or any other OpenID Connect (OIDC)-compatible IdP. They can receive an authentication token and then exchange that token for temporary security credentials in AWS that map to an IAM role with permissions to use the resources in your AWS account.

To use identity pool federation, you don't need to create custom sign-in code or manage your own user identities. Instead, users of your app can sign in using an external IdP, and then you can use the `federateToIdentityPool` API to get AWS credentials directly from Cognito Federated Identities.

### Federate to Identity Pool

You can use the `federateToIdentityPool` API to get AWS credentials directly from Cognito Federated Identities. If you have logged in with `Auth.signIn`, you cannot call `federateToIdentityPool` as Amplify will perform this federation automatically for you in the background. In general, you should only call `Auth.federatedSignIn` when using OAuth flows.

Here is an example of how to use `federateToIdentityPool` in React:
```javascript
import { Auth } from 'aws-amplify';

const federateToIdentityPool = async (token, provider) => {
  try {
    const session = await Auth.federateToIdentityPool(token, provider);
    console.log(session);
  } catch (error) {
    console.error(error);
  }
};
```

### Retrieve Session

After federated login, you can retrieve the session using the `Auth.fetchAuthSession` API.

### Token Refresh

Automatic authentication token refresh is not supported when federated. By default, Amplify will not automatically refresh the tokens from the federated providers. You will need to handle the token refresh logic and provide the new token to the `federateToIdentityPool` API.

### Clear Session

You can clear the federated session using the `Auth.clearFederationToIdentityPool` API.

### Provide Custom Identity ID

You can provide a custom identity ID to the `federateToIdentityPool` API. This is useful when you want to use the same identity ID across multiple devices.

### Subscribing to Events

You can take specific actions when users sign-in or sign-out by subscribing to authentication events in your app.

### Lambda Triggers

With the triggers property of `defineAuth` and `defineFunction` from the new Functions implementation, you can define Lambda Triggers for your Cognito User Pool. These enable you to add custom functionality to your registration and authentication flows.

### Pre Authentication and Pre Sign-up Lambda Triggers

If you have a Pre Authentication Lambda trigger enabled, you can pass `clientMetadata` as an option for `signIn`. This metadata can be used to implement additional validations around authentication.

### Passing Metadata to Other Lambda Triggers

Many Cognito Lambda Triggers also accept unsanitized key-value pairs in the form of a `clientMetadata` attribute. This attribute can be specified for various Auth APIs which result in Cognito Lambda Trigger execution.

### Working with AWS Service Objects

You can use AWS Service Interface Objects to work with AWS Services in an authenticated state. You can call methods on any AWS Service interface object by passing your credentials from Amplify `fetchAuthSession` to the service call constructor.

Here is an example of how to use AWS Service Interface Objects in React:
```javascript
import { Auth } from 'aws-amplify';
import { Route53 } from 'aws-sdk/clients/route53';

const changeResourceRecordSets = async () => {
  try {
    const { credentials } = await Auth.fetchAuthSession();
    const route53 = new Route53({
      apiVersion: '2013-04-01',
      credentials,
    });
    // More code working with route53 object
  } catch (error) {
    console.error(error);
  }
};
```

### Custom Token Providers

Create a custom Auth token provider for situations where you would like to provide your own tokens for a service. For example, using OIDC Auth with AppSync. You must supply the token provider to Amplify via the `Amplify.configure` method call.

Here is an example of how to create a custom token provider in React:
```javascript
import { Amplify } from 'aws-amplify';
import { TokenProvider } from 'aws-amplify/auth';

const myTokenProvider: TokenProvider = {
  async getTokens({ forceRefresh } = {}) {
    if (forceRefresh) {
      // Try to obtain new tokens if possible
    }

    const accessTokenString = '<insert JWT from provider>';
    const idTokenString = '<insert JWT from provider>';

    return {
      accessToken: {
        // token details
      },
      idToken: {
        // token details
      },
    };
  },
};

Amplify.configure(awsconfig, {
  Auth: {
    tokenProvider: myTokenProvider,
  },
});
```

When a user uninstalls an app that uses AWS Amplify, some data may be persisted on the device. This is because certain Amplify categories, such as Analytics and Auth, store data locally on the device.

For Android devices, when an app is uninstalled, the data is removed. However, if the Android Auto Backup for Apps service is enabled, it may attempt to restore the application data when the app is reinstalled. Amplify Auth uses EncryptedSharedPreferences to store auth data, which is encrypted using keys from the Android Keystore. When an app is uninstalled, these keys are deleted, and the encrypted data is no longer readable. As a result, auth information cannot be restored when an app is reinstalled, and the user will need to re-authenticate.

For iOS devices, Amplify stores auth information in the system keychain, which does not guarantee that data will be removed when an app is uninstalled. To handle this situation, app developers should decide when to clear auth data by signing out. One strategy is to use UserDefaults to detect if the app is launching for the first time and invoke `Auth.signOut()` if it has not been launched before.

To accomplish this in a React app, you can use the `useEffect` hook to check if the app is launching for the first time and sign out if necessary. Here is an example:
```javascript
import { useEffect } from 'react';
import { Auth } from 'aws-amplify';

useEffect(() => {
  const isFirstLaunch = localStorage.getItem('isFirstLaunch');
  if (!isFirstLaunch) {
    Auth.signOut();
    localStorage.setItem('isFirstLaunch', 'true');
  }
}, []);
```
This code uses the `localStorage` API to store a flag indicating whether the app has been launched before. If the flag is not set, it signs out the user using `Auth.signOut()` and sets the flag to `true`.

By default, Amplify Auth uses email as the default method for user sign-in. This is set up when you scaffold Amplify Auth. 

To set this up, you define the auth configuration with the `defineAuth` function from `@aws-amplify/backend` and specify that you want to use email for login. 

Here is an example in JavaScript:
```javascript
import { defineAuth } from "@aws-amplify/backend";

const auth = defineAuth({
  loginWith: {
    email: true,
  },
});
```

This sets up an `email` attribute that is required for sign-up and cannot be changed. 

To use this auth configuration in your React application, you can then call the `signIn` API to sign in users. You can also customize the emails that are sent to users during the sign-in process. 

For more information, you can learn how to use the `signIn` API, customize emails, or configure your auth resource for production workloads.

Before you configure external sign-in with Amplify Auth, you need to set up your developer account with each provider you are using. 

To do this, follow these steps for each provider:

### Facebook Login

1. Create a developer account with Facebook.
2. Sign in with your Facebook credentials.
3. Choose "My Apps" from the top navigation bar and create a new app.
4. Set up Facebook Login for your app.
5. Note the App ID and App Secret, which you will use later.

### Google Sign-In

1. Go to the Google Developer Console.
2. Create a new project.
3. Select "APIs & Services" and then "Credentials".
4. Create a new OAuth client ID for a web application.
5. Note the Client ID and Client Secret, which you will use later.

### Login with Amazon

1. Create a developer account with Amazon.
2. Sign in with your Amazon credentials.
3. Create a new security profile to receive the Amazon Client ID and Client Secret.
4. Note the Client ID and Client Secret, which you will use later.

### Sign in with Apple

1. Sign in to the Apple Developer portal.
2. Create a new App ID and enable Sign in with Apple.
3. Create a new Service ID and enable Sign in with Apple.
4. Note the Client ID, Key ID, Private Key, and Team ID, which you will use later.

After setting up your developer accounts, you need to configure the external sign-in backend. In your `amplify/auth/resource.ts` file, add the external providers:

```typescript
import { defineAuth, secret } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      google: {
        clientId: secret('GOOGLE_CLIENT_ID'),
        clientSecret: secret('GOOGLE_CLIENT_SECRET')
      },
      signInWithApple: {
        clientId: secret('SIWA_CLIENT_ID'),
        keyId: secret('SIWA_KEY_ID'),
        privateKey: secret('SIWA_PRIVATE_KEY'),
        teamId: secret('SIWA_TEAM_ID')
      },
      loginWithAmazon: {
        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),
        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET')
      },
      facebook: {
        clientId: secret('FACEBOOK_CLIENT_ID'),
        clientSecret: secret('FACEBOOK_CLIENT_SECRET')
      },
      callbackUrls: [
        'http://localhost:3000/profile',
        'https://mywebsite.com/profile'
      ],
      logoutUrls: ['http://localhost:3000/', 'https://mywebsite.com']
    }
  }
});
```

You also need to inform your external provider of the newly configured authentication resource and its OAuth redirect URI.

For Facebook, go to your Facebook developer account, select your app, and add the OAuth redirect URI to the "Valid OAuth Redirect URIs" field.

For Google, go to the Google Developer Console, select your project, and add the OAuth redirect URI to the "Authorized Redirect URIs" field.

For Login with Amazon, go to the Amazon Developer Console, select your security profile, and add the OAuth redirect URI to the "Allowed Return URLs" field.

For Sign in with Apple, go to the Apple Developer portal, select your App ID, and add the OAuth redirect URI to the "Return URLs" field.

You can customize the scopes for retrieving user data from external providers by adding a `scopes` property to the external provider configuration. For example:

```typescript
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      loginWithAmazon: {
        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),
        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET'),
        scopes: ['profile']
      }
    }
  }
});
```

You can also map attributes between your external identity provider and your users created in Cognito by adding an `attributeMapping` property to the external provider configuration. For example:

```typescript
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      loginWithAmazon: {
        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),
        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET'),
        attributeMapping: {
          email: 'email'
        }
      }
    }
  }
});
```

To configure an OIDC provider, you can add an `oidc` property to the external provider configuration. For example:

```typescript
import { defineAuth, secret } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      oidc: [
        {
          name: 'MicrosoftEntraID',
          clientId: secret('MICROSOFT_ENTRA_ID_CLIENT_ID'),
          clientSecret: secret('MICROSOFT_ENTRA_ID_CLIENT_SECRET'),
          issuerUrl: '<your-issuer-url>'
        }
      ]
    }
  }
});
```

To configure a SAML provider, you can add a `saml` property to the external provider configuration. For example:

```typescript
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      saml: {
        name: 'MicrosoftEntraIDSAML',
        metadata: {
          metadataContent: '<your-url-hosting-saml-metadata>',
          metadataType: 'URL'
        }
      }
    }
  }
});
```

To initiate sign-in with an external identity provider, use the `signInWithRedirect` API:

```typescript
import { signInWithRedirect } from 'aws-amplify/auth';

signInWithRedirect({
  provider: 'Apple'
});
```

To complete external sign-in after redirect, use the `getCurrentUser` and `fetchUserAttributes` APIs:

```typescript
import { getCurrentUser, fetchUserAttributes } from 'aws-amplify/auth';

const user = await getCurrentUser();
const userAttributes = await fetchUserAttributes();
console.log({ user, userAttributes });
```

You can also specify a redirect URL on sign out by using the `signOut` API with the `oauth` option:

```typescript
import { signOut } from 'aws-amplify/auth';

signOut({
  global: false,
  oauth: {
    redirectUrl: 'https://authProvider/logout?logout_uri=https://mywebsite.com/'
  }
});
```

The Auth Plugin in AWS Amplify Gen 2 can be set up to automatically get guest credentials when a device is online. This allows you to use certain features without needing to sign in. However, you won't be able to do things that require a user account, such as changing your password or updating your profile. You can still get a unique ID for the device using the fetchAuthSession method.

For Amplify Auth, this guest access is also available and works the same way. The unique ID can be obtained through the fetchAuthSession method.

In Amplify Gen 2, guest access is allowed by default. To turn it off, you need to update the backend settings. You can do this by changing the backend.ts file to include the following code:

```javascript
const { cfnIdentityPool } = backend.auth.resources.cfnResources;
cfnIdentityPool.allowUnauthenticatedIdentities = false;
```

This code turns off guest access by setting allowUnauthenticatedIdentities to false.

Amplify helps you secure your application while providing an easy sign-in experience for your users, influenced by your security strategy. This security strategy includes the authentication method, security credentials, and enabling additional verification when needed.

There are two main concepts: authentication and authorization. Authentication is the process of validating who you are, often referred to as AuthN, and is typically done by an Identity Provider or IdP, such as Apple, Facebook, Google, or Amazon. Authorization, on the other hand, is the process of validating what you can access, often referred to as AuthZ, and is sometimes done by looking at tokens with custom logic, predefined rules, or signed requests with policies.

Common authentication methods and associated risks include external provider federation, which enables easier access for your users but shares data with third parties. To improve security credentials and verification for these authentication methods, you can modify the default password policy to ensure your users create stronger passwords, require additional contact information from users before they can reset passwords, and enable multi-factor authentication (MFA), which adds a layer of security at sign-in but may also add friction for your users.

Amplify Auth is powered by Amazon Cognito, an identity and access management service that enables you to secure your web or mobile applications. Amazon Cognito is comprised of two services: Amazon Cognito User Pools, a full-featured user directory service to handle user registration, authentication, and account recovery, and Amazon Cognito Federated Identities or Identity Pools, a service used to authorize your users to interact with other AWS services.

Amplify interfaces with User Pools to store your user information, including federation with other OpenID providers, and leverages federated identities to manage user access to AWS resources. Authorization is often done in one of two ways: clients pass tokens to the backend that perform custom logic to allow or deny actions, or clients sign requests and the backend validates the signature, allowing or denying actions depending on predefined policy.

Before building, it's essential to understand that some initial configuration options in Amazon Cognito cannot be changed after the backend resources are configured. These include user attributes, sign-in methods, verification methods, and the sub attribute, which is a unique identifier within each user pool. Additionally, if MFA is set to required with phone number for all users, you will need to include MFA setup when users sign up. 

In a React application, you can implement authentication and authorization using Amazon Cognito and Amplify. For example, you can use the `Auth` class from `@aws-amplify/auth` to authenticate users and then use the `Hub` class from `@aws-amplify/core` to authorize access to AWS resources. 

```javascript
import Amplify from '@aws-amplify/core';
import Auth from '@aws-amplify/auth';

// Initialize Amplify
Amplify.configure({
  Auth: {
    // Your Amazon Cognito User Pool configuration
  }
});

// Authenticate a user
Auth.signIn(username, password)
  .then((user) => {
    // User is authenticated, you can now authorize access to AWS resources
  })
  .catch((error) => {
    // Handle authentication error
  });
```

It's recommended to visit the Amazon Cognito documentation for more details on these settings, including user pool attributes and adding MFA to a user pool.

Amplify Auth supports multi-factor authentication (MFA) for user sign-in flows. MFA is an extra layer of security used to make sure that users trying to gain access to an account are who they say they are. It requires users to provide additional information to verify their identity. Amplify Auth supports MFA with time-based one-time passwords (TOTP), text messages (SMS), and email.

To set up MFA, use the `defineAuth` function to enable MFA for your app. You can set up MFA with TOTP, SMS, or email. If you plan to use SMS for MFA, the `phoneNumber` attribute must be marked as required in your `userAttributes`. If you plan to use email for MFA, the `email` attribute must also be marked as required in your `userAttributes`.

When MFA is `REQUIRED` with SMS in your backend auth resource, you will need to pass the phone number during sign-up API call. If you are using the `email` or `username` as the primary sign-in mechanism, you will need to pass the `phoneNumber` attribute as a user attribute. Similarly, when MFA is `REQUIRED` with email as your delivery mechanism, you will need to pass an email address during the sign-up API call.

To set up TOTP for a user, you need to call the `setUpTOTP` API to generate a `TOTPSetupDetails` object, which should be used to configure an Authenticator app like Microsoft Authenticator or Google Authenticator. Once the Authenticator app is set up, the user can generate a TOTP code and provide it to the library to complete the sign-in process.

To enable EMAIL MFA during sign-up, you need to pass `email` as a user attribute to enable email MFA for your users during sign-up. By default, you have to verify a user account after they sign up using the `confirmSignUp` API, which will send a one-time password to the user's phone number or email, depending on your Amazon Cognito configuration.

After a user signs in, if they have MFA enabled for their account, a challenge will be issued that requires calling the `confirmSignIn` API with the user-provided confirmation code sent to their email address. If MFA is `ON` or enabled for the user, you must call `confirmSignIn` with the OTP sent to their email address.

To set up a user's preferred MFA method, you can use the `fetchMFAPreference` API to get the current MFA preference and enabled MFA types, if any, for the current user. You can then use the `updateMFAPreference` API to update the MFA preference for the current user.

Remembering a device is useful in conjunction with MFA because it allows the second factor requirement to be automatically met when your user signs in on that device and reduces friction in their sign-in experience. By default, this feature is turned off. You can configure device tracking with the `deviceTracking` construct.

There are differences to keep in mind when working with remembered, forgotten, and tracked devices. Tracked devices are those that have been assigned a device key and secret pair. Remembered devices are also tracked, but the user has chosen to remember the device. Not-remembered devices are tracked devices where the user has chosen not to remember the device. Forgotten devices are those that have been removed from being remembered and tracked.

You can use the `forgetDevice` API to remove devices from being both remembered and tracked. You can also use the `ConfirmDevice` API to confirm a device and make it remembered. 

Here is how you would set up MFA in a React application, let's say with SMS:

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

export default async functionotpSetup(req, res) {
  const { Auth } = withSSRContext({ req });

  try {
    const username = 'your-username';
    const password = 'your-password';
    const result = await Auth.signIn(username, password);

    if (result.nextStep === 'CONFIRM_SIGN_IN_WITH_SMS_CODE') {
      const confirmationCode = 'your-confirmation-code';
      const result = await Auth.confirmSignIn({
        challengeResponse: confirmationCode,
      });
    }
  } catch (error) {
    // handle error
  }
}
```
To update the user's device preference, use `updateMFAPreference` like so:

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

export default async function updateDevicePreference(req, res) {
  const { Auth } = withSSRContext({ req });

  try {
    const preference = {
      sms: 'PREFERRED',
    };
    const result = await Auth.updateMFAPreference(preference);
  } catch (error) {
    // handle error
  }
}
```
Note that the actual implementation may vary based on your specific requirements and application architecture.

Amplify supports the use of passwordless authentication flows using the following methods: 
- SMS-based one-time password (SMS OTP)
- Email-based one-time password (Email OTP)
- WebAuthn passkey

Passwordless authentication removes the security risks and user friction associated with traditional passwords.

**Important Note:** Passwordless configuration is currently not available in defineAuth. We are currently working towards enabling support for passwordless configurations.

To implement passwordless sign-in flows, you need to override the Cognito UserPool to enable the sign-in methods. 

### SMS OTP

SMS-based authentication uses phone numbers as the identifier and text messages as the verification channel. Here's how it works: 
1. The user enters their phone number to sign up or sign in
2. They receive a text message with a time-limited code
3. After the user enters their code, they are authenticated

To use SMS-based one-time password, your Amazon Cognito user pool needs to be configured to use Amazon Simple Notification Service (SNS) to send text messages. 

### Email OTP

Email-based authentication uses email addresses for identification and verification. Here's how it works: 
1. The user enters their email address to sign up or sign in
2. They receive an email message with a time-limited code
3. After the user enters their code, they are authenticated

To use email-based one-time password, your Amazon Cognito user pool needs to be configured to use Amazon Simple Email Service (SES) to send email messages. 

### WebAuthn Passkey

WebAuthn uses biometrics or security keys for authentication, leveraging device-specific security features. Here's how it works: 
1. The user chooses to register a passkey
2. Their device prompts for biometric or security key verification
3. For future logins, they authenticate using the same method

To learn more about using WebAuthn passkeys, SMS OTP, and Email OTP in your React application code, you can visit the relevant documentation pages. Additionally, you can learn more about managing WebAuthn credentials. 

For example, to use SMS OTP in a React application, you would typically use the `Auth` class from `@aws-amplify/auth` to send a verification code to the user's phone number, and then use the `Auth` class again to confirm the verification code. 

```javascript
import { Auth } from '@aws-amplify/auth';

// Send a verification code to the user's phone number
Auth.sendCustomAuthorizer demographics = { phoneNumber: '+1234567890' })
 .then(data => console.log(data))
 .catch(err => console.log(err));

// Confirm the verification code
Auth.confirmSignUp('username', 'verificationCode')
 .then(data => console.log(data))
 .catch(err => console.log(err));
```

By default, Amplify Auth allows users to sign in using their email address. However, you can change or extend this to also allow users to sign in using their phone number. 

To do this, you need to configure the phone sign-in method in your authentication settings. Here is an example of how to do this in your Amplify Auth configuration:
```javascript
const auth = {
  loginWith: {
    phone: true,
  },
}
```
This configuration will require users to provide a phone number when signing up, and this attribute cannot be changed. 

After setting up phone sign-in, you can use the `signIn` API to allow users to sign in with their phone number. You can also customize the SMS messages sent to users during the sign-in process. 

To learn more about using the `signIn` API and configuring your account for production SMS workloads, see the next steps below:
 
- Learn how to use the `signIn` API
- Learn how to configure your account for production SMS workloads

Amplify Auth interacts with its underlying Amazon Cognito user pool as an OpenID Connect (OIDC) provider. When users successfully authenticate, you receive OIDC-compliant JSON web tokens (JWT). These tokens are used to identify your user and access resources.

There are two types of tokens: access tokens and ID tokens. Access tokens are used to verify the bearer of the token is authorized to perform an action against a resource. ID tokens are intended to be used within your frontend application only and contain personally identifiable information (PII). They should not be used to authorize access against a resource.

Access tokens have a payload that includes information such as the user's sub (subject), issuer, client ID, and expiration time. For example:
```json
{
  "sub": "54288468-e051-706d-a73f-03892273d7e9",
  "iss": "https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq",
  "client_id": "1sg675g08g6g0e9f64grv9n5sk",
  "origin_jti": "0eadb994-a6e0-419e-b309-a7a0d522d72f",
  "event_id": "b180897a-181c-4f73-94bb-a2946e8b4ef1",
  "token_use": "access",
  "scope": "aws.cognito.signin.user.admin",
  "auth_time": 1714241873,
  "exp": 1714245473,
  "iat": 1714241873,
  "jti": "57f10a4d-a1f2-453b-8672-d1cfa8187047",
  "username": "54288468-e051-706d-a73f-03892273d7e9"
}
```

ID tokens also have a payload that includes information such as the user's sub, email, and email verified status. For example:
```json
{
  "sub": "54288468-e051-706d-a73f-03892273d7e9",
  "email_verified": true,
  "iss": "https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq",
  "cognito:username": "54288468-e051-706d-a73f-03892273d7e9",
  "origin_jti": "0eadb994-a6e0-419e-b309-a7a0d522d72f",
  "aud": "1sg675g08g6g0e9f64grv9n5sk",
  "event_id": "b180897a-181c-4f73-94bb-a2946e8b4ef1",
  "token_use": "id",
  "auth_time": 1714241873,
  "exp": 1714245473,
  "iat": 1714241873,
  "jti": "bb69af10-3ce0-47c2-8d8d-5bdc8630ab58",
  "email": "hello@mycompany.com"
}
```

You can customize the token management options in Amplify Auth. Token keys are automatically rotated for added security, but you can update how they are stored, customize the refresh rate and expiration times, and revoke tokens on sign-out.

To update the token-saving mechanism, you can choose from several storage options, including local storage, cookie storage, and session storage. You can also implement your own custom storage mechanism.

For example, to use local storage in a React application, you can use the following code:
```javascript
import { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';
import { defaultStorage } from 'aws-amplify/utils';

cognitoUserPoolsTokenProvider.setKeyValueStorage(defaultStorage);
```

To use cookie storage, you can use the following code:
```javascript
import { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';
import { CookieStorage } from 'aws-amplify/utils';

cognitoUserPoolsTokenProvider.setKeyValueStorage(new CookieStorage());
```

You can also implement your own custom storage mechanism by creating a class that implements the storage interface. For example:
```javascript
import { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';
import { KeyValueStorageInterface } from 'aws-amplify/utils';

class MyCustomStorage implements KeyValueStorageInterface {
  storageObject: Record<string, string> = {};
  async setItem(key: string, value: string): Promise<void> {
    this.storageObject[key] = value;
  }
  async getItem(key: string): Promise<string | null> {
    return this.storageObject[key];
  }
  async removeItem(key: string): Promise<void> {
    delete this.storageObject[key];
  }
  async clear(): Promise<void> {
    this.storageObject = {};
  }
}

cognitoUserPoolsTokenProvider.setKeyValueStorage(new MyCustomStorage());
```

Token revocation is enabled automatically in Amplify Auth. To revoke tokens, you can set up global sign-out with `signOut({ global: true })` to globally sign out your user from all of their devices.

For example, in a React application, you can use the following code:
```javascript
import { signOut } from 'aws-amplify/auth';

signOut({ global: true });
```

You can learn more about customizing the ID token, bringing your own tokens from external providers, and using cookie storage server-side in the Amplify documentation.

Amplify Auth stores user profile information in user attributes. When a user signs in, Amplify Auth will automatically configure an email or phone number attribute that is required for sign-in.

To extend a user profile beyond the default email or phone number attribute, you can configure attributes with the userAttributes property. However, after creating an auth resource, you cannot switch an attribute between required and not required.

For example, you can configure an attribute such as birthdate by defining your auth resource as follows 
```javascript
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  userAttributes: {
    birthdate: {
      mutable: true,
      required: false,
    }
  },
})
```

User attributes are defined as Cognito Standard Attributes. Attributes can be configured to be required for user sign-up and whether the values are mutable. When configuring your resource to allow users to login with email, an email must be specified for user sign-up and cannot be changed later. However, additional attributes can be configured to be optional and mutable after sign-up.

In addition to the provided standard attributes, you can configure Custom Attributes. These are attributes that are unique to your use case, such as a tenant ID or a user's display name. Custom attributes are identified by the custom: prefix. 

For example 
```javascript
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  userAttributes: {
    "custom:display_name": {
      dataType: "String",
      mutable: true,
      maxLen: 16,
      minLen: 1,
    },
    "custom:favorite_number": {
      dataType: "Number",
      mutable: true,
      min: 1,
      max: 100,
    },
    "custom:is_beta_user": {
      dataType: "Boolean",
      mutable: true,
    },
    "custom:started_free_trial": {
      dataType: "DateTime",
      mutable: true,
    },
  },
})
```

Unlike standard attributes, custom attributes cannot natively be required for sign-up, however, can be required by validating user attributes upon sign-up with a pre-sign-up trigger.

Custom attributes can also be configured with specific data types, including String, Number, Boolean, and DateTime. String and Number can be assigned minimum and maximum constraints, which is useful for simple validations.

Next steps include learning how attributes are surfaced to tokens and learning how to manage your user attributes.

Amplify Auth provides a mechanism that allows you to group users. Assigning users to groups enables you to customize access for a collection of users, or leverage for auditing purposes. For example, only "ADMINS" users are permitted to delete posts from a bulletin, or only "EDITORS" are permitted to modify posts in a "draft" state. To get started with groups, configure the groups property.

To configure the groups property in a React application, you would need to define your authentication resource. Here's an example of how you can do this:

```javascript
const auth = {
  loginWith: {
    email: true,
  },
  groups: ["ADMINS", "EDITORS"],
}
```

Note that there are a few limitations with groups, including a limit of 10,000 groups per user pool.

Amplify resources enable you to define access for groups using common language. For example, you can use `allow.groups` in data. Here's an example of how you can define access for groups in a React application:

```javascript
const schema = {
  Article: {
    authorization: (allow) => [
      allow.groups(["EDITORS"]).to(["read", "update"])
    ]
  }
}
```

Or in storage:

```javascript
const storage = {
  name: "articles",
  access: (allow) => ({
    "drafts/*": [allow.groups(["EDITORS"]).to(["read", "write"])],
  }),
}
```

By defining access with groups, Amplify configures authorization rules to read from the current user's groups. User pool groups are available as a claim in the user's ID token and access token as `cognito:groups`. Requests can be made to secure resources using the access token and validated against this claim to permit action on the resource.

Each Cognito user pool group is assigned an IAM role. IAM roles can be modified to extend access to other AWS resources. Roles can be accessed from your backend on the `role` property of your group. Here's an example of how you can access the role of a group in a React application:

```javascript
const { groups } = auth;
const adminRole = groups["ADMINS"].role;
```

For more information on group roles and how to use them to secure access to your resources, you can refer to the AWS documentation on IAM roles. 

To learn more about using groups with Amplify Auth, you can check out the following resources:

- Learn how to automatically add a user to a group upon account confirmation
- Learn how to secure access to data models using groups
- Learn how to secure access to storage objects using groups

Amplify Auth does not support signing in with only a username and password. However, it can be configured to enable usernames for display purposes. Amazon Cognito offers two ways to provision login mechanisms: username attributes and alias attributes.

Username attributes allow you to customize which attribute can be used as the username, such as allowing users to sign in with an email or phone number instead of a username. Alias attributes allow you to specify which attributes can be used with sign-in in addition to a username.

In Amazon Cognito, usernames are immutable, meaning that after the initial sign-up, users cannot change their username later. This may be undesirable in some applications, which can motivate the use of alias attributes. Alias attributes allow you to define a mutable preferred username in addition to an immutable username.

Amplify Auth uses username attributes to configure Cognito to accept an email or phone number as the username. Users will then need to verify their ownership of the specified email or phone number to confirm their account.

You can also configure your auth resource to accept a preferred username to be used as the display name. This is not a username the user will be able to sign in with, but it can be used to mask their personal information such as their email or phone number when displaying publicly.

To configure a preferred username, you can define your auth resource in a file such as `amplify/auth/resource.ts` with the following code:
```typescript
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  userAttributes: {
    preferredUsername: {
      mutable: true,
      required: false
    }
  }
});
```
This will allow users to enter a preferred username when they sign up, which can be used as their display name.

If you want to override the default behavior and allow your users to sign up with an immutable username, you can use CDK to modify your auth resource's configuration directly. You can do this by adding the following code to your `amplify/backend.ts` file:
```typescript
import { defineBackend } from "@aws-amplify/backend"
import { auth } from "./auth/resource"
import { data } from "./data/resource"

const backend = defineBackend({
  auth,
  data,
})

const { cfnUserPool } = backend.auth.resources.cfnResources
cfnUserPool.usernameAttributes = []
```
This will allow users to sign up with a username that cannot be changed later.

To learn more about configuring email sign-up or phone sign-up, you can visit the relevant documentation pages.

Enabling users to delete their account can improve trust and transparency. Amplify Auth allows you to programmatically enable self-service account deletion.

To set up account deletion, you can use the Amplify Libraries. The `deleteUser` API will delete a user from the Auth category and sign out the user. If your application uses a Cognito User Pool, this action will only delete the user from the Cognito User Pool and will not affect Cognito Identity Pool alone.

Before deleting a user, you may need to delete associated user data that is not stored in Cognito, such as data stored with Amplify Data. This is to comply with guidelines like GDPR that require deleting data associated with a deleted account.

To enable account deletion in a React application, you can use the following method:
```javascript
import { Auth } from 'aws-amplify';

async function handleDeleteUser() {
  try {
    await Auth.deleteUser();
  } catch (error) {
    console.log(error);
  }
}
```
This code will delete the user's account and sign them out. You should update your UI to let users know that their account is deleted and test the functionality with a test user. Note that the user will be signed out of your application when they delete their account.

Amplify Auth emits events during authentication flows, which enables you to react to user flows in real time and trigger custom business logic. For example, you may want to capture data, synchronize your app's state, and personalize the user's experience. You can listen to and respond to events across the Auth lifecycle such as sign-in and sign-out.

You can use Amplify Hub with its built-in Amplify Auth events to subscribe a listener using a publish-subscribe pattern and capture events between different parts of your application. The Amplify Auth category publishes in the `auth` channel when auth events such as `signedIn` or `signedOut` happen independent from your app code.

Here is a basic example of setting up a listener that logs an event emitted through the `auth` channel:
```js
import { Hub } from 'aws-amplify/utils';

Hub.listen('auth', (data) => {
  console.log(data)
});
```

Once your app is set up to subscribe and listen to specific event types from the `auth` channel, the listeners will be notified asynchronously when an event occurs. This pattern allows for a one-to-many relationship where one auth event can be shared with many different listeners that have been subscribed. This lets your app react based on the event rather than proactively poll for information.

You can also set up your listener to extract data from the event payload and execute a callback that you define. For example, you might update UI elements in your app to reflect your user's authenticated state after the `signedIn` or `signedOut` events.

One of the most common workflows will be to log events. In this example you can see how you can listen and target specific `auth` events using a `switch` to log your own messages:
```js
import { Hub } from 'aws-amplify/utils';

Hub.listen('auth', ({ payload }) => {
  switch (payload.event) {
    case 'signedIn':
      console.log('user have been signedIn successfully.');
      break;
    case 'signedOut':
      console.log('user have been signedOut successfully.');
      break;
    case 'tokenRefresh':
      console.log('auth tokens have been refreshed.');
      break;
    case 'tokenRefresh_failure':
      console.log('failure while refreshing auth tokens.');
      break;
    case 'signInWithRedirect':
      console.log('signInWithRedirect API has successfully been resolved.');
      break;
    case 'signInWithRedirect_failure':
      console.log('failure while trying to resolve signInWithRedirect API.');
      break;
    case 'customOAuthState':
      console.log('custom state returned from CognitoHosted UI');
      break;
  }
});
```

You can also stop listening for messages by calling the result of the `Hub.listen()` function. This may be useful if you no longer need to receive messages in your application flow. This can also help you avoid any memory leaks on low powered devices when you are sending large amounts of data through Amplify Hub on multiple channels.

To stop listening to a certain event, you need to wrap the listener function with a variable and call it once you no longer need it:
```js
const hubListenerCancelToken = Hub.listen('auth', (data) => {
  console.log('Listening for all auth events: ', data.payload.data);
});

hubListenerCancelToken(); // stop listening for messages
```

Note that channels are logical group names that help you organize dispatching and listening. However, some channels are protected and cannot be used to publish custom events, and `auth` is one of these channels. Sending unexpected payloads to protected channels can have undesirable side effects such as impacting authentication flows. 

The Amplify Hub guide provides more information on protected channels and how to use them. 

Some examples of listening to auth events are:
- Update UI elements in response to user authentication state
- Capture data and synchronize the app's state in response to authentication events
- Trigger custom business logic in response to authentication events

Overall, listening to auth events with Amplify Hub provides a powerful way to react to user authentication flows in real time and create a more personalized and responsive user experience.

User attributes such as email address and phone number help identify individual users. Defining the user attributes included in user profiles makes user data easy to manage at scale. This information helps personalize user journeys, tailor content, provide intuitive account control, and more. You can capture information upfront during sign-up or enable customers to update their profile after sign-up.

### Pass User Attributes During Sign-up

You can create user attributes during sign-up or when the user is authenticated. To do this as part of sign-up, you can pass them in the `userAttributes` object of the `signUp` API. For example, in a React application using AWS Amplify:
```typescript
import { signUp } from 'aws-amplify/auth';

await signUp({
  username: 'jdoe',
  password: 'mysecurerandompassword#123',
  options: {
    userAttributes: {
      email: 'me@domain.com',
      phone_number: '+12128601234', 
      given_name: 'Jane',
      family_name: 'Doe',
      nickname: 'Jane',
    },
  },
});
```
### Configure Custom User Attributes During Sign-up

Custom attributes can be passed in with the `userAttributes` option of the `signUp` API. For example:
```typescript
import { signUp } from 'aws-amplify/auth';

await signUp({
  username: 'john.doe@example.com',
  password: 'hunter2',
  options: {
    userAttributes: {
      'custom:display_name': 'john_doe123',
    }
  }
});
```
### Retrieve User Attributes

You can retrieve user attributes for your users to read in their profile using the `fetchUserAttributes` API. For example:
```typescript
import { fetchUserAttributes } from 'aws-amplify/auth';

await fetchUserAttributes();
```
### Update User Attribute

You can use the `updateUserAttribute` API to create or update existing user attributes. For example:
```typescript
import { updateUserAttribute } from 'aws-amplify/auth';

async function handleUpdateUserAttribute(attributeKey, value) {
  try {
    const output = await updateUserAttribute({
      userAttribute: {
        attributeKey,
        value
      }
    });
    // handle next steps
  } catch (error) {
    console.log(error);
  }
}
```
Note that if you change an attribute that requires confirmation, the user will receive a confirmation code. This code can be used with the `confirmUserAttribute` API to confirm the change.

### Update User Attributes

You can use the `updateUserAttributes` API to create or update multiple existing user attributes. For example:
```typescript
import { updateUserAttributes } from 'aws-amplify/auth';

await updateUserAttributes({
  userAttributes: {
    email: 'me@domain.com',
    name: 'Jon Doe',
  },
});
```
### Verify User Attribute

Some attributes require confirmation for the attribute update to complete. If the attribute needs to be confirmed, part of the result of the `updateUserAttribute` or `updateUserAttributes` APIs will indicate that a confirmation code was sent. When the user gets the confirmation code, you can present a UI to the user to enter the code and invoke the `confirmUserAttribute` API with their input:
```typescript
import { confirmUserAttribute } from 'aws-amplify/auth';

async function handleConfirmUserAttribute({ userAttributeKey, confirmationCode }) {
  try {
    await confirmUserAttribute({ userAttributeKey, confirmationCode });
  } catch (error) {
    console.log(error);
  }
}
```
### Send User Attribute Verification Code

If an attribute needs to be verified while the user is authenticated, invoke the `sendUserAttributeVerificationCode` API:
```typescript
import { sendUserAttributeVerificationCode } from 'aws-amplify/auth';

async function handleSendUserAttributeVerificationCode(key) {
  try {
    await sendUserAttributeVerificationCode({
      userAttributeKey: key
    });
  } catch (error) {
    console.log(error);
  }
}
```
### Delete User Attributes

The `deleteUserAttributes` API allows deleting one or more user attributes:
```typescript
import { deleteUserAttributes } from 'aws-amplify/auth';

async function handleDeleteUserAttributes(keys) {
  try {
    await deleteUserAttributes({
      userAttributeKeys: ['custom:my_custom_attribute',...keys]
    });
  } catch (error) {
    console.log(error);
  }
}
```
Next steps include learning how to set up password change and recovery, and learning how to set up custom attributes.

Amplify Auth provides access to current user sessions and tokens to help you retrieve your user's information to determine if they are signed in with a valid session and control their access to your app.

To get information about the currently authenticated user, including the username, user ID, and sign-in details, you can use the `getCurrentUser` API. 

```javascript
import { getCurrentUser } from 'aws-amplify/auth';

const { username, userId, signInDetails } = await getCurrentUser();

console.log("username", username);
console.log("user id", userId);
console.log("sign-in details", signInDetails);
```

This method can be used to check if a user is signed in. It throws an error if the user is not authenticated. However, note that the user's sign-in details are not supported when using the Hosted UI or the `signInWithRedirect` API.

To get session details, you can use the `fetchAuthSession` API, which returns a tokens object containing the JSON Web Tokens (JWT).

```javascript
import { fetchAuthSession } from 'aws-amplify/auth';

const session = await fetchAuthSession();

console.log("id token", session.tokens.idToken)
console.log("access token", session.tokens.accessToken)
```

The `fetchAuthSession` API automatically refreshes the user's session when the authentication tokens have expired and a valid refresh token is present. You can also refresh the session explicitly by calling the `fetchAuthSession` API with the `forceRefresh` flag enabled.

```javascript
import { fetchAuthSession } from 'aws-amplify/auth';

await fetchAuthSession({ forceRefresh: true });
```

Note that by default, sessions from external identity providers cannot be refreshed.

After a user has finished signup, they can proceed to sign in. Amplify Auth signin flows can be multi-step processes. The required steps are determined by the configuration you provided when you define your auth resources. 

Depending on the configuration, you may need to call various APIs to finish authenticating a user's signin attempt. To identify the next step in a signin flow, inspect the nextStep parameter in the signin result.

When called successfully, the signin APIs will return an AuthSignInResult. Inspect the nextStep property in the result to see if additional signin steps are required.

The nextStep property is of type object that contains a property called signInStep. The signInStep can be one of the following: 
- CONFIRM_SIGN_IN_WITH_SMS_CODE: Amplify Auth has sent the user a random code over SMS and is waiting for the user to verify that code.
- CONFIRM_SIGN_IN_WITH_TOTP_CODE: Amplify Auth is waiting for the user to enter the TOTP code from their associated authenticator app during set up.
- CONFIRM_SIGN_IN_WITH_EMAIL_CODE: Amplify Auth has sent the user a random code to their email address and is waiting for the user to verify that code.
- CONFIRM_SIGN_IN_WITH_PASSWORD: The user must provide their password as the first factor authentication method.
- CONTINUE_SIGN_IN_WITH_MFA_SELECTION: The user must select the MFA method to use.
- CONTINUE_SIGN_IN_WITH_EMAIL_SETUP: The user must provide an email address to complete the sign in process.
- CONTINUE_SIGN_IN_WITH_TOTP_SETUP: The user must provide a TOTP code to complete the sign in process.
- CONTINUE_SIGN_IN_WITH_MFA_SETUP_SELECTION: The user must select the MFA method to setup.
- CONTINUE_SIGN_IN_WITH_FIRST_FACTOR_SELECTION: The user must select an authentication factor to use.
- CONFIRM_SIGN_IN_WITH_CUSTOM_CHALLENGE: Amplify Auth is awaiting completion of a custom authentication challenge.
- CONFIRM_SIGN_IN_WITH_NEW_PASSWORD: Amplify Auth requires the user choose a new password they proceeding with the sign in.
- RESET_PASSWORD: Amplify Auth requires that the user reset their password before proceeding.
- CONFIRM_SIGN_UP: Amplify Auth requires that the user confirm their email or phone number before proceeding.
- DONE: The sign-in flow is complete, which means the user is successfully authenticated.

To confirm sign-in with SMS MFA, you need to prompt the user to enter the code and then pass the value to the confirmSignIn API.

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

async function confirmSignInWithSmsMfa(code) {
  try {
    const result = await withSSRContext({ req: {} }).Auth.confirmSignIn({
      challengeResponse: code,
    });
    if (result.isSignedIn) {
      console.log('Confirm sign in succeeded');
    } else {
      console.log('Confirm sign in not complete');
      console.log('Next step:', result.nextStep);
    }
  } catch (error) {
    console.log('Confirm sign in failed:', error);
  }
}
```

To confirm sign-in with TOTP MFA, you need to prompt the user to enter the TOTP code and then pass the value to the confirmSignIn API.

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

async function confirmSignInWithTotpMfa(code) {
  try {
    const result = await withSSRContext({ req: {} }).Auth.confirmSignIn({
      challengeResponse: code,
    });
    if (result.isSignedIn) {
      console.log('Confirm sign in succeeded');
    } else {
      console.log('Confirm sign in not complete');
      console.log('Next step:', result.nextStep);
    }
  } catch (error) {
    console.log('Confirm sign in failed:', error);
  }
}
```

To confirm sign-in with Email MFA, you need to prompt the user to enter the code and then pass the value to the confirmSignIn API.

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

async function confirmSignInWithEmailMfa(code) {
  try {
    const result = await withSSRContext({ req: {} }).Auth.confirmSignIn({
      challengeResponse: code,
    });
    if (result.isSignedIn) {
      console.log('Confirm sign in succeeded');
    } else {
      console.log('Confirm sign in not complete');
      console.log('Next step:', result.nextStep);
    }
  } catch (error) {
    console.log('Confirm sign in failed:', error);
  }
}
```

To continue sign-in with MFA selection, you need to prompt the user to select the MFA method and then pass the selected method to the confirmSignIn API.

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

async function continueSignInWithMfaSelection(mfaMethod) {
  try {
    const result = await withSSRContext({ req: {} }).Auth.confirmSignIn({
      challengeResponse: mfaMethod,
    });
    if (result.isSignedIn) {
      console.log('Confirm sign in succeeded');
    } else {
      console.log('Confirm sign in not complete');
      console.log('Next step:', result.nextStep);
    }
  } catch (error) {
    console.log('Confirm sign in failed:', error);
  }
}
```

To continue sign-in with Email setup, you need to prompt the user to enter the email address and then pass the email address to the confirmSignIn API.

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

async function continueSignInWithEmailSetup(email) {
  try {
    const result = await withSSRContext({ req: {} }).Auth.confirmSignIn({
      challengeResponse: email,
    });
    if (result.isSignedIn) {
      console.log('Confirm sign in succeeded');
    } else {
      console.log('Confirm sign in not complete');
      console.log('Next step:', result.nextStep);
    }
  } catch (error) {
    console.log('Confirm sign in failed:', error);
  }
}
```

To continue sign-in with TOTP setup, you need to prompt the user to enter the TOTP code and then pass the TOTP code to the confirmSignIn API.

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

async function continueSignInWithTotpSetup(code) {
  try {
    const result = await withSSRContext({ req: {} }).Auth.confirmSignIn({
      challengeResponse: code,
    });
    if (result.isSignedIn) {
      console.log('Confirm sign in succeeded');
    } else {
      console.log('Confirm sign in not complete');
      console.log('Next step:', result.nextStep);
    }
  } catch (error) {
    console.log('Confirm sign in failed:', error);
  }
}
```

To confirm sign-in with a custom challenge, you need to prompt the user to enter the custom challenge answer and then pass the answer to the confirmSignIn API.

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

async function confirmSignInWithCustomChallenge(answer) {
  try {
    const result = await withSSRContext({ req: {} }).Auth.confirmSignIn({
      challengeResponse: answer,
    });
    if (result.isSignedIn) {
      console.log('Confirm sign in succeeded');
    } else {
      console.log('Confirm sign in not complete');
      console.log('Next step:', result.nextStep);
    }
  } catch (error) {
    console.log('Confirm sign in failed:', error);
  }
}
```

To confirm sign-in with a new password, you need to prompt the user to enter the new password and then pass the new password to the confirmSignIn API.

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

async function confirmSignInWithNewPassword(password) {
  try {
    const result = await withSSRContext({ req: {} }).Auth.confirmSignIn({
      challengeResponse: password,
    });
    if (result.isSignedIn) {
      console.log('Confirm sign in succeeded');
    } else {
      console.log('Confirm sign in not complete');
      console.log('Next step:', result.nextStep);
    }
  } catch (error) {
    console.log('Confirm sign in failed:', error);
  }
}
```

To reset the password, you need to invoke the resetPassword API and follow the reset password flow.

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

async function resetPassword(username) {
  try {
    const result = await withSSRContext({ req: {} }).Auth.resetPassword(username);
    console.log('Reset password succeeded');
    console.log('Next step:', result.nextStep);
  } catch (error) {
    console.log('Reset password failed:', error);
  }
}
```

To confirm sign-up, you need to invoke the confirmSignUp API and follow the confirm sign-up flow.

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

async function confirmSignUp(username, confirmationCode) {
  try {
    const result = await withSSRContext({ req: {} }).Auth.confirmSignUp(username, confirmationCode);
    console.log('Confirm sign up succeeded');
  } catch (error) {
    console.log('Confirm sign up failed:', error);
  }
}
```

The sign-in flow is complete when the next step is DONE, which means the user is successfully authenticated. As a convenience, the SignInResult also provides the isSignedIn property, which will be true if the next step is DONE. 

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

async function getSignInResult() {
  try {
    const result = await withSSRContext({ req: {} }).Auth.currentAuthenticatedUser();
    if (result.isSignedIn) {
      console.log('Sign in is complete');
    } else {
      console.log('Sign in is not complete');
      console.log('Next step:', result.nextStep);
    }
  } catch (error) {
    console.log('Sign in failed:', error);
  }
}
```

Amplify provides a client library that enables you to interact with backend resources such as Amplify Auth. The quickest way to get started with Amplify Auth in your frontend application is with the Authenticator component, which provides a customizable UI and complete authentication flows.

To use the signIn API, you need to call the signIn function and pass in the username and password. The API will return a result that includes a nextStep property, which can be used to determine if further action is required. For example, if the user needs to confirm their sign in with a code sent via SMS or email, the nextStep property will be set to CONFIRM_SIGN_IN_WITH_SMS_CODE or CONFIRM_SIGN_IN_WITH_EMAIL_CODE.

You can handle the next steps by calling the confirmSignIn function and passing in the challenge response. For example, if the user needs to confirm their sign in with a code sent via SMS, you can call confirmSignIn and pass in the code received via SMS.

Here is an example of how to use the signIn API in React:
```tsx
import { signIn } from 'aws-amplify/auth';

async function handleSubmit(event) {
  event.preventDefault();
  const form = event.currentTarget;
  const username = form.elements.email.value;
  const password = form.elements.password.value;
  try {
    const result = await signIn({
      username,
      password,
    });
    if (result.nextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_SMS_CODE') {
      // prompt user for otp code delivered via SMS
      const code = prompt('Enter the code sent via SMS');
      const confirmResult = await confirmSignIn({
        challengeResponse: code,
      });
      if (confirmResult.nextStep.signInStep === 'DONE') {
        console.log('Sign in successful!');
      }
    } else if (result.nextStep.signInStep === 'DONE') {
      console.log('Sign in successful!');
    }
  } catch (error) {
    console.error('Error signing in:', error);
  }
}
```
You can also use the signIn API with other authentication methods such as passwordless authentication with SMS or email OTP, or with external identity providers like Google or Facebook.

To sign in with an external identity provider, you can use the signInWithRedirect function and pass in the provider. For example:
```ts
import { signInWithRedirect } from 'aws-amplify/auth';

signInWithRedirect({ provider: 'Google' });
```
You can also use the autoSignIn API to automatically sign in a user when it was previously enabled by the signUp API.

To use passwordless authentication with SMS or email OTP, you can pass the preferredChallenge parameter to the signIn API. For example:
```ts
import { signIn } from 'aws-amplify/auth';

async function handleSubmit(event) {
  event.preventDefault();
  const form = event.currentTarget;
  const username = form.elements.email.value;
  try {
    const result = await signIn({
      username,
      options: {
        authFlowType: 'USER_AUTH',
        preferredChallenge: 'SMS_OTP',
      },
    });
    if (result.nextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_SMS_CODE') {
      // prompt user for otp code delivered via SMS
      const code = prompt('Enter the code sent via SMS');
      const confirmResult = await confirmSignIn({
        challengeResponse: code,
      });
      if (confirmResult.nextStep.signInStep === 'DONE') {
        console.log('Sign in successful!');
      }
    }
  } catch (error) {
    console.error('Error signing in:', error);
  }
}
```

The quickest way to get started with Amplify Auth in your frontend application is with the Authenticator component, which provides a customizable UI and complete authentication flows.

To sign a user out of your application, use the `signOut` API. Here's an example:
```ts
import { signOut } from 'aws-amplify/auth';

await signOut();
```

You can also sign out users from all devices by performing a global sign-out. This will also invalidate all refresh tokens issued to a user. The user's current access and ID tokens will remain valid on other devices until the refresh token expires (access and ID tokens expire one hour after they are issued). Here's an example:
```ts
import { signOut } from 'aws-amplify/auth';

await signOut({ global: true });
```

Here's a practical example of how to use the `signOut` API in a React application:
```tsx
import { Amplify } from "aws-amplify"
import { signOut } from "aws-amplify/auth"
import outputs from "../amplify_outputs.json"

Amplify.configure(outputs)

export default function App() {
  async function handleSignOut() {
    await signOut()
  }

  return (
    <button type="button" onClick={handleSignOut}>
      Sign out
    </button>
  )
}
```
Note that you need to configure Amplify with your application's outputs before using the `signOut` API.

Amplify provides a client library that enables you to interact with backend resources such as Amplify Auth. The quickest way to get started with Amplify Auth in your frontend application is with the Authenticator component, which provides a customizable UI and complete authentication flows.

To get started, you can use the `signUp()` API to create a new user in your backend. The `signUp` API response will include a `nextStep` property, which can be used to determine if further action is required. It may return the following next steps: 
- `CONFIRM_SIGN_UP`: The sign up needs to be confirmed by collecting a code from the user and calling `confirmSignUp`.
- `DONE`: The sign up process has been fully completed.
- `COMPLETE_AUTO_SIGN_IN`: The sign up process needs to complete by invoking the `autoSignIn` API.

Here's an example of how to use the `signUp` API in React:
```tsx
import { signUp } from "aws-amplify/auth"

const { isSignUpComplete, userId, nextStep } = await signUp({
  username: "hello@mycompany.com",
  password: "hunter2",
  options: {
    userAttributes: {
      email: "hello@mycompany.com",
      phone_number: "+15555555555" 
    },
  }
});
```
You can confirm the sign-up after receiving a confirmation code from the user:
```typescript
import { confirmSignUp } from 'aws-amplify/auth';

const { isSignUpComplete, nextStep } = await confirmSignUp({
  username: "hello@mycompany.com",
  confirmationCode: "123456"
});
```
Your application's users can also sign up using passwordless methods. To learn more, visit the concepts page for passwordless.

For passwordless sign-up with SMS OTP, you can use the following code:
```typescript
// Sign up using a phone number
const { nextStep: signUpNextStep } = await signUp({
	username: 'hello',
	options: {
		userAttributes: {
			phone_number: '+15555551234',
		},
	},
});

// Confirm sign up with the OTP received
const { nextStep: confirmSignUpNextStep } = await confirmSignUp({
	username: 'hello',
	confirmationCode: '123456',
});
```
For passwordless sign-up with Email OTP, you can use the following code:
```typescript
// Sign up using an email address
const { nextStep: signUpNextStep } = await signUp({
	username: 'hello',
	options: {
		userAttributes: {
			email: 'hello@example.com',
		},
	},
});

// Confirm sign up with the OTP received
const { nextStep: confirmSignUpNextStep } = await confirmSignUp({
	username: 'hello',
	confirmationCode: '123456',
});
```
For auto sign-in, you can use the following code:
```typescript
// Call `signUp` API with `USER_AUTH` as the authentication flow type for `autoSignIn`
const { nextStep: signUpNextStep } = await signUp({
	username: 'hello',
	options: {
		userAttributes: {
			email: 'hello@example.com',
			phone_number: '+15555551234',
		},
		autoSignIn: {
			authFlowType: 'USER_AUTH',
		},
	},
});

// Call `confirmSignUp` API to complete the flow
const { nextStep: confirmSignUpNextStep } = await confirmSignUp({
	username: 'hello',
	confirmationCode: '123456',
});

// Call `autoSignIn` API to complete the flow
const { nextStep } = await autoSignIn();
```

AWS Amplify provides various authentication flows for signing in users, including `userSRP`, `userPassword`, `customWithSRP`, `customWithoutSRP`, and `userAuth`. 

The `userSRP` flow uses the Secure Remote Password protocol, where the password never leaves the client and is unknown to the server. This is the recommended flow and is used by default.

The `userPassword` flow sends user credentials to the backend without applying SRP encryption. This flow is useful when migrating users to Cognito using the "Migration" trigger, as it allows users to verify their credentials without resetting their passwords.

The `customWithSRP` and `customWithoutSRP` flows allow for custom challenge types, such as CAPTCHAs or dynamic challenge questions, in addition to a password. These flows can be used to meet specific requirements and can be initiated by calling `signIn` with the corresponding auth flow type.

The `userAuth` flow is a choice-based authentication flow that allows users to choose from available authentication methods, such as `emailOTP`, `smsOTP`, `webAuthn`, `password`, or `passwordSRP`. This flow is useful when providing users with the option to choose their authentication method.

To switch between authentication flows, you can configure the flow in the `amplify_outputs.json` file or pass the `authFlowType` as a runtime parameter to the `signIn` API call. Runtime configuration takes precedence over any auth flow type configuration present in `amplify_outputs.json`.

Here's an example of how to initiate a custom authentication flow in React:
```javascript
import { Amplify, Auth } from 'aws-amplify';

//...

const signIn = async () => {
  try {
    const result = await Auth.signIn({
      username: 'username',
      password: 'password',
      options: {
        authFlowType: 'CUSTOM_WITH_SRP',
      },
    });
    // Handle the result
  } catch (error) {
    // Handle the error
  }
};
```
For the `userAuth` flow, you can provide the user with a list of available authentication methods and allow them to choose their preferred method. Here's an example:
```javascript
import { Amplify, Auth } from 'aws-amplify';

//...

const signIn = async () => {
  try {
    const result = await Auth.signIn({
      username: 'username',
      options: {
        authFlowType: 'USER_AUTH',
      },
    });
    // Handle the result, which may include a list of available authentication methods
  } catch (error) {
    // Handle the error
  }
};
```
You can then use the `confirmSignIn` API to complete the sign-in process with the user's chosen authentication method.

In terms of migrating users with Amazon Cognito, you can use the "Migration" trigger to migrate users from an existing user directory into Cognito. This trigger invokes a Lambda function that validates user credentials against the existing directory and returns a response object containing user attributes and status on success.

For custom authentication flows, you need to implement three Lambda triggers for Amazon Cognito: `defineAuthChallenge`, `createAuthChallenge`, and `verifyAuthChallengeResponse`. These triggers allow you to define custom challenge types and verify user responses to these challenges.

Overall, AWS Amplify provides a flexible and customizable authentication system that can meet various use cases and requirements. By choosing the right authentication flow and configuring it appropriately, you can provide a secure and user-friendly authentication experience for your users.

The quickest way to get started with Amplify Auth in your React application is with the Authenticator component, which provides a customizable UI and complete authentication flows. This component is automatically configured based on the outputs generated from your backend.

To use the Authenticator component in your React application, you can import it from `@aws-amplify/ui-react` and configure Amplify with your backend outputs. Here's an example of how to use the Authenticator component:

```tsx
import { Authenticator } from '@aws-amplify/ui-react';
import { Amplify } from 'aws-amplify';
import '@aws-amplify/ui-react/styles.css';
import outputs from "../amplify_outputs.json";

Amplify.configure(outputs);

export default function App() {
  return (
    <Authenticator>
      {({ signOut, user }) => (
        <main>
          <h1>Hello {user?.username}</h1>
          <button onClick={signOut}>Sign out</button>
        </main>
      )}
    </Authenticator>
  );
}
```

Alternatively, you can bring your own UI and leverage the library from `aws-amplify` to handle authentication flows manually. To learn more about the Authenticator and how to customize its appearance, visit the Amplify UI documentation.

The Auth category can be configured to perform a custom authentication flow defined by you. The following guide shows how to setup a simple passwordless authentication flow in a React application.

## Prerequisites
An application with Amplify libraries integrated.

## Configure Auth
The custom auth flow can be configured manually.

## Sign in a user
Implement a UI to get the username from the user. After the user enters the username you can start the sign in flow by calling the following method:
```javascript
import Amplify from 'aws-amplify';
import Auth from '@aws-amplify/auth';

async function signIn(username) {
  try {
    const result = await Auth.signIn(username);
    if (result.nextStep === 'confirmSignInWithCustomChallenge') {
      // Ask the user to enter the custom challenge.
    } else {
      console.log('Sign in succeeded');
    }
  } catch (error) {
    console.log('Sign in failed', error);
  }
}
```

## Confirm sign in with custom challenge
To get a custom challenge from the user, create an appropriate UI for the user to submit the required value, and pass that value into the `confirmSignIn()` API.
```javascript
async function confirmSignIn(response) {
  try {
    const result = await Auth.confirmSignIn(response);
    console.log('Confirm sign in succeeded');
  } catch (error) {
    console.log('Confirm sign in failed', error);
  }
}
```

## Lambda Trigger Setup
AWS Amplify now supports creating functions as part of its new backend experience. For more information on the Functions and how to start with them check out the Amplify Functions documentation. In addition, more information on available triggers can be found in the Cognito documentation.

## Custom Auth Flow with Secure Remote Password (SRP)
Cognito User Pool allows to start the custom authentication flow with SRP as the first step. If you would like to use this flow, setup Define Auth Lambda trigger to handle SRP_A as the first challenge.
```javascript
exports.handler = (event, context) => {
  if (event.request.session.length == 1 && 
      event.request.session[0].challengeName == 'SRP_A') {
        event.response.issueTokens = false;
        event.response.failAuthentication = false;
        event.response.challengeName = 'PASSWORD_VERIFIER';
  } else if (event.request.session.length == 2 && 
      event.request.session[1].challengeName == 'PASSWORD_VERIFIER' && 
      event.request.session[1].challengeResult == true) {
        event.response.issueTokens = false;
        event.response.failAuthentication = false;
        event.response.challengeName = 'CUSTOM_CHALLENGE';
  } else if (event.request.session.length == 3 && 
      event.request.session[2].challengeName == 'CUSTOM_CHALLENGE' && 
      event.request.session[2].challengeResult == true) {
        event.response.issueTokens = true;
        event.response.failAuthentication = false;
  } else {
      event.response.issueTokens = false;
      event.response.failAuthentication = true;
  }
  context.done(null, event);
};
```
If your lambda is setup to start with `SRP` as the first step, make sure to initiate the signIn process with `customWithSRP` as the authentication flow:
```javascript
import Amplify from 'aws-amplify';
import Auth from '@aws-amplify/auth';

async function signInWithSRP(username, password) {
  try {
    const options = {
      authFlowType: 'CUSTOM_AUTH_WITH_SRP',
    };
    const result = await Auth.signIn(username, password, options);
    console.log('Sign in result', result);
  } catch (error) {
    console.log('Sign in failed', error);
  }
}
```

To customize the emails your users receive when signing up with AWS Amplify, you can modify the default behavior of the email attribute in the auth settings. 

When users sign up, they receive a verification email to confirm their email address. You can customize this email by changing the email attribute from true to an object. This object can have several properties, including verificationEmailStyle, verificationEmailSubject, and verificationEmailBody. 

For example, you can set the verificationEmailStyle to "CODE" and specify a custom subject and body for the email. The verificationEmailBody is a function that takes a createCode function as an argument, which generates the verification code. You can use this code in the email body.

In React, you can achieve this by modifying the auth settings as follows:
```javascript
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
    email: {
      verificationEmailStyle: "CODE",
      verificationEmailSubject: "Welcome to my app!",
      verificationEmailBody: (createCode) => `Use this code to confirm your account: ${createCode()}`,
    },
  },
})
```

You can also customize the invitation email that is sent to users when you set up a user account on their behalf in the Amplify console. To do this, you can override the userInvitation attribute of the email object. This attribute has two properties: emailSubject and emailBody. The emailBody is a function that takes two arguments: user and code. These arguments are functions that must be called to get the user's username and temporary password.

In React, you can customize the invitation email as follows:
```javascript
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
    email: {
      verificationEmailStyle: "CODE",
      verificationEmailSubject: "Welcome to my app!",
      verificationEmailBody: (createCode) => `Use this code to confirm your account: ${createCode()}`,
      userInvitation: {
        emailSubject: "Welcome to my app!",
        emailBody: (user, code) =>
          `We're happy to have you! You can now login with username ${user()} and temporary password ${code()}`,
      },
    },
  },
})
```

You can customize Amplify Auth's behavior using triggers. A trigger is a function that executes during the authentication flow. This allows you to add custom logic, such as validating email domains, adding users to groups, or creating user profiles upon account confirmation.

Triggers are essentially Cognito user pool Lambda triggers. When a Lambda trigger is assigned to your user pool, Amazon Cognito interrupts its default flow and requests information from your function. It generates a JSON event containing user request information, such as creating a user account, signing in, resetting a password, or updating an attribute. Your function can then take action or send the event back unmodified.

To get started with triggers in a React application, you would define a function and specify the triggers property on your auth resource. Here is an example of how to do this in React:

```javascript
import { defineAuth } from "@aws-amplify/backend";

const auth = defineAuth({
  loginWith: {
    email: true,
  },
  triggers: {}
});
```

You can learn more about use cases for triggers by visiting the Functions examples. This will provide you with more information on how to implement triggers in your React application.

Apple requires app developers to provide the data usage policy of the app when submitting their app to the App Store. The Amplify Library is used to interact with AWS resources and gathers API usage metrics from the AWS services accessed. This process involves adding a user agent to the request made to the AWS service, which includes information about the Amplify Library version, operating system name, and version. AWS collects this data to generate metrics related to library usage, but it is not linked to the user's identity and not used for tracking purposes.

The Amplify Library collects various types of data, which can be categorized into several groups. These groups include contact info, user content, identifiers, and other data. The contact info group includes data such as name, email address, and phone number, which are linked to the user's identity and used for app functionality. The user content group includes data such as photos or videos and audio data, which are not linked to the user's identity and used for app functionality.

The identifiers group includes data such as user ID and device ID, which are linked to the user's identity and used for app functionality and analytics. The other data group includes data such as OS version, OS name, locale info, app version, and network information, which are not linked to the user's identity and used for analytics and app functionality.

Some Amplify categories, such as Analytics and Auth, persist data to the local device. This data is automatically removed when a user uninstalls the app from the device. However, Amplify stores Auth information in the local system keychain, which does not guarantee any particular behavior around whether data is removed when an app is uninstalled.

To clear auth information, app developers should decide when to clear the data by signing out. One strategy for accomplishing this would be to detect whether or not the app is launching for the first time and invoke Auth.signOut() if the app has not been launched before. In a React application, this could be implemented using the following code:
```
import { Auth } from '@aws-amplify/auth';

// Detect whether or not the app is launching for the first time
const isFirstLaunch = localStorage.getItem('isFirstLaunch') === null;

if (isFirstLaunch) {
  // Invoke Auth.signOut() if the app has not been launched before
  Auth.signOut();
  localStorage.setItem('isFirstLaunch', 'false');
}
```

Microsoft Entra ID can be used as a SAML provider with Amazon Cognito. To integrate Entra ID, you can sign in with your existing enterprise users and maintain profiles unique to the Amplify Auth resource. 

To configure Entra ID, start by defining your auth resource with the appropriate redirect URIs. You can do this by using the Amplify CLI to create an auth resource with the necessary configuration.

Next, deploy your changes to your personal cloud sandbox using the Amplify CLI. This will generate a domain that you can use to configure your new Entra ID App.

To set up Microsoft Entra ID, navigate to the Azure portal and select Entra ID. Create a new enterprise application and choose to integrate any other application that is not in the gallery. Specify a name for the application and choose to integrate a non-gallery application.

Configure Single Sign-on with SAML by selecting the Single sign-on option and then selecting SAML. You will need to populate the Basic SAML Configuration step with the appropriate values, including the Identifier (Entity ID) and Reply URL (Assertion Consumer Service URL).

The Identifier (Entity ID) should be in the format `urn:amazon:cognito:sp:<your-cognito-user-pool-id>`, and the Reply URL should be in the format `https://<your-cognito-domain>/saml2/idpresponse`.

You can find the necessary values in the `amplify_outputs.json` file, which is generated when you deploy your changes to your personal cloud sandbox.

Once you have configured the Basic SAML Configuration step, you can save the configuration and proceed to the SAML Certificates section. Copy the App Federation Metadata Url, which you will need to configure your auth resource with the new SAML provider.

To configure your backend with Entra ID, you will need to update your auth resource configuration to include the SAML provider. You can do this by adding a new external provider to your auth resource configuration, with the name `MicrosoftEntraIDSAML` and the metadata content set to the App Federation Metadata Url that you copied earlier.

You can also optionally upload the Cognito Signing Certificate to Azure, which can be done by navigating to your Cognito User Pool and selecting the identity provider that you created earlier.

Finally, to connect your frontend to Entra ID, you can use the `signInWithRedirect` function from the Amplify Auth library, and specify the provider name as `MicrosoftEntraIDSAML`. 

For example, in React:
```javascript
import { signInWithRedirect } from "aws-amplify/auth"

signInWithRedirect({
  provider: { custom: "MicrosoftEntraIDSAML" }
})
```
This will redirect the user to the Entra ID login page, where they can sign in with their Entra ID credentials. Once they have signed in, they will be redirected back to your application, where they can access protected resources.

To grant access to auth resources in Amplify Auth, you can define an `access` property that allows other resources to interact with auth by specifying actions. 

This is typically done when defining and configuring your auth resource. 

Here's an example of how to define and configure your auth resource in a React application:
```javascript
const auth = {
  loginWith: {
    email: true,
  },
  access: (allow) => [
    allow.resource('addUserToGroup').to(['addUserToGroup'])
  ],
}
```
When you grant a function access to another resource in your Amplify backend, it will configure environment variables for that function to make SDK calls to the AWS services it has access to. 

These environment variables are typed and available as part of the `env` object.

Here's a list of available actions that can be used in the `access` property:

* manageUsers: Grants CRUD access to users in the UserPool
* manageGroupMembership: Grants permission to add and remove users from groups
* manageGroups: Grants CRUD access to groups in the UserPool
* manageUserDevices: Manages devices registered to users
* managePasswordRecovery: Grants permission to reset user passwords
* addUserToGroup: Grants permission to add any user to any group
* createUser: Grants permission to create new users and send welcome messages via email or SMS
* deleteUser: Grants permission to delete any user
* deleteUserAttributes: Grants permission to delete attributes from any user
* disableUser: Grants permission to deactivate any user
* enableUser: Grants permission to activate any user
* forgetDevice: Grants permission to deregister any user's devices
* getDevice: Grants permission to get information about any user's devices
* getUser: Grants permission to look up any user by user name
* listUsers: Grants permission to list users and their basic details in the UserPool
* listDevices: Grants permission to list any user's remembered devices
* listGroupsForUser: Grants permission to list the groups that any user belongs to
* listUsersInGroup: Grants permission to list users in the specified group
* removeUserFromGroup: Grants permission to remove any user from any group
* resetUserPassword: Grants permission to reset any user's password
* setUserMfaPreference: Grants permission to set any user's preferred MFA method
* setUserPassword: Grants permission to set any user's password
* setUserSettings: Grants permission to set user settings for any user
* updateDeviceStatus: Grants permission to update the status of any user's remembered devices
* updateUserAttributes: Grants permission to updates any user's standard or custom attributes

Each action corresponds to specific Cognito IAM actions that are granted when the action is allowed.

Amplify Auth enables you to track devices your users use for auditing, MFA, and more. Before you begin, it is essential to understand the terminology for device statuses:
- Tracked: Every time the user signs in with a new device, the client is given the device key at the end of a successful authentication event. We use this device key to generate a salt and password verifier which is used to call the ConfirmDevice API. At this point, the device is considered to be tracked. Once the device is in a tracked state, you can use the Amazon Cognito console to see the time it started to be tracked, last authentication time, and other information about that device.
- Remembered: Remembered devices are also tracked. During user authentication, the device key and secret pair assigned to a remembered device is used to authenticate the device to verify that it is the same device that the user previously used to sign in.
- Not Remembered: A not-remembered device is a tracked device where Cognito has been configured to require users to "Opt-in" to remember a device, but the user has not opted in to having the device remembered. This use case is used for users signing into their application from a device that they don't own.
- Forgotten: A forgotten device is one removed from being remembered.

Note that device tracking and remembering features are not available when using federating sign-in with external providers as devices are tracked on the upstream identity provider. These features are also not available when using Cognito's Hosted UI.

To remember devices in a React application, you can use the following code:
```javascript
import { rememberDevice } from 'aws-amplify/auth';

await rememberDevice();
```

To forget devices in a React application, note that forgotten devices are neither remembered nor tracked. You can use the following code:
```javascript
import { forgetDevice } from 'aws-amplify/auth';

await forgetDevice();
```

To fetch a list of remembered devices in a React application, you can use the following code:
```javascript
import { fetchDevices } from 'aws-amplify/auth';

const output = await fetchDevices();
```

You can now set up devices to be remembered, forgotten, and fetched in your React application.

Amplify Auth provides a secure way for your users to change their password or recover a forgotten password. 

By default, your users can retrieve access to their accounts if they forgot their password by using either their phone or email. The default account recovery methods are as follows: 
- If `phone` is used as a login option, the user account verification channel is their phone number.
- If `email` is used as a login option, the user account verification channel is their email.
- If both `email` and `phone` are used as login options, the user account verification channel is their email.

To reset a user's password, you can use the `resetPassword` API. This API sends a reset code to the user based on their settings. 

Here is a React code example of how to reset a user's password:
```javascript
import { resetPassword } from 'aws-amplify/auth';

const resetUserPassword = async () => {
  try {
    const output = await resetPassword({
      username: "hello@mycompany.com"
    });

    const { nextStep } = output;
    switch (nextStep.resetPasswordStep) {
      case 'CONFIRM_RESET_PASSWORD_WITH_CODE':
        const codeDeliveryDetails = nextStep.codeDeliveryDetails;
        console.log(`Confirmation code was sent to ${codeDeliveryDetails.deliveryMedium}`);
        // Collect the confirmation code from the user and pass to confirmResetPassword.
        break;
      case 'DONE':
        console.log('Successfully reset password.');
        break;
    }
  } catch (error) {
    console.log('Error resetting password:', error);
  }
};
```

After sending the reset code, you need to confirm the password reset using the `confirmResetPassword` API. This API takes the username, new password, and the confirmation code as parameters.

Here is a React code example of how to confirm the password reset:
```javascript
import { confirmResetPassword } from 'aws-amplify/auth';

const confirmPasswordReset = async () => {
  try {
    await confirmResetPassword({
      username: "hello@mycompany.com",
      confirmationCode: "123456",
      newPassword: "hunter3",
    });
    console.log('Password reset confirmed');
  } catch (error) {
    console.log('Error confirming password reset:', error);
  }
};
```

You can also update a signed-in user's password using the `updatePassword` API. This API takes the old password and the new password as parameters.

Here is a React code example of how to update a user's password:
```javascript
import { updatePassword } from 'aws-amplify/auth';

const updateCurrentUserPassword = async () => {
  try {
    await updatePassword({
      oldPassword: "hunter2",
      newPassword: "hunter3",
    });
    console.log('Password updated successfully');
  } catch (error) {
    console.log('Error updating password:', error);
  }
};
```

You can override the default user account verification channel by modifying the `accountRecovery` setting in the `auth` resource.

Here is a code example of how to override the default user account verification channel:
```javascript
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true
  },
  accountRecovery: 'EMAIL_ONLY'
});
```

You can also customize the password policy by modifying the `passwordPolicy` setting in the `cfnUserPool` resource.

Here is a code example of how to override the default password policy:
```javascript
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';

const backend = defineBackend({
  auth,
});

const { cfnUserPool } = backend.auth.resources.cfnResources;

cfnUserPool.policies = {
  passwordPolicy: {
    minimumLength: 32,
    requireLowercase: true,
    requireNumbers: true,
    requireSymbols: true,
    requireUppercase: true,
    temporaryPasswordValidityDays: 20,
  },
};
```

WebAuthn registration and authentication are not currently supported on React Native, other passwordless features are fully supported.

Amplify Auth enables your users to associate, keep track of, and delete passkeys. To register a passkey, the user must be authenticated and have at least one other first-factor authentication mechanism associated with their account.

You can associate a passkey using the following code:
```javascript
import { associateWebAuthnCredential } from 'aws-amplify/auth';

await associateWebAuthnCredential();
```
This will prompt the user to register a passkey using their local authenticator, which will then be associated with Cognito.

To list registered passkeys, you can use the following code:
```javascript
import { listWebAuthnCredentials } from 'aws-amplify/auth';

const result = await listWebAuthnCredentials();

for (const credential of result.credentials) {
  console.log(`Credential ID: ${credential.credentialId}`);
  console.log(`Friendly Name: ${credential.friendlyCredentialName}`);
  console.log(`Relying Party ID: ${credential.relyingPartyId}`);
  console.log(`Created At: ${credential.createdAt}`);
}
```
To delete a passkey, you can use the following code:
```javascript
import { deleteWebAuthnCredential } from 'aws-amplify/auth';

const id = "credential-id-to-delete";

await deleteWebAuthnCredential({
  credentialId: id
});
```
Here is a practical example that uses the list and delete APIs together. In this example, the user has 3 passkeys registered. They want to list all passkeys while using a `pageSize` of 2 as well as delete the first passkey in the list.
```javascript
import { 
  listWebAuthnCredentials,
  deleteWebAuthnCredential
} from 'aws-amplify/auth';

let passkeys = [];

const result = await listWebAuthnCredentials({ pageSize: 2 });

passkeys.push(...result.credentials);

const nextPage = await listWebAuthnCredentials({
  pageSize: 2,
  nextToken: result.nextToken,
});

passkeys.push(...nextPage.credentials);

const id = passkeys[0].credentialId;

await deleteWebAuthnCredential({
  credentialId: id
});
```

To manage users with Admin Actions in Amplify Auth, you can use the AWS SDK's `@aws-sdk/client-cognito-identity-provider` package. This package is intended for server-side use and can be used within a Function. One example of using this package is with the `addUserToGroup` action, which can be defined as a custom mutation.

First, create an "ADMINS" group that will be used to authorize the mutation. This is done by defining authentication settings that include the creation of the "ADMINS" group.

Next, create a Function resource named "add-user-to-group". This function will be used to handle the `addUserToGroup` mutation.

Then, in your authentication resources, grant access for the "add-user-to-group" function to perform the `addUserToGroup` action. This involves specifying the function and the action it is allowed to perform.

After that, define the custom mutation for `addUserToGroup`. This mutation will use the "add-user-to-group" function resource and can only be called by a user in the "ADMINS" group. The mutation takes two arguments: the user ID and the group name.

Finally, create the handler for the "add-user-to-group" function using the AWS SDK's `@aws-sdk/client-cognito-identity-provider` package. The handler function will add a user to a group using the `AdminAddUserToGroupCommand`.

To use the `addUserToGroup` mutation in your React frontend, you can generate a client using the Amplify data API and then call the mutation with the group name and user ID. Here's an example of how to call the mutation:

```javascript
import Amplify from 'aws-amplify';
import { API } from 'aws-amplify';

// Initialize Amplify
Amplify.configure({
  // your configuration
});

// Generate the client
const apiName = 'your-api-name';
const api = API.graphql({ apiName });

// Call the mutation
const variables = {
  groupName: 'ADMINS',
  userId: '5468d468-4061-70ed-8870-45c766d26225',
};

const mutation = `
  mutation AddUserToGroup($groupName: String!, $userId: String!) {
    addUserToGroup(groupName: $groupName, userId: $userId)
  }
`;

api.graphql({
  query: mutation,
  variables,
});
```

This will add the specified user to the "ADMINS" group using the `addUserToGroup` mutation.

The User management page in the Amplify console provides a user-friendly interface for managing your application's users. You can create and manage users and groups, edit user attributes, and suspend users. 

If you have not yet created an auth resource, you should visit the Auth setup guide to learn how to set this up.

To access the User management page, log in to the Amplify console and choose your app. Select the branch you would like to access, then select Authentication from the left navigation bar, and finally select User management.

To create a user, go to the User management page and select the Users tab. Then select Create user and enter a unique identifier, such as an email address, username, or phone number, and a temporary password. Choose Create user to create the new user. 

A user can be confirmed by using pre-built UI components and Amplify libraries in your React application. For example, you can use the Auth library to confirm a user:
```javascript
import { Auth } from 'aws-amplify';

Auth.confirmSignUp(username, code);
```

To create a group, go to the User management page and choose the Groups tab. Then choose Create group and enter a name for the group. Choose Create group to create the new group.

To add users to a group, go to the User management page and choose the Groups tab. Select the name of the group to add users to, then choose Add users. Choose how you want to search for users to add from the Search menu, add one or multiple users, and then choose Add users.

To delete a group, go to the User management page and choose the Groups tab. Select the name of the group to delete, then choose Delete. A confirmation window will be displayed, enter Delete and choose Confirm deletion to delete the group.

Amplify Auth provides default settings for Amazon Cognito resource definitions. You can customize your authentication resource using AWS Cloud Development Kit (CDK) to make it behave exactly as needed for your use cases.

To override the password policy, you can use the CDK construct and add a property override. For example, you can modify the password policy to require a minimum length of 10 characters, lowercase letters, numbers, symbols, and uppercase letters, and set the temporary password validity to 20 days.

To override the Cognito UserPool multi-factor authentication options, you need to modify the underlying CDK construct. First, ensure your auth resource configuration includes a compatible account recovery option and a custom SES sender. Then, extend the underlying CDK construct by activating Amazon Cognito's Advanced Security Features (ASF) and add EMAIL_OTP to the enabled MFA options.

You can also modify the Cognito UserPool to enable passwordless sign-in methods. This can be done by modifying the underlying Cognito user pool resource to allow sign in with passwordless methods, such as web authentication, email OTP, or SMS OTP.

Here are some examples of how you can achieve this in your React code:

To override the password policy:
```typescript
const cfnUserPool = backend.auth.resources.cfnResources.cfnUserPool;
cfnUserPool.policies = {
  passwordPolicy: {
    minimumLength: 10,
    requireLowercase: true,
    requireNumbers: true,
    requireSymbols: true,
    requireUppercase: true,
    temporaryPasswordValidityDays: 20,
  },
};
```

To override the Cognito UserPool multi-factor authentication options:
```typescript
const { cfnUserPool } = backend.auth.resources.cfnResources;
cfnUserPool.userPoolAddOns = {
  advancedSecurityMode: "AUDIT",
};
cfnUserPool.enabledMfas = [...(cfnUserPool.enabledMfas || []), "EMAIL_OTP"];
```

To override the Cognito UserPool to enable passwordless sign-in methods:
```typescript
const { cfnResources } = backend.auth.resources;
const { cfnUserPool, cfnUserPoolClient } = cfnResources;
cfnUserPool.addPropertyOverride(
  'Policies.SignInPolicy.AllowedFirstAuthFactors',
  ['PASSWORD', 'WEB_AUTHN', 'EMAIL_OTP', 'SMS_OTP']
);
cfnUserPoolClient.explicitAuthFlows = [
  'ALLOW_REFRESH_TOKEN_AUTH',
  'ALLOW_USER_AUTH'
];
cfnUserPool.addPropertyOverride('WebAuthnRelyingPartyID', '<RELYING_PARTY>');
cfnUserPool.addPropertyOverride('WebAuthnUserVerification', 'preferred');
```

To move your Amplify Auth resources to production, you need to configure them to handle production workloads. By default, Amplify Auth provisions Amazon Cognito resources with limited capabilities for sending email and SMS messages, which is sufficient for developing your application but not for production. 

For email, Cognito has a default email functionality that limits the number of emails that can be sent in one day. To handle production workloads, you can configure Cognito to send emails using Amazon Simple Email Service (Amazon SES). However, new AWS accounts default to a "sandbox" status with Amazon SES, which means you can only send emails to verified email addresses and domains. 

To get started with Amazon SES in production, you need to request production access, which can take up to 24 hours to process. After your account is configured for production access and you have verified your sender email, you can configure your Cognito user pool to send emails using the verified sender. 

Here is an example of how to configure your auth resource to send emails using Amazon SES in a React application:
```javascript
import Amplify from 'aws-amplify';

Amplify.configure({
  Auth: {
    loginWith: {
      email: true,
    },
    senders: {
      email: {
        fromEmail: "registrations@example.com",
      },
    },
  },
});
```
You can also customize the display name of the sender and optionally apply a custom address for your users to reply. 
```javascript
import Amplify from 'aws-amplify';

Amplify.configure({
  Auth: {
    loginWith: {
      email: true,
    },
    senders: {
      email: {
        fromEmail: "registrations@example.com",
        fromName: "MyApp",
        replyTo: "inquiries@example.com"
      },
    },
  },
});
```
For SMS authentication codes, you need to request an origination number, which will be used to send authentication codes. If your AWS account is in the SMS sandbox, you also need to add a destination phone number. You can check if your AWS account is in the SMS sandbox by going to the Amazon SNS console and checking the status under the Account information section. 

Note that this process is specific to AWS Amplify and Amazon Cognito, and the code examples provided are for a React application.

Amplify Auth is powered by Amazon Cognito, a robust user directory service that handles user registration, authentication, account recovery, and other operations. To get started with defining your authentication resource, you need to open or create the auth resource file. 

By default, your auth resource is scaffolded using email as the default login mechanism. You can also configure your auth resource to allow signing in with phone numbers or an external provider such as Google, Facebook, Amazon, or Sign in with Apple. At a minimum, you will need to pass a loginWith value to set up how your users sign in to your app. Signing in with email and password is configured by default if you do not provide any value.

To deploy your auth resource, run the command `npx ampx sandbox` in your terminal. This command creates your resource in your personal cloud sandbox and generates an outputs file (amplify_outputs.json) to enable your frontend app to connect to your backend resources.

After a successful deployment, you can connect your application code to your auth resource. Amplify's Authenticator UI component streamlines this process by enabling you to rapidly build the entire authentication flow for your app. The component works seamlessly with the configuration in your auth resource file to automatically connect with your backend resources.

To use the Authenticator component, you need to install the required library for your platform. For React, you can install the @aws-amplify/ui-react library using the command `npm add @aws-amplify/ui-react`. Then, you can add the Authenticator component to your app and configure it to use your auth resource.

Here is an example of how to use the Authenticator component in a React app:
```typescript
import { Authenticator } from '@aws-amplify/ui-react';
import Amplify from 'aws-amplify';
import outputs from '@/amplify_outputs.json';
import '@aws-amplify/ui-react/styles.css';

Amplify.configure(outputs);

export default function App() {
  return (
    <Authenticator>
      {({ signOut, user }) => (
        <main>
          <h1>Hello {user?.username}</h1>
          <button onClick={signOut}>Sign out</button>
        </main>
      )}
    </Authenticator>
  );
};
```
You can also customize the Authenticator component to adjust colors and styling as needed. Once you add the Authenticator component to your app, you can test the sign-up, sign-in, and sign-out functionality.

In addition to React, Amplify provides Authenticator components for other platforms, including Vue, Angular, React Native, Flutter, Android, and Swift. You can follow the same process to install and configure the Authenticator component for your platform.

After setting up authentication in your Amplify app, you may also want to add some additional features, such as learning more about authentication concepts or moving to production.

To enable sign-in with a web UI using Amazon Cognito Auth plugin, follow these steps:

First, ensure you have an app set up according to the getting started walkthrough. 

When configuring social sign-in, exercise caution when designating attributes as "required" because different social identity providers have varied scopes in terms of the information they respond back to Cognito with. User pool attributes that are initially set up as "required" cannot be changed later and may require you to migrate the users or create a new user pool.

The Cognito plugin currently supports the Authorization Code Grant OAuth Flow. To configure Auth, update the auth configuration to include external providers with callback and logout URLs.

For Android, update the AndroidManifest.xml file by adding an activity and intent filter with the redirect URI scheme.

For iOS, update the Info.plist file by adding a URL scheme for the redirect URI. You may also need to enable Keychain Sharing capability in Xcode.

To launch web UI sign-in, use the `signInWithWebUI` method from the Amplify Auth API, passing in the presentation anchor, such as the main window of the app. The `signInWithWebUI` method returns a result indicating whether the sign-in was successful.

You can also specify a provider, such as Google or Facebook, when calling `signInWithWebUI`. Additionally, on iOS, you can set the `preferPrivateSession` flag to true to bypass the permissions dialog during sign-in and sign-out, but this will prevent reuse of existing sessions from the user's browser.

For Flutter, the setup is similar, but you need to configure the platform-specific setup for Android, iOS, macOS, Windows, and Linux. You can then call the `signInWithWebUI` method to launch the web UI sign-in flow.

Here's an example of how to call `signInWithWebUI` in React:
```javascript
import Amplify from 'aws-amplify';
import Auth from '@aws-amplify/auth';

// Configure Auth
Auth.configure({
  // Your Auth configuration
});

// Launch web UI sign-in
const signIn = async () => {
  try {
    const result = await Auth.signInWithWebUI();
    console.log('Sign in result:', result);
  } catch (error) {
    console.log('Error signing in:', error);
  }
};
```
Note that this example assumes you have already set up Amplify and Auth in your React application.

For advanced use cases where Amplify does not provide the functionality, you can retrieve an escape hatch to access the underlying Amazon Cognito client.

To access the escape hatch in React, you would use the AWS Amplify Auth API to get the AWSCognitoAuthPlugin instance and then retrieve the escape hatch.

Here is a React example of how to get the escape hatch:
```javascript
import { Auth } from 'aws-amplify';

const getEscapeHatch = async () => {
  try {
    const authPlugin = await Auth.getPlugin('awsCognitoAuthPlugin');
    const escapeHatch = authPlugin.getEscapeHatch();
    // Use the escape hatch to access the underlying Amazon Cognito client
    const cognitoIdentityProviderClient = escapeHatch.cognitoIdentityProviderClient;
    // Use the cognitoIdentityProviderClient to make requests to Amazon Cognito
  } catch (error) {
    console.error('Error getting escape hatch:', error);
  }
};
```
You can then use the escape hatch to access the underlying Amazon Cognito client and make requests to Amazon Cognito. For example, to resend a confirmation code:
```javascript
const resendCodeUsingEscapeHatch = async () => {
  try {
    const authPlugin = await Auth.getPlugin('awsCognitoAuthPlugin');
    const escapeHatch = authPlugin.getEscapeHatch();
    const cognitoIdentityProviderClient = escapeHatch.cognitoIdentityProviderClient;
    const request = {
      ClientId: 'xxxxxxxxxxxxxxxx',
      Username: 'user1',
    };
    const response = await cognitoIdentityProviderClient.resendConfirmationCode(request);
    console.log('Response:', response);
  } catch (error) {
    console.error('Error resending code:', error);
  }
};
```

You can configure Amplify Auth to use an existing Amazon Cognito user pool and identity pool. If you are in a team setting or part of a company that has previously created auth resources, you can configure the client library directly or maintain references with AWS Cloud Development Kit (AWS CDK) in your Amplify backend. 

When using existing auth resources, you may need to add additional policies or permissions for your authenticated and unauthenticated IAM roles, and these changes must be performed manually.

To use existing resources without an Amplify backend, you can configure the client library directly. For example, in a React application, you can configure Amplify like this:
```javascript
import Amplify from 'aws-amplify';

Amplify.configure({
  Auth: {
    Cognito: {
      userPoolId: "<your-cognito-user-pool-id>",
      userPoolClientId: "<your-cognito-user-pool-client-id>",
      identityPoolId: "<your-cognito-identity-pool-id>",
      loginWith: {
        email: true,
      },
      signUpVerificationMethod: "code",
      userAttributes: {
        email: {
          required: true,
        },
      },
      allowGuestAccess: true,
      passwordFormat: {
        minLength: 8,
        requireLowercase: true,
        requireUppercase: true,
        requireNumbers: true,
        requireSpecialCharacters: true,
      },
    },
  },
})
```

If you have created Amazon Cognito resources outside of the context of your Amplify app, you can use `referenceAuth` to reference the existing resources. It requires a user pool, a user pool client, identity pool, and an authenticated and unauthenticated IAM role configured on your identity pool.

To reference existing resources in a React application, you would typically do this in your Amplify backend configuration. For example:
```javascript
import { referenceAuth } from '@aws-amplify/backend';

export const auth = referenceAuth({
  userPoolId: 'us-east-1_xxxx',
  identityPoolId: 'us-east-1:b57b7c3b-9c95-43e4-9266-xxxx',
  authRoleArn: 'arn:aws:iam::xxxx:role/amplify-xxxx-mai-amplifyAuthauthenticatedU-xxxx',
  unauthRoleArn: 'arn:aws:iam::xxxx:role/amplify-xxxx-mai-amplifyAuthunauthenticate-xxxx',
  userPoolClientId: 'xxxx',
});
```

The configuration of your referenced resources cannot be modified. However, you can grant permissions to your auth resource from other Amplify backend resources using the `access` property.

You can also reference different sets of auth resources depending on the deployment context by using environment variables. 

Finally, to connect your frontend to the auth resources, you would need to follow the instructions for connecting your frontend, which can be found in the next steps section.

To generate React code directly from Figma, you can use the Amplify UI Figma file and the Amplify UI Builder plugin. 

First, you need to duplicate the Amplify UI Figma file. This file contains several pages, including a README page that explains how to use the Figma file to create new components, theme primitives, and customize layout and styling. 

The Theme page displays the theme values and design tokens used to style the primitives. If you want to make changes to the theme, you should use the Amplify UI Builder Figma plugin. 

The Primitives page contains building-block components such as alerts, buttons, and badges. These primitives correspond to the Amplify UI primitives and can be exported to code with all their properties. 

The My components page contains custom components built using the primitives. You can customize the provided components or build your own. 

To generate React code, you need to run the Amplify UI Builder Figma plugin. You can do this in dev mode or non-dev mode. 

In dev mode, you turn on Figma dev mode, select the AWS Amplify UI Builder plugin, and choose a layer in your file to get React code and a live preview of the generated code. 

In non-dev mode, you select the AWS Amplify UI Builder plugin and choose Download component code to download the React code for your components. 

For example, if you were to generate a button component, the React code might look like this:
```jsx
import React from 'react';

const Button = () => {
  return (
    <button>
      Click me
    </button>
  );
};

export default Button;
```
You should follow the instructions in the README page of the Figma file to learn how to create your components and optimize for code quality.

To customize the form inputs generated by Amplify, you can override properties of individual input components. The generated form provides a mechanism to override properties for each input component, such as TextField, TextAreaField, and SelectField. You can override any props to those components with the `overrides` prop on the form component.

For example, if you want to change the variation and label of the `content` field in the TodoCreateForm, you can do so like this:
```jsx
<TodoCreateForm
  overrides={{
    content: {
      variation: 'quiet',
      label: 'Todo'
    }
  }}
/>
```
It's not recommended to override properties that are already set by the generated form, as this could lead to unexpected behavior during runtime. You can verify the set properties by navigating to the component in the `src/ui-components/[your-form-component].jsx` file.

To customize the form, you can manually add a form input field connected to a data model. For example, let's say you add a `priority` field to your data model. You can make the following edits to the generated form:
```jsx
const initialValues = {
  content: "",
  priority: ""
};

const [priority, setPriority] = React.useState(initialValues.priority);

const resetStateValues = () => {
  setPriority(initialValues.priority)
  setErrors({});
};

const validations = {
  content: [],
  priority: []
};

const onSubmit = async (event) => {
  event.preventDefault();
  let modelFields = {
    content: content,
    priority: priority
  };
  // submit the form
};

// Add TextField
<TextField
  label="Priority"
  isRequired={false}
  isReadOnly={false}
  value={priority}
  onChange={(e) => {
    let { value } = e.target;
    setPriority(value);
  }}
  onBlur={() => runValidationTasks("priority", priority)}
  errorMessage={errors.priority?.errorMessage}
  hasError={errors.priority?.hasError}
  {...getOverrideProps(overrides, "priority")}
/>
```
You can also manually add option fields, such as Select Fields, Radio Group Fields, and Autocomplete Fields, by replacing the `<TextField>` with the respective component.

To configure form spacings, you can add spacing to your form and between inputs using the `overrides` prop.
```jsx
<TodoCreateForm overrides={{
  TodoCreateForm: {
    rowGap: 'xl',
    columnGap: 'xs',
    padding: 'xl'
  }
}} />
```
You can customize the label for Submit and Clear buttons using the `overrides` prop.
```jsx
<TodoCreateForm overrides={{
  ClearButton: {
    children: 'Close'
  },
  SubmitButton: {
    children: 'Save todo'
  }
}} />
```
You can also toggle the visibility of action buttons using the `overrides` prop.
```jsx
<TodoCreateForm overrides={{
  ClearButton: {
    display: 'none'
  },
  SubmitButton: {
    display: 'none'
  }
}} />
```
If you hide all form action buttons, you can still manage the form lifecycle using the `onChange` event handler.
```jsx
<TodoCreateForm
  onChange={(fields) => {
    console.log({ fields })
    return fields
  }}
/>
```

Connected forms in AWS Amplify Gen 2 are forms that are bound to a model in your app's data schema. When a connected form is submitted, it automatically creates or updates a record in the bound data model, mapping some or all of the form's input fields to fields in the data model. These forms work seamlessly with any Amplify GraphQL API and do not require `onSubmit` handling.

To generate connected forms, you need to install the Amplify UI library by running `npm add @aws-amplify/ui-react` in your terminal. Then, deploy a data model from your sandbox environment and run `npx ampx generate forms` from your project root. This command generates create and update forms for each model defined in your schema, which can be found in the `ui-components` folder.

If you update your data model and need to regenerate the forms, make sure to back up the original `ui-components` folder before running `npx ampx generate forms` again.

To render a React form in your app, start by adding the necessary imports and configuration to your application's entrypoint file. This includes importing the `@aws-amplify/ui-react` styles and `ThemeProvider`, as well as configuring Amplify with your `amplify_outputs.json` file.

Next, wrap your `<App />` component with the `ThemeProvider` component to apply the Amplify UI theme. Then, import your generated form by name, such as `TodoCreateForm`, and place it in your code where you want the form to render.

There are two types of forms: Create forms and Update forms. Create forms render a form with empty inputs and generate a new record upon submission if connected to a data model. Update forms expect an input value to pre-populate the form and can be connected to a data model using the `id` prop or the model prop.

For example, you can use the `id` prop to update a record like this: `<AuthorUpdateForm id="ac74af5c-3aab-4274-8f41-23e1e6576af5" />`. Alternatively, you can use the model prop to pass a record to the form, like this: `<AuthorUpdateForm author={authorRecord}>`.

To manage a form's lifecycle, you can hook into its lifecycle events to customize user input before submission, run validations, handle errors, or self-manage user input events. The form lifecycle consists of several stages, including initial state, onChange, onValidate, onSubmit, onSuccess, onError, and onCancel.

The initial state is when the inputs are either empty or pre-populated based on a default value. If the user clicks the Clear or Reset button, they will be brought back to this state.

The onChange event is triggered when the form data is changed by the user. This can be used to get the form data after every user input. For example, you can use the onChange event to get the form data in real-time as the user is filling the form.

```jsx
import { useState } from 'react'
import { HomeCreateForm } from './ui-components'

function App() {
  const [formData, setFormData] = useState()

  return (
    <HomeCreateForm onChange={fields => setFormData(fields)}/>
  )
}
```

The onValidate event is used to extend validation rules in code. This event triggers after onChange and can be used to validate the form input against external APIs.

The onSubmit event is triggered when the user clicks the Submit button. This can be used to customize the form data before it is saved to the cloud. For example, you can use the onSubmit event to trim all string data before saving it.

```jsx
<HomeCreateForm
    onSubmit={(fields) => {
        const updatedFields = {}
        Object.keys(fields).forEach(key => {
            if (typeof fields[key] === 'string') {
                updatedFields[key] = fields[key].trim()
            } else {
                updatedFields[key] = fields[key]
            }
        })
        return updatedFields
    }}
/>
```

The onSuccess event is triggered when the form data has been successfully submitted. This can be used to take an action after the form data has been successfully submitted, such as hiding the form.

```jsx
import { useState } from 'react'
import { HomeCreateForm } from './ui-components'

function App() {
  const [showForm, setShowForm] = useState(true)

  return (
    {showForm &&
      <HomeCreateForm onSuccess={() => {
        setShowForm(false) // Hide the form
      }}/>}
  )
}
```

The onError event is triggered when there is an error during the submit process. This can be used to log the error and present an alert to the user.

```jsx
import { HomeCreateForm } from './ui-components'

function App() {
  return (
    <HomeCreateForm onError={(error) => {
      console.log(error)
    }}/>
  )
}
```

The onCancel event is triggered when the user clicks the Cancel button. This can be used to hide the form or route the user to another page.

```jsx
import { useState } from 'react'
import { HomeCreateForm } from './ui-components'

function App() {
  const [showForm, setShowForm] = useState(true)

  return (
    {showForm &&
      <HomeCreateForm onCancel={() => {
        setShowForm(false) // Hide the form
      }}/>}
  )
}
```

The File Uploader field in Amplify form builder allows users to upload files, which are stored in an Amazon S3 bucket connected to your Amplify app. After uploading, the file's S3 key is stored in your data model, allowing for systematic retrieval.

To use the File Uploader field, your Amplify app must have Authentication and Storage enabled. The File Uploader input allows users to select files from their local device and upload them to an S3 bucket. Files are uploaded immediately upon selection, and an S3 key is generated. By default, File Uploader generates a unique S3 key based on the file uploaded.

To add the File Uploader to your form, you need a data model with an attribute that is either a string or an array of strings. After updating your data model, run `npx ampx generate forms` to generate the form JSX file. Then, replace the existing component with the FileUploader component.

For example, if your attribute is an array of strings, you can replace the ArrayField component with the FileUploader component like this:
```
<FileUploader
  accessLevel="public"
  maxFileCount={10}
  acceptedFileTypes={['image/*']}
  processFile={processFile}
  onUploadSuccess={({key}) => {
    setImages(prevImages => [...prevImages, key])
  }}
  onFileRemove={({key}) => {
    setImages(prevImages => prevImages.filter(img => img!== key))
  }}
/>
```
If your data model has only one image instead of an array of images, you can replace the TextField component with the FileUploader component like this:
```
<FileUploader
  accessLevel="public"
  maxFileCount={1}
  acceptedFileTypes={['image/*']}
  processFile={processFile}
  onUploadSuccess={({key}) => {
    setImage(key)
  }}
  onFileRemove={({key}) => {
    setImage(undefined)
  }}
/>
```
The FileUploader component has several configuration options, including accessLevel, maxFileCount, and acceptedFileTypes.

File Uploader generates a unique S3 key by hashing the file contents to prevent accidental overwriting of files. However, if a form submitter uploads two identical files to the same path, even with different file names, File Uploader will prevent file duplication in your S3 bucket. If the File level access for your File Uploader is set to private or protected, identical files uploaded by separate users will be saved separately. If the File level access is set to public, identical files will overwrite each other.

To validate form data in Amplify generated forms, you can add and customize validation rules. By default, Amplify infers a range of validation rules based on the data model. For example, if you have a field with an `AWSEmail` type, the generated form input will automatically run an email validation rule.

You can configure validation rules for different input types, such as `String`, `Int`, `Float`, `AWSDate`, `AWSTime`, and `AWSDateTime`. The available validation rules for each type include:

* `String`: Start With, End With, Contain, Does not contain, Be less than N characters long, Be at least N characters long
* `Int`, `Float`: Be greater than, Be less than, Be equal to
* `AWSDate`, `AWSTime`, `AWSDateTime`: Be before, Be after

Some types have automatically configured validation rules, such as:
* `AWSIPAddress`: must be a valid IPv4 or IPv6 address
* `AWSURL`: must consist of a schema and a path part
* `AWSEmail`: must be an email address in the format `<local-part>@<domain-part>`
* `AWSJSON`: must be a valid JSON
* `AWSPhone`: must be a phone number that can contain spaces or hyphens to separate digit groups

To add custom validation rules, you can use the `onValidate` event handler. This handler takes an object with validation functions for the fields you want to validate. The validation function must return a validation response with a shape of `{ hasError: boolean, errorMessage?: string }`.

For example, to validate that an `address` field starts with a number:
```jsx
<HomeCreateForm
  onValidate={{
    address: (value, validationResponse) => {
      const firstWord = value.split('')[0];
      if (!isNaN(firstWord)) {
        return {
          hasError: true,
          errorMessage: 'Address must start with a number'
        };
      }
      return validationResponse;
    }
  }}
/>
```

You can also add validation rules for nested JSON data by passing in validation functions in the same nested structure as the data. For example:
```js
<ProductForm
  onValidate={{
    price: {
      currency: (value, validationResponse) => {
        const allowedCurrencies = ['$', '€', '￥', '₹'];
        if (!allowedCurrencies.includes(value)) {
          return {
            hasError: true,
            errorMessage: 'Currency must be either "$", "€", "￥", or "₹".'
          };
        }
        return validationResponse;
      }
    }
  }}
  onSubmit={(fields) => {
    /* handle form data submission */
  }}
/>
```

Additionally, you can call external APIs for asynchronous form validation by returning a Promise in the `onValidate` prop. For example:
```jsx
<AgentContactForm
  onValidate={{
    licenseNumber: (value, validationResponse) => {
      return fetch(`http://localhost:3000/api/agent/${value}`).then(
        (response) => {
          if (response.status!== 200) {
            return {
              hasError: true,
              errorMessage: 'No agent was not found with that license number.'
            };
          }
          return validationResponse;
        }
      );
    }
  }}
  onSubmit={(fields) => {
    /* Handle form submission */
  }}
/>
```

Amplify offers a UI Library that makes it easy to build web app user interfaces connected to the backend. The Amplify UI Library provides connected components designed to work seamlessly with AWS Amplify backend services. These components allow you to quickly add common user experience patterns, such as authentication and storage, without having to build them from scratch.

The UI Library also includes tooling that can generate React forms from data and React components from Figma designs. This tooling is designed to work with React, JavaScript, and Next.js. 

This page is for formatting only

AWS AppSync Apollo Extensions provide a seamless way to connect to your AWS AppSync backend using Apollo client, an open-source GraphQL client. 

To learn more about Apollo, see https://www.apollographql.com/docs/. 

## Features

AWS AppSync Apollo Extensions provide AWS AppSync authorizers to be used with the Apollo client to make it simple to apply the correct authorization payloads to your GraphQL operations.

Additionally, the included Amplify components allow Amplify to provide auth tokens and signing logic for the corresponding Authorizers.

## Install the AWS AppSync Apollo Extensions library

To install the library in a React application, you can use npm or yarn to add the `apollo-appsync-amplify` dependency. 

```bash
npm install apollo-appsync-amplify
```

or 

```bash
yarn add apollo-appsync-amplify
```

Alternatively, if you are not using Amplify, you can install the `apollo-appsync` dependency.

```bash
npm install apollo-appsync
```

or 

```bash
yarn add apollo-appsync
```

## Connecting to AWS AppSync with Apollo client

To connect to AWS AppSync with Apollo client in a React application, you need to create an Apollo client instance and pass it to the ApolloProvider component.

Here is an example of how you can create an Apollo client instance:

```javascript
import { ApolloClient, InMemoryCache } from '@apollo/client';
import { AppSyncAuthTransformer } from 'apollo-appsync-amplify';

const client = new ApolloClient({
  uri: 'https://your-appsync-endpoint.com/graphql',
  cache: new InMemoryCache(),
  transformResponse: AppSyncAuthTransformer,
});
```

You can then pass the client to the ApolloProvider component:

```javascript
import { ApolloProvider } from '@apollo/client';

function App() {
  return (
    <ApolloProvider client={client}>
      // your application code here
    </ApolloProvider>
  );
}
```

## Providing AppSync Authorizers

To provide AppSync authorizers, you need to create an instance of the AppSyncAuth class and pass it to the Apollo client.

Here is an example of how you can create an AppSyncAuth instance:

```javascript
import { AppSyncAuth } from 'apollo-appsync-amplify';

const appSyncAuth = new AppSyncAuth({
  apikey: 'your-api-key',
});
```

You can then pass the appSyncAuth instance to the Apollo client:

```javascript
const client = new ApolloClient({
  uri: 'https://your-appsync-endpoint.com/graphql',
  cache: new InMemoryCache(),
  transformResponse: AppSyncAuthTransformer,
  auth: appSyncAuth,
});
```

## Connecting Amplify Data to Apollo client

To connect Amplify Data to Apollo client, you need to create an instance of the AmplifyAuth class and pass it to the Apollo client.

Here is an example of how you can create an AmplifyAuth instance:

```javascript
import { AmplifyAuth } from 'aws-amplify';

const amplifyAuth = new AmplifyAuth({
  // your amplify configuration here
});
```

You can then pass the amplifyAuth instance to the Apollo client:

```javascript
const client = new ApolloClient({
  uri: 'https://your-appsync-endpoint.com/graphql',
  cache: new InMemoryCache(),
  transformResponse: AppSyncAuthTransformer,
  auth: amplifyAuth,
});
```

## Downloading the AWS AppSync schema

To download the AWS AppSync schema, you can use the AWS AppSync console or the Amplify CLI.

Here is an example of how you can download the schema using the Amplify CLI:

```bash
amplify pull --schema
```

This will download the schema and save it to a file named `schema.json`.

## Generating Queries, Mutations, and Subscriptions for Apollo client

To generate queries, mutations, and subscriptions for Apollo client, you can use the Amplify CLI.

Here is an example of how you can generate queries, mutations, and subscriptions using the Amplify CLI:

```bash
amplify codegen --graphql
```

This will generate the queries, mutations, and subscriptions based on your schema and save them to a file named `graphql.ts`.

## Connecting to AWS AppSync real-time endpoint

To connect to the AWS AppSync real-time endpoint, you need to create an instance of the AppSyncRealTimeClient class and pass it to the Apollo client.

Here is an example of how you can create an AppSyncRealTimeClient instance:

```javascript
import { AppSyncRealTimeClient } from 'apollo-appsync-amplify';

const realTimeClient = new AppSyncRealTimeClient({
  endpoint: 'https://your-appsync-endpoint.com/graphql',
  auth: appSyncAuth,
});
```

You can then pass the realTimeClient instance to the Apollo client:

```javascript
const client = new ApolloClient({
  uri: 'https://your-appsync-endpoint.com/graphql',
  cache: new InMemoryCache(),
  transformResponse: AppSyncAuthTransformer,
  realTime: realTimeClient,
});
```

Note: The above examples are for React applications, and you may need to adjust them according to your specific use case. Additionally, you will need to replace the placeholders (e.g. `https://your-appsync-endpoint.com/graphql`) with your actual AWS AppSync endpoint and credentials.

To connect to AWS AppSync Events using the Amplify library, you need to create a secure and performant serverless WebSocket API that can broadcast real-time event data to millions of subscribers. This feature allows you to build multi-user features such as collaborative document editors, chat apps, and live polling systems.

First, if you don't have an existing Amplify backend, you'll need to create an Event API via the AWS Console and take note of the HTTP endpoint, region, and API Key. Then, you can configure the Amplify library in your React application by providing the Event API endpoint, region, and API Key.

Here's an example of how to configure the Amplify library in a React application:

```jsx
import { Amplify } from 'aws-amplify';
import { events } from 'aws-amplify/data';

Amplify.configure({
  API: {
    Events: {
      endpoint: 'https://your-event-api-endpoint.us-east-1.amazonaws.com/event',
      region: 'us-east-1',
      defaultAuthMode: 'apiKey',
      apiKey: 'your-api-key'
    }
  }
});
```

Next, you can connect to the Event API and subscribe to a channel to receive events in real-time. Here's an example of how to do this in a React application:

```jsx
import { useState, useEffect } from 'react';
import { events } from 'aws-amplify/data';

export default function App() {
  const [myEvents, setMyEvents] = useState([]);

  useEffect(() => {
    let channel;

    const connectAndSubscribe = async () => {
      channel = await events.connect('default/channel');

      channel.subscribe({
        next: (data) => {
          console.log('received', data);
          setMyEvents((prev) => [data,...prev]);
        },
        error: (err) => console.error('error', err)
      });
    };

    connectAndSubscribe();

    return () => channel && channel.close();
  }, []);

  async function publishEvent() {
    await events.post('default/channel', { some: 'data' });
  }

  return (
    <>
      <button onClick={publishEvent}>Publish Event</button>
      <ul>
        {myEvents.map((data) => (
          <li key={data.id}>{JSON.stringify(data.event)}</li>
        ))}
      </ul>
    </>
  );
}
```

If you have an existing Amplify backend, you can add an Event API to it by updating the backend definition. First, you need to add a new Event API to your backend definition using the Amplify CLI. Then, you can deploy the updated backend and connect your frontend application to the Event API.

To add an Event API to an existing Amplify backend, you need to update the backend definition by creating a new stack for the Event API resources and adding a new Event API to the stack. You also need to configure the User Pool as the auth provider for the Event API and attach a policy to the authenticated user role to grant access to the Event API.

Here's an example of how to update the backend definition to add an Event API:

```typescript
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import {
  CfnApi,
  CfnChannelNamespace,
  AuthorizationType,
} from 'aws-cdk-lib/aws-appsync';
import { Policy, PolicyStatement } from 'aws-cdk-lib/aws-iam';

const backend = defineBackend({
  auth,
});

const customResources = backend.createStack('custom-resources');

const cfnEventAPI = new CfnApi(customResources, 'CfnEventAPI', {
  name: 'my-event-api',
  eventConfig: {
    authProviders: [
      {
        authType: AuthorizationType.USER_POOL,
        cognitoConfig: {
          awsRegion: customResources.region,
          userPoolId: backend.auth.resources.userPool.userPoolId,
        },
      },
    ],
    connectionAuthModes: [{ authType: AuthorizationType.USER_POOL }],
    defaultPublishAuthModes: [{ authType: AuthorizationType.USER_POOL }],
    defaultSubscribeAuthModes: [{ authType: AuthorizationType.USER_POOL }],
  },
});

const namespace = new CfnChannelNamespace(
  customResources,
  'CfnEventAPINamespace',
  {
    apiId: cfnEventAPI.attrApiId,
    name: 'default',
  }
);

backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(
  new Policy(customResources, 'AppSyncEventPolicy', {
    statements: [
      new PolicyStatement({
        actions: [
          'appsync:EventConnect',
          'appsync:EventSubscribe',
          'appsync:EventPublish',
        ],
        resources: [`${cfnEventAPI.attrApiArn}/*`, `${cfnEventAPI.attrApiArn}`],
      }),
    ],
  })
);

backend.addOutput({
  custom: {
    events: {
      url: `https://${cfnEventAPI.getAtt('Dns.Http').toString()}/event`,
      aws_region: customResources.region,
      default_authorization_type: AuthorizationType.USER_POOL,
    },
  },
});
```

After deploying the updated backend, you can connect your frontend application to the Event API using the Amplify Authenticator component to sign in to the Cognito User Pool.

Here's an example of how to connect your frontend application to the Event API:

```jsx
import { Amplify } from 'aws-amplify';
import { events, type EventsChannel } from 'aws-amplify/data';
import { Authenticator } from '@aws-amplify/ui-react';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);

export default function App() {
  const [myEvents, setMyEvents] = useState([]);

  useEffect(() => {
    let channel;

    const connectAndSubscribe = async () => {
      channel = await events.connect('default/channel');

      channel.subscribe({
        next: (data) => {
          console.log('received', data);
          setMyEvents((prev) => [data,...prev]);
        },
        error: (err) => console.error('error', err),
      });
    };

    connectAndSubscribe();

    return () => channel && channel.close();
  }, []);

  async function publishEvent() {
    await events.post('default/channel', { some: 'data' });
  }

  return (
    <Authenticator>
      {({ signOut, user }) => (
        <>
          <div>
            <h1>Welcome, {user.username}</h1>
            <button onClick={signOut}>Sign Out</button>
          </div>
          <div>
            <button onClick={publishEvent}>Publish Event</button>
            <ul>
              {myEvents.map((data) => (
                <li key={data.id}>{JSON.stringify(data.event)}</li>
              ))}
            </ul>
          </div>
        </>
      )}
    </Authenticator>
  );
}
```

To connect to Amplify Data from a Next.js server runtime, you need to follow these steps:

First, make sure you have a Next.js application created, Amplify libraries installed and configured for Next.js, and Amplify Data resources deployed or set up using AWS AppSync.

There are two types of data clients for Next.js server runtimes: one that uses cookies and another that uses NextRequest and NextResponse. The choice of data client depends on your Next.js Router and use case.

For the App Router, use the `generateServerClientUsingCookies()` function for React Server Components, Server Actions, and Route Handlers, and `generateServerClientUsingReqRes()` for Middleware.

For the Pages Router, use `generateServerClientUsingReqRes()` for server-side component code, API Routes, and Middleware.

To generate a Data client using cookies, provide your Amplify configuration and the cookies function from Next.js. 

```javascript
import { generateServerClientUsingCookies } from '@aws-amplify/adapter-nextjs/data';
import outputs from './amplify_outputs.json';
import { cookies } from 'next/headers';

const cookieBasedClient = generateServerClientUsingCookies({
  config: outputs,
  cookies,
});
```

To generate a Data client using NextRequest and NextResponse, provide your Amplify configuration. 

```javascript
import { generateServerClientUsingReqRes } from '@aws-amplify/adapter-nextjs/data';
import outputs from './amplify_outputs.json';

const reqResBasedClient = generateServerClientUsingReqRes({
  config: outputs,
});
```

Then, import the generated client in your Next.js React Server Components, Server Actions, or Route Handlers, and make API requests using the client.

```javascript
const fetchTodos = async () => {
  const { data: todos, errors } = await cookieBasedClient.models.Todo.list();

  if (!errors) {
    return todos;
  }
};
```

For NextRequest/NextResponse-based clients, import the client in your Next.js server runtime code and make API requests within the `runWithAmplifyServerContext` function.

```javascript
import { runWithAmplifyServerContext, reqResBasedClient } from './amplifyServerUtils';

type ResponseData = {
  todos: any[];
};

export default async function handler(
  request: any,
  response: any
) {
  const todos = await runWithAmplifyServerContext({
    nextServerContext: { request, response },
    operation: async (contextSpec) => {
      const { data: todos } = await reqResBasedClient.models.Todo.list(
        contextSpec
      );
      return todos;
    },
  });

  response.status(200).json({ todos });
}
```

To connect to Amplify Data from a React application, you will need to set up the Amplify APIs plugin and use the `runWithAmplifyServerContext` adapter. Here's how you can do it:

First, you need to have a React application created and Amplify Data resources deployed. 

To set up the AmplifyAPIs plugin, you will need to create a plugin that registers both client-specific and server-specific Amplify APIs. You can then access these APIs via a context.

Here is an example of how to set up the Amplify APIs plugin in a React application using Next.js:

```javascript
// amplify-apis.js
import Amplify from 'aws-amplify';
import { createClient } from '@aws-amplify/datastore';
import { withSSRContext } from 'aws-amplify';

export const AmplifyAPI = {
  async getAuthSession() {
    const { Auth } = withSSRContext();
    return Auth.currentSession();
  },
};

export default AmplifyAPI;
```

Next, you need to use the `useContext` hook to access the Amplify APIs in your React components.

```javascript
// App.js
import React, { useState, useEffect } from 'react';
import AmplifyAPI from './amplify-apis';

function App() {
  const [user, setUser] = useState(null);

  useEffect(() => {
    AmplifyAPI.getAuthSession().then((session) => {
      setUser(session);
    });
  }, []);

  return (
    <div>
      {user? <p>Welcome, {user.username}!</p> : <p>Please login</p>}
    </div>
  );
}

export default App;
```

For server-side rendering, you can use the `getServerSideProps` function in Next.js to pre-render pages on the server.

```javascript
// pages/index.js
import AmplifyAPI from '../amplify-apis';

export const getServerSideProps = async ({ req }) => {
  const session = await AmplifyAPI.getAuthSession(req);
  return {
    props: {
      user: session,
    },
  };
};

function HomePage({ user }) {
  return (
    <div>
      {user? <p>Welcome, {user.username}!</p> : <p>Please login</p>}
    </div>
  );
}

export default HomePage;
```

To call Amplify APIs in an isolated server context, you can create a helper function that uses the `runWithAmplifyServerContext` function from the `aws-amplify/adapter-core` package.

```javascript
// amplify-utils.js
import { runWithAmplifyServerContext } from 'aws-amplify/adapter-core';
import Amplify from 'aws-amplify';

const amplifyConfig = Amplify.configure();

export const runAmplifyApi = async (operation) => {
  return runWithAmplifyServerContext(amplifyConfig, operation);
};
```

You can then use this helper function to call Amplify APIs in your React components.

```javascript
// App.js
import React, { useState, useEffect } from 'react';
import { runAmplifyApi } from './amplify-utils';

function App() {
  const [user, setUser] = useState(null);

  useEffect(() => {
    runAmplifyApi(async (contextSpec) => {
      const session = await contextSpec.Auth.currentSession();
      setUser(session);
    });
  }, []);

  return (
    <div>
      {user? <p>Welcome, {user.username}!</p> : <p>Please login</p>}
    </div>
  );
}

export default App;
```

To connect your React application code to a backend API using the Amplify Libraries, you need to have a cloud sandbox with an Amplify Data resource up and running, a frontend application set up with the Amplify library installed, and npm installed.

First, configure the Amplify Library by adding the following code to your app's entry point to initialize and configure the Amplify client library:
```typescript
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
```

Next, generate a "Data client" for your frontend code to make fully-typed API requests to your backend. To do this, use the following code:
```typescript
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource';

const client = generateClient<Schema>();
```

You can now use the Data client to make CRUDL operations. For example, to fetch a list of todos, you can use the following code:
```typescript
const fetchTodos = async () => {
  const { data: todos, errors } = await client.models.Todo.list();
};
```

To configure authorization mode, you need to determine how a request should be authorized with the backend. Amplify Data uses the "userPool" authorization by default, which uses the signed-in user credentials to sign an API request. If you use a `allow.publicApiKey()` authorization rule for your data models, you need to use "apiKey" as an authorization mode.

You can set the authorization mode on a per-client basis by specifying the `authMode` parameter on the `generateClient` function. For example:
```typescript
const client = generateClient<Schema>({
  authMode: 'apiKey',
});
```

Alternatively, you can set the authorization mode on each individual API request. For example:
```typescript
const { data: todos, errors } = await client.models.Todo.list({
  authMode: 'apiKey',
});
```

You can also set custom request headers for authorization purposes or to pass additional metadata from your frontend to the backend API. To do this, you can specify a `headers` parameter in the configuration. For example:
```typescript
const client = generateClient<Schema>({
  headers: {
    'My-Custom-Header': 'my value',
  },
});
```

If you have an additional Data endpoint that you're managing with a different Amplify project or through other means, you can utilize that endpoint in your frontend code by specifying the `endpoint` parameter on the `generateClient` function. For example:
```typescript
const client = generateClient({
  endpoint: 'https://my-other-endpoint.com/graphql',
});
```

To connect to an external Amazon DynamoDB data source, you can follow these steps:

First, you need to set up your Amazon DynamoDB table. This involves defining a custom type in your schema and creating an external DynamoDB table to store records for it. 

Next, you need to add your Amazon DynamoDB table as a data source for your API. This can be done in your `amplify/backend.ts` file by creating a new stack and adding the external DynamoDB table as a data source.

After that, you can define custom queries and mutations using the `a.handler.custom()` modifier, which accepts the name of the data source and an entry point for your resolvers. 

You will then need to configure custom business logic handler code for your resolvers. This involves creating JavaScript files that define the custom resolvers for the custom queries and mutations added to your schema.

Finally, you can invoke custom queries or mutations from your generated Data client. The client will have APIs for all your custom queries and mutations under the client.queries and client.mutations properties respectively.

The available DynamoDB operations include GetItem, PutItem, UpdateItem, DeleteItem, Query, Scan, Sync, BatchGetItem, BatchDeleteItem, BatchPutItem, TransactGetItems, and TransactWriteItems. Each operation has its own set of parameters and configurations that can be specified in the request object.

Here's an example of how you might define a custom query in your schema:
```javascript
addPost: a
 .mutation()
 .arguments({
    id: a.id(),
    author: a.string().required(),
    title: a.string(),
    content: a.string(),
    url: a.string(),
  })
 .returns(a.ref("Post"))
 .authorization(allow => [allow.publicApiKey()])
 .handler(
    a.handler.custom({
      dataSource: "ExternalPostTableDataSource",
      entry: "./addPost.js",
    })
  ),
```
And here's an example of how you might invoke this custom query from your Data client:
```javascript
const { data, errors } = await client.mutations.addPost({
  title: "My Post",
  content: "My Content",
  author: "Chris",
});
```

To connect your React app to an existing MySQL or PostgreSQL database using AWS Amplify Gen 2, follow these steps:

First, you need to create a connection string using your database information, including hostname, port, username, user password, and database name.

To get started, set secrets for your database connection using the Amplify sandbox's secret functionality or the Amplify console. You can use the following command to set secrets:
```
npx ampx sandbox secret set SQL_CONNECTION_STRING
```
The connection string format for MySQL is:
```
mysql://user:password@hostname:port/db-name
```
And for PostgreSQL:
```
postgres://user:password@hostname:port/db-name
```
Next, generate a TypeScript representation of your database schema using the following command:
```
npx ampx generate schema-from-database --connection-uri-secret SQL_CONNECTION_STRING --out amplify/data/schema.sql.ts
```
This will create a new schema.sql.ts file with a schema reflecting the types of your database. Do not edit this file directly. Instead, import the schema to your amplify/data/resource.ts file and apply any additive changes there.

To fine-grain authorization rules, use the `.setAuthorization()` modifier to set model-level and field-level authorization rules for your SQL-backed data models.

You can also deploy your Data resources using the cloud sandbox and make create, read, update, delete, and subscribe requests to your SQL-backed data models.

Additionally, you can rename generated models and fields, add relationships between tables, and add custom queries, mutations, and subscriptions to your auto-generated SQL data schema.

To configure the database connection for production, add the database connection string as a secret and make sure to add the appropriate database connection string with the same secret name used in the sandbox environment.

To troubleshoot issues, you can enable debug mode by setting the `DEBUG_MODE` environment variable to `true` on the Amplify-generated SQL Lambda function.

Note that if your table doesn't have a designated primary key, it may not get generated when running `npx ampx generate schema-from-database`. A primary key is required for `npx ampx generate schema-from-database` to infer the table structure and create a create, read, update, and delete API.

Here is an example of how to use the generated schema in your React app:
```typescript
import { schema as generatedSqlSchema } from './schema.sql';

const sqlSchema = generatedSqlSchema.authorization(allow => allow.guest());

const combinedSchema = a.combine([schema, sqlSchema]);

export type Schema = ClientSchema<typeof combinedSchema>;

export const data = defineData({
  schema: combinedSchema
});
```
You can then use the `data` object to make requests to your SQL-backed data models. For example:
```typescript
const { data: events } = await client.models.event.list();
```

Batch DynamoDB operations allow you to add multiple items in a single mutation.

To perform batch operations, you first need to define a custom mutation. This involves defining a return type as a custom type or model, and then defining the mutation itself with the return type and any optional arguments.

For example, let's say we want to create a custom mutation called `BatchCreatePost` that accepts an array of post contents and returns an array of post objects. In React, this can be achieved by defining a schema using the `@aws-amplify/backend` module.

Next, we need to configure a custom business logic handler code for our mutation. This involves defining a custom handler using the `a.handler.custom` function and specifying the data source and entry point for the handler.

The handler code itself will be responsible for mapping the request to the data source's input parameters and then mapping the data source's response back to the query or mutation's return type. Amplify provides a `stash` object that contains useful information such as the AppSync API ID and Amplify API environment name, which can be used to construct the DynamoDB table name.

Finally, once our custom mutation is defined and configured, we can invoke it from our React application using the generated Data client. We can pass in the required arguments, such as an array of post contents, and receive an array of post objects in response.

Here's an example of how we might invoke the `BatchCreatePost` mutation from our React application:
```javascript
const { data, errors } = await client.mutations.BatchCreatePost({
  contents: ['Post 1', 'Post 2', 'Post 3']
});
```
This code will create three new posts in our DynamoDB table with the specified contents and return an array of post objects.

Amazon Polly is a text-to-speech service offered by Amazon Web Services. It uses advanced deep learning technologies to convert written text into lifelike speech, enabling you to create applications with speech capabilities in various languages and voices.

With Amazon Polly, you can easily add voice interactions and accessibility features to your applications. The service supports a wide range of use cases, such as providing audio content for the visually impaired, enhancing e-learning experiences, creating interactive voice response systems, and more.

Key features of Amazon Polly include multiple voices and languages, high-quality speech, speech marks and speech synthesis markup language, and scalable and cost-effective pricing.

To integrate Amazon Polly into your React application using AWS Amplify, follow these steps:

1. Set up your project by following the instructions in the Quickstart guide.
2. Install the Amazon Polly SDK by running the command `npm add @aws-sdk/client-polly` in your project's root folder.
3. Create a file named `amplify/storage/resource.ts` and add the necessary content to configure a storage resource.
4. Configure IAM roles by updating the `amplify/backend.ts` file with the necessary permissions to access Amazon Polly.
5. Define the function handler by creating a new file, `amplify/data/convertTextToSpeech.ts`, which converts text into speech using Amazon Polly and stores the synthesized speech as an MP3 file in an S3 bucket.
6. Define the custom mutation and function in your `amplify/data/resource.ts` file.
7. Update storage permissions by modifying the `amplify/storage/resource.ts` file to provide access to the `convertTextToSpeech` resource.
8. Configure the frontend by importing and loading the configuration file in your app.

To invoke the API, use the following example frontend code to create an audio buffer for playback using a text input:
```typescript
import "./App.css";
import { generateClient } from "aws-amplify/api";
import type { Schema } from "../amplify/data/resource";
import { getUrl } from "aws-amplify/storage";
import { useState } from "react";

const client = generateClient<Schema>();

type PollyReturnType = Schema["convertTextToSpeech"]["returnType"];

function App() {
  const [src, setSrc] = useState("");
  const [file, setFile] = useState<PollyReturnType>("");
  return (
    <div className="flex flex-col">
      <button
        onClick={async () => {
          const { data, errors } = await client.mutations.convertTextToSpeech({
            text: "Hello World!",
          });

          if (!errors && data) {
            setFile(data);
          } else {
            console.log(errors);
          }
        }}
      >
        Synth
      </button>
      <button
        onClick={async () => {
          const res = await getUrl({
            path: "public/" + file,
          });

          setSrc(res.url.toString());
        }}
      >
        Fetch audio
      </button>
      <a href={src}>Get audio file</a>
    </div>
  );
}

export default App;
```

Amazon Rekognition is a machine learning service provided by Amazon Web Services (AWS) that allows developers to incorporate image and video analysis into their applications. It uses state-of-the-art machine learning models to analyze images and videos, providing valuable insights such as object and scene detection, text recognition, face analysis, and more.

Key features of Amazon Rekognition include object and scene detection, text detection and recognition, facial analysis, facial recognition, and content moderation. 

To integrate Amazon Rekognition into your React application, follow these steps:

1. Set up your project by following the instructions in the Quickstart guide.

2. Install the Amazon Rekognition SDK by running the command npm add @aws-sdk/client-rekognition in your project's root folder.

3. Create a new file named amplify/storage/resource.ts and add the content to configure a storage resource.

```typescript
import { defineStorage } from '@aws-amplify/backend';
export const storage = defineStorage({
  name: 'predictions_gen2'
});
```

4. Add Amazon Rekognition as an HTTP Data Source and configure the proper IAM policy for Lambda to effectively utilize the desired feature and grant permission to access the storage. Update the amplify/backend.ts file as shown below.

```typescript
import { PolicyStatement } from 'aws-cdk-lib/aws-iam';
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';
import { storage } from './storage/resource';
const backend = defineBackend({
  auth,
  data,
  storage
});
const rekognitionDataSource = backend.data.addHttpDataSource(
  "RekognitionDataSource",
  `https://rekognition.${backend.data.stack.region}.amazonaws.com`,
  {
    authorizationConfig: {
      signingRegion: backend.data.stack.region,
      signingServiceName: "rekognition",
    },
  }
);
rekognitionDataSource.grantPrincipal.addToPrincipalPolicy(
  new PolicyStatement({
    actions: ["rekognition:DetectText", "rekognition:DetectLabels"],
    resources: ["*"],
  })
);
backend.storage.resources.bucket.grantReadWrite(
  rekognitionDataSource.grantPrincipal
);
```

5. Define the function handler by creating a new file, amplify/data/identifyText.ts. This function analyzes the image and extracts text using the Amazon Rekognition DetectText service.

```typescript
export function request(ctx) {
  return {
    method: "POST",
    resourcePath: "/",
    params: {
      body: {
        Image: {
          S3Object: {
            Bucket: ctx.env.S3_BUCKET_NAME,
            Name: ctx.arguments.path,
          },
        },
      },
      headers: {
        "Content-Type": "application/x-amz-json-1.1",
        "X-Amz-Target": "RekognitionService.DetectText",
      },
    },
  };
}
export function response(ctx) {
  return JSON.parse(ctx.result.body)
   .TextDetections.filter((item) => item.Type === "LINE")
   .map((item) => item.DetectedText)
   .join("\n")
   .trim();
}
```

6. Define the custom query using the a.handler.custom() modifier, which takes the name of the data source and an entry point for your resolvers. In your amplify/data/resource.ts file, specify RekognitionDataSource as the data source and identifyText.js as the entry point.

```typescript
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";
const schema = a.schema({
  identifyText: a
   .query()
   .arguments({
      path: a.string(),
    })
   .returns(a.string())
   .authorization((allow) => [allow.publicApiKey()])
   .handler(
      a.handler.custom({
        entry: "./identifyText.js",
        dataSource: "RekognitionDataSource",
      })
    ),
});
export type Schema = ClientSchema<typeof schema>;
export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
```

7. Update Storage permissions to manage access to various paths within your storage bucket. Modify the file amplify/storage/resource.ts as shown below.

```typescript
import { defineStorage } from "@aws-amplify/backend"
export const storage = defineStorage({
  name: "predictions_gen2",
  access: allow => ({
    'public/*': [
      allow.guest.to(['list', 'write', 'get'])
    ]
  })
})
```

8. Configure the frontend by importing and loading the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.

```typescript
import { Amplify } from "aws-amplify";
import outputs from "../amplify_outputs.json";
Amplify.configure(outputs);
```

To invoke the Text Recognition API in a React app, you can use the following code:

```typescript
import { type ChangeEvent, useState } from "react";
import { generateClient } from "aws-amplify/api";
import { uploadData } from "aws-amplify/storage";
import { Schema } from "@/amplify/data/resource";
const client = generateClient<Schema>();
type IdentifyTextReturnType = Schema["identifyText"]["returnType"];
function App() {
  const [path, setPath] = useState<string>("");
  const [textData, setTextData] = useState<IdentifyTextReturnType>();
  const handleTranslate = async (event: ChangeEvent<HTMLInputElement>) => {
    if (event.target.files) {
      const file = event.target.files[0];
      const s3Path = "public/" + file.name;
      try {
        uploadData({
          path: s3Path,
          data: file,
        });
        setPath(s3Path);
      } catch (error) {
        console.error(error);
      }
    }
  };
  const recognizeText = async () => {
    const { data } = await client.queries.identifyText({
      path, 
    });
    setTextData(data);
  };
  return (
    <div>
      <h1>Amazon Rekognition Text Recognition</h1>
      <div>
        <input type="file" onChange={handleTranslate} />
        <button onClick={recognizeText}>Recognize Text</button>
        <div>
          <h3>Recognized Text:</h3>
          {textData}
        </div>
      </div>
    </div>
  );
}
export default App;
```

Amazon Translate is a neural machine translation service provided by Amazon Web Services (AWS) that uses advanced deep learning technologies to deliver fast and high-quality language translation. With Amazon Translate, you can easily add multilingual support to your applications and services, enabling users to communicate and interact in their preferred language.

The key features of Amazon Translate include accurate and fluent translations, support for multiple languages, real-time and batch translation, and cost-effective and scalable pricing. 

To integrate Amazon Translate into your React application using AWS Amplify, follow these steps:

1. Set up your project by following the instructions in the Quickstart guide.

2. Install the Amazon Translate SDK by running the command `npm add @aws-sdk/client-translate` in your project's root folder.

3. Add Amazon Translate as an HTTP Data Source and configure the proper IAM policy for AWS Lambda to utilize the desired feature effectively. 

4. Create a custom business logic handler by defining custom resolvers in a file named `translate.js` in your `amplify/data` folder.

5. Define the custom query by referencing the Amazon Translate data source in a custom query using the `a.handler.custom()` modifier.

6. Configure the frontend by importing and loading the configuration file in your app and invoking the API to translate text from one language to another.

Here is an example of how to invoke the API in a React application:
```typescript
import { generateClient } from 'aws-amplify/data';
import { type Schema } from '../amplify/data/resource';

const client = generateClient<Schema>();

const translateText = async () => {
  const { data } = await client.queries.translate({
    sourceLanguage: "en",
    targetLanguage: "es",
    text: "Hello World!",
  });
  console.log(data);
};
```
This code generates a client using the `generateClient` function from `aws-amplify/data` and then invokes the `translate` query with the source language, target language, and text to be translated. The translated text is then logged to the console. 

You can call the `translateText` function from any React component to translate text from one language to another using Amazon Translate.

Amazon Bedrock is a fully managed service that simplifies the use of foundation models for generative AI development. It offers a curated selection of high-performing models from leading AI companies and provides a unified API for access and use. With Amazon Bedrock, you can streamline generative AI development by choosing from a range of models, integrating them easily, and benefiting from built-in security and privacy features.

To connect to Amazon Bedrock from your AWS Amplify app, you can follow these steps:

1. Add Amazon Bedrock as a data source to your app. You can do this by using a Lambda function or a custom resolver powered by AppSync JavaScript resolvers.

2. Define a custom query that will be used to invoke the generative AI model in Amazon Bedrock. This query will take a prompt as an argument and return the generated text.

3. Configure custom business logic handler code that will be used to invoke the generative AI model. This code will take the user's prompt, invoke the model, and return the generated text.

4. Invoke the custom query to prompt the generative AI model. You can do this by calling the query from your app's frontend code and passing in the user's prompt.

Here's an example of how you might invoke the custom query from a React app:

```tsx
const { data, errors } = await client.queries.generateHaiku({
  prompt: "Frank Herbert's Dune",
});
```

You can also create a simple UI that prompts a generative AI model to create a haiku based on user input. For example:

```tsx
import type { Schema } from '@/amplify/data/resource';
import type { FormEvent } from 'react';
import { useState } from 'react';
import { Amplify } from 'aws-amplify';
import { generateClient } from 'aws-amplify/api';
import outputs from '@/amplify_outputs.json';

Amplify.configure(outputs);

const client = generateClient<Schema>();

export default function App() {
  const [prompt, setPrompt] = useState<string>('');
  const [answer, setAnswer] = useState<string | null>(null);

  const sendPrompt = async (event: FormEvent<HTMLFormElement>) => {
    event.preventDefault();

    const { data, errors } = await client.queries.generateHaiku({
      prompt
    });

    if (!errors) {
      setAnswer(data);
      setPrompt('');
    } else {
      console.log(errors);
    }
  };

  return (
    <main className="flex min-h-screen flex-col items-center justify-center p-24 dark:text-white">
      <div>
        <h1 className="text-3xl font-bold text-center mb-4">Haiku Generator</h1>
        <form className="mb-4 self-center max-w-[500px]" onSubmit={sendPrompt}>
          <input
            className="text-black p-2 w-full"
            placeholder="Enter a prompt..."
            name="prompt"
            value={prompt}
            onChange={(event) => setPrompt(event.target.value)}
          />
        </form>
        <div className="text-center">
          <pre>{answer}</pre>
        </div>
      </div>
    </main>
  );
}
```

By following these steps and using Amazon Bedrock with your AWS Amplify app, you can leverage the power of generative AI models to create innovative and engaging user experiences.

Amazon EventBridge is a serverless event bus that simplifies how applications communicate with each other. It acts as a central hub for events generated by various sources, including AWS services, custom applications, and third-party SaaS providers. EventBridge delivers event data in real-time, allowing you to build applications that react swiftly to changes. You define rules to filter and route these events to specific destinations, known as targets.

By adopting an event-driven architecture with EventBridge, you can achieve loose coupling, increased resilience, and simplified integration. Loose coupling means applications become independent and communicate through events, improving scalability and maintainability. Increased resilience means system failures are isolated as events are delivered asynchronously, ensuring overall application availability. Simplified integration means EventBridge provides a unified interface for integrating diverse event sources, streamlining development.

To connect to Amazon EventBridge, you need to set up your API, add your Amazon EventBridge event bus as a data source, define custom queries and mutations, configure custom business logic handler code, invoke custom mutations to send events to EventBridge, subscribe to mutations invoked by EventBridge, and invoke mutations and trigger subscriptions from EventBridge.

First, set up your API by defining a custom type that represents an order status change event. This type includes fields for the order ID, status, and message. 

```typescript
const schema = a.schema({
  OrderStatus: a.enum(["OrderPending", "OrderShipped", "OrderDelivered"]),
  OrderStatusChange: a.customType({
    orderId: a.id().required(),
    status: a.ref("OrderStatus").required(),
    message: a.string().required(),
  }),
});
```

Next, add your Amazon EventBridge event bus as a data source for your API. You can do this by using the `addEventBridgeDataSource` method.

```typescript
backend.data.addEventBridgeDataSource("MyEventBridgeDataSource", eventBus);
```

Then, define custom queries and mutations. For example, you can add `publishOrderToEventBridge` and `publishOrderFromEventBridge` custom mutations, and an `onOrderStatusChange` custom subscription to your schema.

```typescript
const schema = a.schema({
  publishOrderToEventBridge: a
   .mutation()
   .arguments({
      orderId: a.id().required(),
      status: a.string().required(),
      message: a.string().required(),
    })
   .returns(a.ref("OrderStatusChange"))
   .authorization((allow) => [allow.publicApiKey()])
   .handler(
      a.handler.custom({
        dataSource: "EventBridgeDataSource",
        entry: "./publishOrderToEventBridge.js",
      })
    ),
  publishOrderFromEventBridge: a
   .mutation()
   .arguments({
      orderId: a.id().required(),
      status: a.string().required(),
      message: a.string().required(),
    })
   .returns(a.ref("OrderStatusChange"))
   .authorization((allow) => [allow.publicApiKey(), allow.guest()])
   .handler(
      a.handler.custom({
        entry: "./publishOrderFromEventBridge.js",
      })
    ),
  onOrderFromEventBridge: a
   .subscription()
   .for(a.ref("publishOrderFromEventBridge"))
   .authorization((allow) => [allow.publicApiKey()])
   .handler(
      a.handler.custom({
        entry: "./onOrderFromEventBridge.js",
      })
    ),
});
```

After that, configure custom business logic handler code. For example, you can create a file called `publishOrderToEventBridge.js` with the following code:

```javascript
export function request(ctx) {
  return {
    operation: "PutEvents",
    events: [
      {
        source: "amplify.orders",
        ["detail-type"]: "OrderStatusChange",
        detail: {...ctx.args },
      },
    ],
  };
}

export function response(ctx) {
  return ctx.args;
}
```

You can then invoke custom mutations to send events to EventBridge. For example:

```typescript
await client.mutations.publishOrderToEventBridge({
  orderId: "12345",
  status: "SHIPPED",
  message: "Order has been shipped",
});
```

You can also subscribe to mutations invoked by EventBridge. For example:

```typescript
const sub = client.subscriptions.onOrderStatusChange().subscribe({
  next: (data) => {
    console.log(data);
  },
});
```

Finally, you can invoke a mutation and trigger a subscription from EventBridge. You can test your custom mutation and subscriptions by using the EventBridge console to send an event which will invoke the custom mutation. You can then observe the results from the subscription being triggered. 

To send an event, navigate to the Amazon EventBridge console and choose "Send Events". Fill out the form, specifying the event source to be `amplify.orders` and the `detail-type` to be `OrderStatusChange`. Choose "Send" and observe the subscription output in the AppSync Queries console.

The HTTP Datasource allows you to quickly configure HTTP resolvers within your Data API. 

This guide will demonstrate how to establish a connection to an external REST API using an HTTP data source and use Amplify Data's custom mutations and queries to interact with the REST API.

To start, you need to set up your custom type. For this example, we will define a Post type and use an existing external REST API that will store records for it. In Amplify Gen 2, a customType adds a type to the schema that is not backed by an Amplify-generated DynamoDB table. 

With the Post type defined, it can then be referenced as the return type when defining your custom queries and mutations. To add the Post custom type to your schema, use the following code 
```javascript
const schema = {
  Post: {
    title: 'string',
    content: 'string',
    author: 'string',
  },
};
```

Next, you need to add your REST API or HTTP API as a Datasource. To integrate the external REST API or HTTP API, you'll need to set it up as the HTTP Datasource. 

Now that your REST API has been added as a data source, you can reference it in custom queries and mutations. Use the following code examples to add addPost, getPost, updatePost, and deletePost as custom queries and mutations to your schema 
```javascript
const addPost = {
  type: 'mutation',
  args: {
    title: 'string',
    content: 'string',
    author: 'string',
  },
  resolve: async (parent, args) => {
    const response = await fetch('https://www.example.com/post', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        title: args.title,
        content: args.content,
        author: args.author,
      }),
    });
    return response.json();
  },
};

const getPost = {
  type: 'query',
  args: {
    id: 'string',
  },
  resolve: async (parent, args) => {
    const response = await fetch(`https://www.example.com/posts/${args.id}`);
    return response.json();
  },
};

const updatePost = {
  type: 'mutation',
  args: {
    id: 'string',
    title: 'string',
    content: 'string',
    author: 'string',
  },
  resolve: async (parent, args) => {
    const response = await fetch(`https://www.example.com/posts/${args.id}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        title: args.title,
        content: args.content,
        author: args.author,
      }),
    });
    return response.json();
  },
};

const deletePost = {
  type: 'mutation',
  args: {
    id: 'string',
  },
  resolve: async (parent, args) => {
    const response = await fetch(`https://www.example.com/posts/${args.id}`, {
      method: 'DELETE',
    });
    return response.json();
  },
};
```

Next, you need to configure custom business logic handler code. Create the following files and use the code examples to define custom resolvers for the custom queries and mutations added to your schema from the previous step. 

To invoke custom queries or mutations, you can use the following code examples 
```javascript
const addPostData = await fetch('https://www.example.com/post', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    title: 'My Post',
    content: 'My Content',
    author: 'Chris',
  }),
});

const getPostData = await fetch('https://www.example.com/posts/<post-id>');
const updatePostData = await fetch('https://www.example.com/posts/<post-id>', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    title: 'An Updated Post',
  }),
});

const deletePostData = await fetch('https://www.example.com/posts/<post-id>', {
  method: 'DELETE',
});
```

In this guide, you’ve added an external REST API as a HTTP data source to an Amplify Data API and defined custom queries and mutations, handled by AppSync JS resolvers, to manipulate Post items in an external REST API using the Amplify Gen 2 Data client. 

To clean up, you can delete your sandbox by accepting the prompt when terminating the sandbox process in your terminal. Alternatively, you can also use the AWS Amplify console to manage and delete sandbox environments.

To add custom queries and mutations to your AWS Amplify application, you need to follow three steps. 

First, you define a custom query or mutation. A query is used when the request only needs to read data and will not modify any backend data, while a mutation is used when the request will modify backend data. You need to set a return type and, optionally, arguments for your custom query or mutation. 

In React, you can define your custom query or mutation in your amplify/data/resource.ts file. For example, to define a custom query, you can use the `a.query()` method and specify the return type and arguments. 

```typescript
const schema = a.schema({
  EchoResponse: a.customType({
    content: a.string(),
    executionDuration: a.float()
  }),

  echo: a
   .query()
   .arguments({
      content: a.string()
    })
   .returns(a.ref('EchoResponse'))
});
```

To define a custom mutation, you can use the `a.mutation()` method and specify the return type and arguments. 

```typescript
const schema = a.schema({
  Post: a.model({
    id: a.id(),
    content: a.string(),
    likes: a.integer()
  }),

  likePost: a
   .mutation()
   .arguments({
      postId: a.string()
    })
   .returns(a.ref('Post'))
});
```

Second, you need to configure custom business logic handler code. You can either define it in a function or using a custom resolver powered by AppSync JavaScript resolver. 

To define a function, you can create a handler.ts file in your amplify/data/echo-handler/ folder and import the utility type for your function handler via the Schema type from your backend resource. 

```typescript
export const handler: Schema["echo"]["functionHandler"] = async (event, context) => {
  const start = performance.now();
  return {
    content: `Echoing content: ${event.arguments.content}`,
    executionDuration: performance.now() - start
  };
};
```

Then, in your amplify/data/resource.ts file, you can define the function using `defineFunction` and reference the function with your query or mutation using `a.handler.function()` as a handler. 

```typescript
const echoHandler = defineFunction({
  entry: './echo-handler/handler.ts'
})

const schema = a.schema({
  EchoResponse: a.customType({
    content: a.string(),
    executionDuration: a.float()
  }),

  echo: a
   .query()
   .arguments({
      content: a.string()
    })
   .returns(a.ref('EchoResponse'))
   .handler(a.handler.function(echoHandler))
});
```

To use a custom resolver, you can define a custom handler using `a.handler.custom` in your amplify/data/resource.ts file. 

```typescript
const schema = a.schema({
  Post: a.model({
    content: a.string(),
    likes: a.integer()
  }),

  likePost: a
   .mutation()
   .arguments({
      postId: a.id()
    })
   .returns(a.ref('Post'))
   .handler(a.handler.custom({
      dataSource: a.ref('Post'),
      entry: './increment-like.js'
    }))
});
```

You can then define the custom resolver in a separate file, such as amplify/data/increment-like.js. 

```typescript
export function request(ctx) {
  return {
    operation: 'UpdateItem',
    key: util.dynamodb.toMapValues({ id: ctx.args.postId}),
    update: {
      expression: 'ADD likes :plusOne',
      expressionValues: { ':plusOne': { N: 1 } },
    }
  }
}

export function response(ctx) {
  return ctx.result
}
```

Third, you need to invoke the custom query or mutation. You can do this using the generated Data client. 

```typescript
const { data, errors } = await client.queries.echo({
  content: 'hello world!!!'
});

const { data, errors } = await client.mutations.likePost({
  postId: 'hello'
});
```

Note that all handlers must be of the same type. You cannot mix and match `a.handler.function` with `a.handler.custom` within a single `.handler()` modifier. 

Additionally, you can use async function handlers to execute long-running operations asynchronously, improving the responsiveness of your API. To define an async function handler, you can use the `.async()` method when defining your handler. 

```typescript
const signUpForNewsletter = defineFunction({
  entry: './sign-up-for-newsletter/handler.ts'
});

const schema = a.schema({
  someAsyncOperation: a.mutation()
   .arguments({
      email: a.email().required()
    })
   .handler(a.handler.function(signUpForNewsletter).async())
});
```

Amazon OpenSearch Service is a managed platform for deploying search and analytics solutions with OpenSearch or Elasticsearch. It integrates with Amazon DynamoDB, allowing for seamless search on DynamoDB data by automatically replicating and transforming it without requiring custom code or infrastructure. This integration simplifies processes and reduces the operational workload of managing data pipelines.

To connect to Amazon OpenSearch, follow these steps:

## Step 1: Setup the project

Begin by setting up your project. For this example, we'll sync a Todo table from DynamoDB to OpenSearch. Add the Todo model to your schema.

```typescript
const schema = {
  Todo: {
    content: 'string',
    done: 'boolean',
    priority: ['low', 'medium', 'high']
  }
}
```

Enable Point in Time Recovery (PITR) and DynamoDB streams to capture item changes that will be ingested into OpenSearch.

## Step 2: Setting Up the OpenSearch Instance

Create an OpenSearch instance with encryption. Define the OpenSearch domain and set the instance type, node count, and removal policy.

```typescript
const openSearchDomain = {
  version: 'OPENSEARCH_2_11',
  capacity: {
    masterNodeInstanceType: 't3.small.search',
    masterNodes: 0,
    dataNodeInstanceType: 't3.small.search',
    dataNodes: 1
  },
  nodeToNodeEncryption: true,
  removalPolicy: 'DESTROY',
  encryptionAtRest: {
    enabled: true
  }
}
```

## Step 3: Setting Up Zero ETL from DynamoDB to OpenSearch

### Step 3a: Setup Storage and IAM Role

Establish storage to back up raw events consumed by the OpenSearch pipeline. Generate a file to set up a storage resource and tailor your storage configurations to regulate access.

```typescript
const storage = {
  name: 'opensearch-backup-bucket',
  access: {
    'public/*': ['list', 'write', 'get']
  }
}
```

Create an IAM role for OpenSearch integration and assign the necessary permissions.

```typescript
const openSearchIntegrationPipelineRole = {
  assumedBy: 'osis-pipelines.amazonaws.com',
  inlinePolicies: {
    openSearchPipelinePolicy: {
      statements: [
        {
          actions: ['es:DescribeDomain'],
          resources: [openSearchDomain.domainArn, openSearchDomain.domainArn + '/*']
        }
      ]
    }
  }
}
```

### Step 3b: OpenSearch Service Pipeline

Define the pipeline construct and its configuration. Customize the template content JSON-representation to define the data structure for the ingestion pipeline.

```typescript
const openSearchTemplate = `
version: "2"
dynamodb-pipeline:
  source:
    dynamodb:
      acknowledgments: true
      tables:
        - table_arn: "${tableArn}"
          stream:
            start_position: "LATEST"
          export:
            s3_bucket: "${s3BucketName}"
            s3_region: "${backend.storage.stack.region}"
            s3_prefix: "${tableName}/"
      aws:
        sts_role_arn: "${openSearchIntegrationPipelineRole.roleArn}"
        region: "${backend.data.stack.region}"
  sink:
    - opensearch:
        hosts:
          - "https://${openSearchDomain.domainEndpoint}"
        index: "${indexName}"
        index_type: "custom"
        template_content: |
          ${JSON.stringify(indexMapping)}
        document_id: '${getMetadata("primary_key")}'
        action: '${getMetadata("opensearch_action")}'
        document_version: '${getMetadata("document_version")}'
        document_version_type: "external"
        bulk_size: 4
        aws:
          sts_role_arn: "${openSearchIntegrationPipelineRole.roleArn}"
          region: "${backend.data.stack.region}"
`
```

Create the OSIS pipeline resource and define the log group and pipeline configuration.

```typescript
const logGroup = {
  logGroupName: '/aws/vendedlogs/OpenSearchService/pipelines/1',
  removalPolicy: 'DESTROY'
}

const cfnPipeline = {
  maxUnits: 4,
  minUnits: 1,
  pipelineConfigurationBody: openSearchTemplate,
  pipelineName: 'dynamodb-integration-2',
  logPublishingOptions: {
    isLoggingEnabled: true,
    cloudWatchLogDestination: {
      logGroup: logGroup.logGroupName
    }
  }
}
```

## Step 4: Expose new queries on OpenSearch

### Step 4a: Add OpenSearch Datasource to backend

Add the OpenSearch data source to the data backend.

```typescript
const osDataSource = backend.data.addOpenSearchDataSource('osDataSource', openSearchDomain)
```

### Step 4b: Create Resolver and attach to query

Create a search resolver and attach it to the query. Define the request and response functions for the resolver.

```typescript
export function request(ctx) {
  return {
    operation: 'GET',
    path: '/todo/_search'
  }
}

export function response(ctx) {
  if (ctx.error) {
    util.error(ctx.error.message, ctx.error.type)
  }
  return ctx.result.hits.hits.map((hit) => hit._source)
}
```

### Step 4c: Add the AppSync Resolver for the Search Query

Update the schema and add a searchTodo query. Attach the resolver to the query.

```typescript
const schema = {
  Todo: {
    content: 'string',
    done: 'boolean',
    priority: ['low', 'medium', 'high']
  },
  searchTodos: {
    type: 'Todo',
    args: {
      filter: {
        type: 'TodoFilterInput'
      }
    },
    resolve: async (source, args, context, info) => {
      const result = await context.dataSources.osDataSource.searchTodo(args.filter)
      return result.items
    }
  }
}
```

Once you've deployed the resources, you can verify the changes by checking the AppSync console. Run the 'searchTodo' query and review the results to confirm their accuracy.

To add custom real-time subscriptions to your application, you need to define a custom subscription in your amplify/data/resource file. This involves setting the mutation that triggers the subscription event, the return type that matches the subscribed mutation's return type, and authorization rules. You can also optionally set filter arguments to customize server-side subscription filter rules.

To define a custom subscription, use the `a.subscription()` function and specify the mutation that should trigger the subscription event using the `for` method. You can also specify a subscription handler to set custom filters and authorization rules.

For example, to create a custom real-time subscription for a mutation called `publish`, you would use the following code:

```javascript
const schema = a.schema({
  // Message type that's used for this PubSub sample
  Message: a.customType({
    content: a.string().required(),
    channelName: a.string().required()
  }),

  // Message publish mutation
  publish: a.mutation()
   .arguments({
      channelName: a.string().required(),
      content: a.string().required()
    })
   .returns(a.ref('Message'))
   .handler(a.handler.custom({ entry: './publish.js' }))
   .authorization(allow => [allow.publicApiKey()]),

  // Subscribe to incoming messages
  receive: a.subscription()
    // subscribes to the 'publish' mutation
   .for(a.ref('publish')) 
    // subscription handler to set custom filters
   .handler(a.handler.custom({entry: './receive.js'})) 
    // authorization rules as to who can subscribe to the data
   .authorization(allow => [allow.publicApiKey()]),
});
```

To subscribe to custom subscriptions client-side, you can use the `client.subscriptions` object and the `subscribe` function. For example:

```javascript
import { generateClient } from 'aws-amplify/data'
import type { Schema } from '../amplify/data/resource'

const client = generateClient<Schema>()

const sub = client.subscriptions.receive()
 .subscribe({
    next: event => {
      console.log(event)
    }
  }
)
```

You can also try publishing an event using the custom mutation to test the real-time subscription.

```javascript
client.mutations.publish({
  channelName: "world",
  content: "My first message!"
})
```

Your subscription event should be received and logs the payload into your app's developer console. Unsubscribe your subscription to disconnect using the `unsubscribe` function.

```javascript
sub.unsubscribe()
```

To add server-side subscription filters, you can add arguments to the custom subscriptions. For example, you can introduce a required `name` argument that allows your users to filter events based on a specific channel name.

```javascript
const schema = a.schema({
  Channel: a.customType({
    name: a.string(),
    data: a.json()
  }),
  // Define a mutation to publish events to
  publish: a.mutation()
   .arguments({
      name: a.string(),
      data: a.json()
    })
   .returns(a.ref('Channel'))
   .handler(a.handler.custom({
      entry: "./publish.js"
    }))
   .authorization(allow => [allow.authenticated()]),
  
  // Subscribe to all events from the "publish" mutation
  receive: a.subscription(['publish'])
    // subscription filter
   .arguments({ name: a.string() })
   .authorization(allow => [allow.publicApiKey()])
});
```

To customize the filters, modify the subscription handler. For example, you can allow a customer to pass in a `namePrefix` parameter that allows the end users to only receive channel events in channels that start with the `namePrefix`.

```javascript
const schema = a.schema({
  Channel: a.model({
    name: a.string(),
  }).authorization(allow => [allow.publicApiKey()]),

  Message: a.customType({
    content: a.string().required(),
    channelName: a.string().required()
  }),

  publish: a.mutation()
   .arguments({
      channelName: a.string().required(),
      content: a.string().required()
    })
   .returns(a.ref('Message'))
   .handler(a.handler.custom({ entry: './publish.js' }))
   .authorization(allow => [allow.publicApiKey()]),

  receive: a.subscription()
   .for(a.ref('publish'))
    // subscription filter
   .arguments({ namePrefix: a.string() })
   .handler(a.handler.custom({entry: './receive.js'}))
   .authorization(allow => [allow.publicApiKey()])
});
```

In your handler, you can set custom subscription filters based on arguments passed into the custom subscription. For example:

```javascript
import { util, extensions } from "@aws-appsync/utils"

// Subscription handlers must return a `null` payload on the request
export function request() { return { payload: null } }

/**
 * @param {import('@aws-appsync/utils').Context} ctx
 */
export function response(ctx) {
  const filter = {
    channelName: {
      beginsWith: ctx.args.namePrefix
    }
  }

  extensions.setSubscriptionFilter(util.transform.toSubscriptionFilter(filter))

  return null
}
```

Amplify Data allows you to configure custom identity and group claims instead of using the default Amazon Cognito claims. This can be useful if you want to populate claims from an external source like a database or 3rd party auth provider. 

You can define custom claims to provide more flexibility in authorization rules. For example, you can check the `user_id` identity claim and the `user_groups` group claim that could come from a custom pre token generation Lambda trigger.

To use custom claims, specify `identityClaim` or `groupClaim` as appropriate. In the example below, the `identityClaim` is specified and the record owner will check against this `user_id` claim. Similarly, if the `user_groups` claim contains a "Moderator" string then access will be granted.

In your React application, you can perform CRUD operations against the model using `client.models.model-name` with the `userPool` auth mode. Here is an example:
```javascript
const client = generateClient();
const { errors, data: newTodo } = await client.models.Post.create(
  {
    postname: 'My New Post',
    content: 'My post content',
  },
  {
    authMode: 'userPool',
  }
);
```
You can define your schema with custom claims like this:
```javascript
const schema = {
  Post: {
    id: 'string',
    owner: 'string',
    postname: 'string',
    content: 'string',
  },
  authorization: (allow) => [
    allow.owner().identityClaim('user_id'),
    allow.groups(['Moderator']).withClaimIn('user_groups'),
  ],
};
```
This schema defines a `Post` model with an `owner` field that checks against the `user_id` claim, and allows access to the "Moderator" group if the `user_groups` claim contains the string "Moderator".

You can define your own custom authorization rule with a Lambda function. To do this, you will need to indicate which models or fields should use a custom authorization rule and pass in the function to be used for a custom authorization rule.

In your backend, you will need to define a schema that includes the custom authorization rule. For example, if you have a Todo model, you can define the schema as follows:

```typescript
const schema = {
  Todo: {
    content: 'string',
    authorization: (allow) => [allow.custom()],
  },
};
```

You will then need to define the custom authorization rule in your Lambda function. The Lambda function will receive an authorization token from the client and execute the desired authorization logic. The AppSync GraphQL API will receive a payload from Lambda after invocation to allow or deny the API call accordingly.

To configure a Lambda function as the authorization mode, you can create a new file `custom-authorizer.ts`. You can use the following Lambda function code template as a starting point for your authorization handler code:

```typescript
export const handler = async (event) => {
  const {
    authorizationToken,
    requestContext: { apiId, accountId },
  } = event;
  const response = {
    isAuthorized: authorizationToken === 'custom-authorized',
    resolverContext: {
      userid: 'user-id',
      info: 'contextual information A',
      more_info: 'contextual information B',
    },
    deniedFields: [
      `arn:aws:appsync:${process.env.AWS_REGION}:${accountId}:apis/${apiId}/types/Event/fields/comments`,
      `Mutation.createEvent`,
    ],
    ttlOverride: 300,
  };
  return response;
};
```

In your React application, you can perform CRUD operations against the model using the `client.models.<model-name>` with the `lambda` auth mode. For example:

```typescript
const client = generateClient<Schema>();
const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
  {
    authMode: 'lambda',
  }
);
```

The Lambda function receives an event that includes the authorization token, API ID, and account ID. The function needs to return a JSON response that includes the `isAuthorized` field, `resolverContext` field, and optionally the `deniedFields` and `ttlOverride` fields.

For example, the event received by the Lambda function might look like this:

```json
{
  "authorizationToken": "ExampleAuthToken123123123",
  "requestContext": {
    "apiId": "aaaaaa123123123example123",
    "accountId": "111122223333",
    "requestId": "f4081827-1111-4444-5555-5cf4695f339f",
    "queryString": "mutation CreateEvent {...}\n\nquery MyQuery {...}\n",
    "operationName": "MyQuery",
    "variables": {}
  }
}
```

And the Lambda function needs to return a response like this:

```json
{
  "isAuthorized": true,
  "resolverContext": {
    "banana": "very yellow"
  },
  "deniedFields": ["TypeName.FieldName"],
  "ttlOverride": 10
}
```

To grant a Lambda function access to an API and data in AWS Amplify Gen 2, you can configure an authorization rule on the schema object using the `authorization` method. This method uses a `deny-by-default` authorization model, meaning that function access must be explicitly defined in the schema.

To start, create a new directory and a resource file, `amplify/functions/data-access/resource.ts`. Then, define the function with `defineFunction` and export it. This function can be passed directly to `allow.resource()` in the schema authorization rules, allowing the function to execute Query, Mutation, and Subscription operations against the GraphQL API.

You can narrow down access to one or more operations using the `.to()` method. For example, you can allow query and subscription operations but not mutations.

Function access can only be configured on the schema object and not on individual models or fields.

To access the API using `aws-amplify`, you need to configure the Amplify data client in the handler file for your function. You can do this by using `getAmplifyDataClientConfig` and `generateClient`.

Here is an example of how to grant access to a function:
```javascript
const schema = new Schema({
  Todo: new Model({
    name: new Field(String),
    description: new Field(String),
    isDone: new Field(Boolean)
  })
})
 .authorization((allow) => [
    allow.resource(functionWithDataAccess)
  ]);
```
And here is an example of how to narrow down access to one or more operations:
```javascript
const schema = new Schema({
  Todo: new Model({
    name: new Field(String),
    description: new Field(String),
    isDone: new Field(Boolean)
  })
})
 .authorization((allow) => [
    allow.resource(functionWithDataAccess).to(['query', 'listen'])
  ]);
```
To access the API using `aws-amplify`, you can use the following code in your function handler:
```javascript
const client = generateClient();
export const handler = async (event) => {
  const { errors: createErrors, data: newTodo } = await client.models.Todo.create({
    name: "My new todo",
    description: "Todo description",
    isDone: false,
  })

  const { errors: listErrors, data: todos } = await client.models.Todo.list();

  return event;
};
```
Note that when configuring Amplify with `getAmplifyDataClientConfig`, your function consumes schema information from an S3 bucket created during backend deployment with grants for the access your function needs to use it. Any changes to this bucket outside of backend deployment may break your function.

To customize authorization rules in AWS Amplify Gen 2, you can use the `.authorization()` modifier. This modifier operates on the deny-by-default principle, meaning that if an authorization rule is not specifically configured, it is denied.

There are several available authorization strategies, including:

* Public data access using `publicApiKey` or `guest`
* Per user data access using `owner`
* Any signed-in data access using `authenticated`
* Per user group data access using `group`
* Custom authorization rules using `custom`

You can apply authorization rules globally, to specific data models, or to specific fields. Amplify will always use the most specific authorization rule available. If there are multiple authorization rules present, they will be logically OR'ed.

Here's an example of how to configure authorization rules in React:
```javascript
const schema = {
  Post: {
    content: 'string',
    createdBy: 'string'
  }
};

const authorizationRules = {
  Post: {
    auth: [
      {
        allow: 'publicApiKey',
        operations: ['read']
      },
      {
        allow: 'owner',
        operations: ['create', 'read', 'update', 'delete']
      }
    ]
  }
};
```
In this example, anyone with a public API key can read all posts, and the owner of a post can create, read, update, and delete their own posts.

You can also configure multiple authorization rules, which will be logically OR'ed. For example:
```javascript
const authorizationRules = {
  Post: {
    auth: [
      {
        allow: 'guest',
        operations: ['read']
      },
      {
        allow: 'owner',
        operations: ['create', 'read', 'update', 'delete']
      }
    ]
  }
};
```
In this example, unauthenticated users (guests) can read all posts, and the owner of a post can create, read, update, and delete their own posts.

Note that IAM authorization is enabled by default for all Amplify Gen 2 projects, which allows for administrative access to your API using IAM policies.

It's also important to note that authorization rules are only supported on data models and custom operations, and not on custom types. However, Amplify will add appropriate authorization rules to custom types to allow authenticated users to access them.

To authenticate with the corresponding authorization mode on the client-side, you can use the following code:
```javascript
import { API } from 'aws-amplify';

// Creating a post is restricted to Cognito User Pools
const post = {
  title: 'Hello World'
};
API.graphql({
  query: 'createPost',
  variables: { input: post },
  authMode: 'AMAZON_COGNITO_USER_POOLS'
});

// Listing posts is available to unauthenticated users (verified by Amazon Cognito identity pool's unauthenticated role)
API.graphql({
  query: 'listPosts',
  authMode: 'AWS_IAM'
});
```
This code creates a new post using the `createPost` mutation, which is restricted to Cognito User Pools, and lists all posts using the `listPosts` query, which is available to unauthenticated users.

The ownersDefinedIn rule grants a set of users access to a record by automatically creating an owners field to store the allowed record owners. You can override the default owners field name by specifying inField with the desired field name to store the owner information. You can dynamically manage which users can access a record by updating the owner field.

To grant a set of users access to a record, you use the ownersDefinedIn rule. This automatically creates an owners field to store the allowed owners. 

For example, in a React application, you can define a schema with the ownersDefinedIn rule like this:
```javascript
const schema = {
  Todo: {
    content: 'string',
    owners: ['string']
  },
  authorization: (allow) => [allow.ownersDefinedIn('owners')]
}
```
In your React application, you can perform CRUD operations against the model using the Amplify API with the userPool auth mode. To create a record with the current user as the first owner:
```javascript
const { errors, data: newTodo } = await Amplify.API.graphql({
  query: 'createTodo',
  variables: {
    input: {
      content: 'My new todo'
    },
    authMode: 'userPool'
  }
});
```
To add another user as an owner, you can update the owners field:
```javascript
await Amplify.API.graphql({
  query: 'updateTodo',
  variables: {
    input: {
      id: newTodo.id,
      owners: [...(newTodo.owners), otherUserId]
    },
    authMode: 'userPool'
  }
});
```
You can override the default owners field name by specifying inField with the desired field name to store the owner information. For example:
```javascript
const schema = {
  Todo: {
    content: 'string',
    authors: ['string']
  },
  authorization: (allow) => [allow.ownersDefinedIn('authors')]
}
```
This way, the authors field will store the owner information instead of the default owners field. Any user listed in the authors field can access the record.

The owner authorization strategy restricts operations on a record to only the record's owner. When configured, the owner field will automatically be added and populated with the identity of the created user. The API will authorize against the owner field to allow or deny operations.

To add per-user/per-owner authorization rule, you can use the owner authorization strategy to restrict a record's access to a specific user. When owner authorization is configured, only the record's owner is allowed the specified operations.

For example, in a React application, you can define a schema with the following code:
```javascript
const schema = {
  Todo: {
    content: 'string',
    authorization: {
      allow: ['owner'],
    },
  },
};
```
This will allow the owner of a Todo record to create, read, update, and delete their own todos.

You can also specify the operations that the owner is allowed to perform:
```javascript
const schema = {
  Todo: {
    content: 'string',
    authorization: {
      allow: ['owner'].to(['create', 'read', 'update']),
    },
  },
};
```
This will allow the owner of a Todo record to create, read, and update their own todos, but not delete them.

In your React application, you can perform CRUD operations against the model using the `API.graphql` method with the `userPool` auth mode:
```javascript
import { API } from 'aws-amplify';

const todo = {
  content: 'My new todo',
};

API.graphql({
  query: 'createTodo',
  variables: { input: todo },
  authMode: 'AMAZON_COGNITO_USER_POOLS',
})
 .then((result) => console.log(result))
 .catch((error) => console.error(error));
```
Behind the scenes, Amplify will automatically add a `owner` field to each record which contains the record owner's identity information upon record creation. By default, the Cognito user pool's user information is populated into the `owner` field.

To prevent an owner from reassigning their record to another user, you can protect the owner field with a field-level authorization rule. For example:
```javascript
const schema = {
  Todo: {
    content: 'string',
    owner: 'string',
    authorization: {
      allow: ['owner'].to(['read', 'delete']),
    },
  },
};
```
You can also customize the owner field by specifying a custom `ownerField` in the authorization rule:
```javascript
const schema = {
  Todo: {
    content: 'string',
    author: 'string',
    authorization: {
      allow: ['ownerDefinedIn'].to(['author']),
    },
  },
};
```

The public authorization strategy grants everyone access to the API, which is protected behind the scenes with an API key. You can also override the authorization provider to use an unauthenticated IAM role from Cognito instead of an API key for public access.

To grant everyone access, use the public authorization strategy. Behind the scenes, the API will be protected with an API key.

To implement this in React, you can use the following code:
```javascript
const schema = {
  Todo: {
    content: 'string',
  },
  authorization: {
    allow: ['publicApiKey'],
  },
};
```
In your React application, you can perform CRUD operations against the model using the `client.models` object by specifying the `apiKey` auth mode.
```javascript
const client = generateClient(schema);

const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
  {
    authMode: 'apiKey',
  }
);
```
If the API key has not expired, you can extend the expiration date by deploying your app again. The API key expiration date will be set to `expiresInDays` days from the date when the app is deployed.
```javascript
export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 7,
    },
  },
});
```
You can rotate an API key if it was expired, compromised, or deleted. To rotate an API key, you can override the logical ID of the API key resource in the `amplify/backend` file. This will create a new API key with a new logical ID.
```javascript
const backend = defineBackend({
  auth,
  data,
});

backend.data.resources.cfnResources.cfnApiKey.overrideLogicalId(
  `recoverApiKey${new Date().getTime()}`
);
```
You can also override the authorization provider to use an Amazon Cognito identity pool's unauthenticated role. In this case, you can use the `identityPool` auth mode.
```javascript
const schema = {
  Todo: {
    content: 'string',
  },
  authorization: {
    allow: ['guest'],
  },
};
```
In your React application, you can perform CRUD operations against the model using the `client.models` object with the `identityPool` auth mode.
```javascript
const client = generateClient(schema);

const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
  {
    authMode: 'identityPool',
  }
);
```
Note that if you're not using the auto-generated `amplify_outputs.json` file, you must set the Amplify Library resource configuration's `allowGuestAccess` flag to `true`. This lets the Amplify Library use the unauthenticated role from your Cognito identity pool when your user isn't logged in.
```javascript
import Amplify from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(
  {
   ...outputs,
    Auth: {
      Cognito: {
        identityPoolId: config.aws_cognito_identity_pool_id,
        userPoolClientId: config.aws_user_pools_web_client_id,
        userPoolId: config.aws_user_pools_id,
        allowGuestAccess: true,
      },
    },
  }
);
```

The authenticated authorization strategy restricts record access to only signed-in users authenticated through IAM, Cognito, or OpenID Connect, applying the authorization rule to all users. It provides a simple way to make data private to all authenticated users.

To add signed-in user authorization rule, you can use the authenticated authorization strategy to restrict a record's access to every signed-in user. This is done by adding the allow.authenticated() method to the model's authorization rules.

For example, if you have a Todo model, you can add the authenticated authorization rule like this:
```javascript
const schema = new Schema({
  Todo: new Model({
    content: {
      type: 'string',
    },
  })
 .authorization(allow => [allow.authenticated()]),
});
```
This will allow anyone with a valid JWT token from the Cognito user pool to access all Todos.

To perform CRUD operations against the model, you can use the client.models.modelName method with the userPool auth mode. For example:
```javascript
import { DataStore } from 'aws-amplify';

const todo = new Todo({ content: 'My new todo' });
DataStore.save(todo, {
  authMode: 'userPool',
})
```
You can also override the authorization provider by specifying identityPool as the provider, which allows you to use an Unauthenticated Role from the Cognito identity pool for public access instead of an API key.

For example:
```javascript
const schema = new Schema({
  Todo: new Model({
    content: {
      type: 'string',
    },
  })
 .authorization(allow => [allow.authenticated('identityPool')]),
});
```
To perform CRUD operations against the model, you can use the client.models.modelName method with the iam auth mode. For example:
```javascript
import { DataStore } from 'aws-amplify';

const todo = new Todo({ content: 'My new todo' });
DataStore.save(todo, {
  authMode: 'identityPool',
})
```
Note that the user must be logged in for the Amplify Library to use the authenticated role from your Cognito identity pool. 

Additionally, you can also use OpenID Connect with authenticated authorization.

You can use the group authorization strategy to restrict access based on user groups. The user group authorization strategy allows restricting data access to specific user groups or groups defined dynamically on each data record.

To restrict access to a specific set of user groups, provide the group names in the groups parameter. For example, to only allow users that are part of the Admin user group to access the Salary model, you can use the following code:
```javascript
const schema = {
  Salary: {
    wag: 'float',
    currency: 'string',
  },
  auth: {
    rules: [
      {
        allow: {
          groups: ['Admin'],
        },
      },
    ],
  },
};
```
You can also allow access to multiple defined groups by passing an array of group names to the groups parameter. For example:
```javascript
const schema = {
  Salary: {
    wag: 'float',
    currency: 'string',
  },
  auth: {
    rules: [
      {
        allow: {
          groups: ['Admin', 'Leadership'],
        },
      },
    ],
  },
};
```
In your React application, you can perform CRUD operations against the model using the Amplify API. For example:
```javascript
import { API } from 'aws-amplify';

const salary = {
  wage: 50.25,
  currency: 'USD',
};

const response = await API.graphql({
  query: 'createSalary',
  variables: { input: salary },
  authMode: 'AMAZON_COGNITO_USER_POOLS',
});
```
To add authorization rules for dynamically set user groups, you can use the groupsDefinedIn or groupDefinedIn methods. For example:
```javascript
const schema = {
  Post: {
    title: 'string',
    groups: ['string'],
  },
  auth: {
    rules: [
      {
        allow: {
          groupsDefinedIn: 'groups',
        },
      },
    ],
  },
};
```
You can also access a user's groups from their session using the Auth category:
```javascript
import { Auth } from 'aws-amplify';

const session = await Auth.currentSession();
const groups = session.accessToken.payload['cognito:groups'] || [];

console.log('User groups:', groups);
```
Note that there are known limitations for real-time subscriptions when using dynamic group authorization. If you authorize based on a single group per record, then subscriptions are only supported if the user is part of 5 or fewer user groups. If you authorize via an array of groups, subscriptions are only supported if the user is part of 20 or fewer groups, and you can only authorize 20 or fewer user groups per record.

To use OpenID Connect as an authorization provider in your React application, you can configure it with private, owner, and group authorization strategies. To do this, add "oidc" to the authorization rule as the provider. You will also need to configure the OpenID Connect provider name, OpenID Connect provider domain, Client ID, Issued at TTL, and Auth Time TTL using the `oidcAuthorizationMode` property.

Here's an example of how to configure the authorization strategies with an "oidc" authorization provider. For owner and group-based authorization, you will also need to specify a custom identity and group claim.

```javascript
// amplify/data/resource.js
import { Amplify } from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

const schema = {
  Todo: {
    type: 'object',
    properties: {
      content: { type: 'string' },
    },
    required: ['content'],
  },
};

const authorizationModes = {
  defaultAuthorizationMode: 'oidc',
  oidcAuthorizationMode: {
    oidcProviderName: 'oidc-provider-name',
    oidcIssuerUrl: 'https://example.com',
    clientId: 'client-id',
    tokenExpiryFromAuthInSeconds: 300,
    tokenExpireFromIssueInSeconds: 600,
  },
};

Amplify.configure({
  aws_appsync_authenticationType: 'OIDC',
  aws_appsync_oidcProvider: {
    issuerUrl: authorizationModes.oidcAuthorizationMode.oidcIssuerUrl,
    clientId: authorizationModes.oidcAuthorizationMode.clientId,
  },
});

const { DataStore } = withSSRContext({ Amplify });

DataStore HubbubModel = {
  Todo: {
    authorization: {
      allow: [
        {
          owner: 'oidc',
          identityClaim: 'user_id',
        },
        {
          authenticated: 'oidc',
        },
        {
          groups: ['testGroupName'],
          withClaimIn: 'user_groups',
        },
      ],
    },
  },
};
```

To perform CRUD operations against the model, you can use the `DataStore` and specify the `oidc` auth mode.

```javascript
import Amplify from 'aws-amplify';
import { withSSRContext } from 'aws-amplify';

const { DataStore } = withSSRContext({ Amplify });

const todo = await DataStore.save(
  new Todo({ content: 'My new todo' }),
  { authMode: 'oidc' }
);

const todos = await DataStore.query(Todo, { authMode: 'oidc' });
```

Amplify Data supports various field types, including built-in and custom types. The built-in types include:

* ID: a unique identifier for an object, serialized as a string but not meant to be human-readable
* String: a UTF-8 character sequence
* Integer: an integer value between -(2^31) and 2^31-1
* Float: an IEEE 754 floating point value
* Boolean: a Boolean value, either true or false
* Date: an extended ISO 8601 date string in the format YYYY-MM-DD
* Time: an extended ISO 8601 time string in the format hh:mm:ss.sss
* Datetime: an extended ISO 8601 date and time string in the format YYYY-MM-DDThh:mm:ss.sssZ
* Timestamp: an integer value representing the number of seconds before or after 1970-01-01-T00:00Z
* Email: an email address in the format local-part@domain-part as defined by RFC 822
* JSON: a JSON string, automatically parsed and loaded in the resolver code as maps, lists, or scalar values
* Phone: a phone number, stored as a string and validated on the service side
* URL: a URL as defined by RFC 1738, with type enforcement on the schema part
* IP Address: a valid IPv4 or IPv6 address, with type enforcement for IPv4 and IPv6 patterns

You can specify custom field types in your schema. There are two ways to define custom types: inline and explicit. 

Inline definition: you can define a custom type directly in the model definition. For example:
```javascript
const schema = {
  Post: {
    location: {
      lat: 'float',
      long: 'float',
    },
    content: 'string',
  },
}
```
Explicit definition: you can define a custom type separately and reference it in the model definition. For example:
```javascript
const schema = {
  Location: {
    lat: 'float',
    long: 'float',
  },
  Post: {
    location: 'Location',
    content: 'string',
  },
}
```
You can also define enum field types, which have a similar developer experience to custom types. Enums can be defined using the short-hand or long-form approach.

Short-hand approach:
```javascript
const schema = {
  Post: {
    privacySetting: ['PRIVATE', 'FRIENDS_ONLY', 'PUBLIC'],
    content: 'string',
  },
}
```
Long-form approach:
```javascript
const schema = {
  PrivacySetting: ['PRIVATE', 'FRIENDS_ONLY', 'PUBLIC'],
  Post: {
    content: 'string',
    privacySetting: 'PrivacySetting',
  },
}
```
When creating a new item client-side, the enums are also type-enforced. For example:
```javascript
client.models.Post.create({
  content: 'hello',
  privacySetting: 'PRIVATE', // WORKS - value auto-completed
  // privacySetting: 'NOT_PUBLIC', // DOES NOT WORK - TYPE ERROR
})
```
You can list available enum values client-side using the `client.enums.<ENUM_NAME>.values()` API.

You can mark fields as required using the `.required()` modifier. For example:
```javascript
const schema = {
  Todo: {
    content: {
      type: 'string',
      required: true,
    },
  },
}
```
You can mark fields as arrays using the `.array()` modifier. For example:
```javascript
const schema = {
  Todo: {
    content: 'string',
    notes: {
      type: 'string',
      array: true,
    },
  },
}
```
You can assign default values for fields using the `.default(...)` modifier. For example:
```javascript
const schema = {
  Todo: {
    content: {
      type: 'string',
      default: 'My new Todo',
    },
  },
}
```
Note that the `.default(...)` modifier cannot be applied to required fields.

Identifiers for models can be defined using the `.identifier()` method. If this method is not used, a field named `id` of type `ID` will be automatically generated.

For example, consider a `Todo` model with a `content` field and a `completed` field. Without defining an identifier, the model will automatically have an `id` field:
```javascript
const schema = {
  Todo: {
    content: 'string',
    completed: 'boolean',
  }
}
```
You can use Amplify Data to define single-field and composite identifiers. A single-field identifier can be defined by passing the name of the field to the `.identifier()` method. For example:
```javascript
const schema = {
  Todo: {
    todoId: { type: 'id', required: true },
    content: 'string',
    completed: 'boolean',
  },
  identifiers: ['todoId']
}
```
This will create a `Todo` model with a `todoId` field as the identifier.

To create a new `Todo` item with a custom identifier:
```javascript
const client = /* your Amplify client */;
const todo = await client.models.Todo.create({ todoId: 'MyUniqueTodoId', content: 'Buy Milk', completed: false });
console.log(`New Todo created: ${todo.todoId}`);
```
A composite identifier can be defined by passing an array of field names to the `.identifier()` method. For example:
```javascript
const schema = {
  StoreBranch: {
    geoId: { type: 'id', required: true },
    name: { type: 'string', required: true },
    country: 'string',
    state: 'string',
    city: 'string',
    zipCode: 'string',
    streetAddress: 'string',
  },
  identifiers: ['geoId', 'name']
}
```
This will create a `StoreBranch` model with a composite identifier consisting of the `geoId` and `name` fields.

To retrieve a `StoreBranch` item with a composite identifier:
```javascript
const client = /* your Amplify client */;
const branch = await client.models.StoreBranch.get({ geoId: '123', name: 'Downtown' });
```

Data modeling capabilities allow you to define and customize your data model as part of a data schema. You can enhance your data model with various fields, customize their identifiers, apply authorization rules, or model relationships. Every data model automatically provides create, read, update, and delete API operations as well as real-time subscription events.

In React, you can define a data model using the Amplify schema builder. For example:
```javascript
import { a, defineData } from '@aws-amplify/backend';

const schema = a
 .schema({
    Customer: a
     .model({
        customerId: a.id().required(),
        name: a.string(),
        location: a.customType({
          lat: a.float().required(),
          long: a.float().required(),
        }),
        engagementStage: a.enum(["PROSPECT", "INTERESTED", "PURCHASED"]),
        collectionId: a.id(),
        collection: a.belongsTo("Collection", "collectionId")
      })
     .identifier(["customerId"]),
    Collection: a
     .model({
        customers: a.hasMany("Customer", "collectionId"), 
        tags: a.string().array(), 
        representativeId: a.id().required(),
      })
     .secondaryIndexes((index) => [index("representativeId")]),
  })
 .authorization((allow) => [allow.publicApiKey()]);

const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
```
This example defines a data model with two types: `Customer` and `Collection`. The `Customer` type has fields for `customerId`, `name`, `location`, `engagementStage`, `collectionId`, and `collection`. The `Collection` type has fields for `customers`, `tags`, and `representativeId`. The `identifier` method is used to customize the identifier for the `Customer` type, and the `secondaryIndexes` method is used to customize the secondary indexes for the `Collection` type.

If you are coming from Gen 1, you can continue to use the GraphQL Schema Definition Language (SDL) for defining your schema. However, it is strongly recommended to use the TypeScript-first schema builder experience in your project as it provides type safety and is the recommended way of working with Amplify going forward.

For example, you can define a schema using GraphQL SDL like this:
```javascript
import { defineData } from '@aws-amplify/backend';

const schema = /* GraphQL */`
  type Todo @model @auth(rules: [{ allow: owner }]) {
    content: String
    isDone: Boolean
  }
`;

const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
```
Note that some features available in Gen 1 GraphQL SDL are not available in Gen 2. You can see the feature matrix for features supported in Gen 2.

When modeling application data, you often need to establish relationships between different data models. In Amplify Data, you can create one-to-many, one-to-one, and many-to-many relationships in your Data schema. On the client-side, Amplify Data allows you to lazy or eager load related data.

There are three types of relationships: 
- One-to-many: Creates a one-to-many relationship between two models. For example, a Team has many Members, and a Member belongs to a Team.
- One-to-one: Creates a one-to-one relationship between two models. For example, a Customer has one Cart, and a Cart belongs to one Customer.
- Many-to-many: Creates two one-to-many relationships between the related models in a join table. For example, a Post has many Tags, and a Tag has many Posts.

To model a one-to-many relationship, you need to create a reference field on the child model that matches the type of the parent model's identifier, and then create a relationship field that references the reference field. For example, to create a one-to-many relationship between a Team and a Member, you would create a reference field called teamId on the Member model, and then create a relationship field called team that references the teamId field.

To create a "Has Many" relationship between records, you need to create the parent record and then create the child record and assign the parent. For example, to create a "Has Many" relationship between a Team and a Member, you would create a Team record and then create a Member record and assign the Team to the Member.

You can update a "Has Many" relationship by updating the child record and assigning a new parent. For example, to update a "Has Many" relationship between a Team and a Member, you would update the Member record and assign a new Team to the Member.

You can delete a "Has Many" relationship by setting the relationship value to null. For example, to delete a "Has Many" relationship between a Team and a Member, you would update the Member record and set the teamId field to null.

To load related data in a "Has Many" relationship, you can use the relationship field to fetch the related data. For example, to load the Members of a Team, you would use the members relationship field on the Team model to fetch the related Members.

To lazy load a "Has Many" relationship, you can use the relationship field to fetch the related data on demand. For example, to lazy load the Members of a Team, you would use the members relationship field on the Team model to fetch the related Members when needed.

To eagerly load a "Has Many" relationship, you can use the selectionSet parameter to fetch the related data when fetching the parent record. For example, to eagerly load the Members of a Team, you would use the selectionSet parameter to fetch the members relationship field when fetching the Team record.

To handle orphaned foreign keys on parent record deletion in a "Has One" relationship, you need to delete the child record when the parent record is deleted. For example, to handle orphaned foreign keys on parent record deletion in a "Has One" relationship between a Customer and a Cart, you would delete the Cart record when the Customer record is deleted.

To model a one-to-one relationship, you need to create a reference field on one of the models that matches the type of the other model's identifier, and then create a relationship field that references the reference field. For example, to create a one-to-one relationship between a Customer and a Cart, you would create a reference field called customerId on the Cart model, and then create a relationship field called customer that references the customerId field.

To create a "Has One" relationship between records, you need to create the parent record and then create the child record and assign the parent. For example, to create a "Has One" relationship between a Customer and a Cart, you would create a Customer record and then create a Cart record and assign the Customer to the Cart.

You can update a "Has One" relationship by updating the child record and assigning a new parent. For example, to update a "Has One" relationship between a Customer and a Cart, you would update the Cart record and assign a new Customer to the Cart.

You can delete a "Has One" relationship by setting the relationship value to null. For example, to delete a "Has One" relationship between a Customer and a Cart, you would update the Cart record and set the customerId field to null.

To load related data in a "Has One" relationship, you can use the relationship field to fetch the related data. For example, to load the Cart of a Customer, you would use the activeCart relationship field on the Customer model to fetch the related Cart.

To lazy load a "Has One" relationship, you can use the relationship field to fetch the related data on demand. For example, to lazy load the Cart of a Customer, you would use the activeCart relationship field on the Customer model to fetch the related Cart when needed.

To eagerly load a "Has One" relationship, you can use the selectionSet parameter to fetch the related data when fetching the parent record. For example, to eagerly load the Cart of a Customer, you would use the selectionSet parameter to fetch the activeCart relationship field when fetching the Customer record.

To model a many-to-many relationship, you need to create a join model that contains two one-to-many relationships between the related entities. For example, to model a many-to-many relationship between a Post and a Tag, you would create a PostTag join model that contains two one-to-many relationships between the Post and Tag entities.

To model multiple relationships between two models, you need to create separate reference fields and relationship fields for each relationship. For example, to model multiple relationships between a Post and a Person, you would create separate reference fields and relationship fields for the author and editor relationships.

To make relationships required or optional, you can use the required parameter on the reference field to determine if the relationship is required or not. For example, to make a relationship required, you would set the required parameter to true on the reference field.

You can optimize your list queries based on secondary indexes. For example, if you have a Customer model, you can query based on the customer's id identifier field by default, but you can add a secondary index based on the accountRepresentativeId to get a list of customers for a given account representative.

A secondary index consists of a hash key and, optionally, a sort key. Use the hash key to perform strict equality and the sort key for greater than, greater than or equal to, less than, less than or equal to, equals, begins with, and between operations.

To define a secondary index, you can use the secondaryIndexes modifier in your schema. For instance:
```javascript
const schema = {
  Customer: {
    name: 'string',
    phoneNumber: 'string',
    accountRepresentativeId: 'string',
  },
  secondaryIndexes: [
    {
      hashKey: 'accountRepresentativeId',
    },
  ],
};
```
The example client query below allows you to query for Customer records based on their accountRepresentativeId:
```javascript
import { API } from 'aws-amplify';

const queriedCustomers = await API.graphql({
  query: 'listCustomerByAccountRepresentativeId',
  variables: {
    accountRepresentativeId: 'YOUR_REP_ID',
  },
});
```
You can define sort keys to add a set of flexible filters to your query, such as greater than, greater than or equal to, less than, less than or equal to, equals, begins with, and between operations. To define a sort key, you can add a sortKeys property to your secondary index definition:
```javascript
const schema = {
  Customer: {
    name: 'string',
    phoneNumber: 'string',
    accountRepresentativeId: 'string',
  },
  secondaryIndexes: [
    {
      hashKey: 'accountRepresentativeId',
      sortKey: 'name',
    },
  ],
};
```
On the client side, you should find a new list query that's named after the hash key and sort keys. For example, in this case: listCustomerByAccountRepresentativeIdAndName. You can supply the filter as part of this new list query:
```javascript
import { API } from 'aws-amplify';

const queriedCustomers = await API.graphql({
  query: 'listCustomerByAccountRepresentativeIdAndName',
  variables: {
    accountRepresentativeId: 'YOUR_REP_ID',
    name: {
      beginsWith: 'Rene',
    },
  },
});
```
You can also customize the auto-generated query name under client.models.ModelName.listBy... by setting the queryField modifier.
```javascript
const schema = {
  Customer: {
    name: 'string',
    phoneNumber: 'string',
    accountRepresentativeId: 'string',
  },
  secondaryIndexes: [
    {
      hashKey: 'accountRepresentativeId',
      queryField: 'listByRep',
    },
  ],
};
```
In your client app code, you'll see the query updated under the Data client:
```javascript
import { API } from 'aws-amplify';

const queriedCustomers = await API.graphql({
  query: 'listByRep',
  variables: {
    accountRepresentativeId: 'YOUR_REP_ID',
  },
});
```
To customize the underlying DynamoDB's index name, you can optionally provide the name modifier.
```javascript
const schema = {
  Customer: {
    name: 'string',
    phoneNumber: 'string',
    accountRepresentativeId: 'string',
  },
  secondaryIndexes: [
    {
      hashKey: 'accountRepresentativeId',
      name: 'MyCustomIndexName',
    },
  ],
};
```
Amplify uses Amazon DynamoDB tables as the default data source for your models. For key-value databases, it is critical to model your access patterns with secondary indexes. Use the secondaryIndexes modifier to configure a secondary index. Amazon DynamoDB is a key-value and document database that delivers single-digit millisecond performance at any scale, but making it work for your access patterns requires a bit of forethought. DynamoDB query operations may use at most two attributes to efficiently query data. The first query argument passed to a query (the hash key) must use strict equality and the second attribute (the sort key) may use gt, ge, lt, le, eq, beginsWith, and between. DynamoDB can effectively implement a wide variety of access patterns that are powerful enough for the majority of applications.

To enable logging for your Amplify data resource, you can use Amazon CloudWatch logs. You can learn more about the logging and monitoring capabilities for your GraphQL API in the AWS AppSync documentation.

To enable default logging configuration, you can set the logging property to true in the call to defineData. For example:
```
const data = defineData({
  logging: true
});
```
This applies the default configuration, which includes:
- Excluding verbose content from logs
- No field-level logging
- Retaining logs for 1 week

You can customize individual configuration values by providing a DataLogConfig object. For example:
```
const data = defineData({
  logging: {
    excludeVerboseContent: false,
    fieldLogLevel: 'all',
    retention: '1 month'
  }
});
```
Be careful when setting excludeVerboseContent to false, as this can log full queries and user parameters, which may contain sensitive data. It's recommended to limit CloudWatch log access to only those roles or users who genuinely require it.

The logging configuration properties include:
- logging: enables default logging or overrides default fields with a DataLogConfig object
- DataLogConfig fields:
  - excludeVerboseContent: defaults to true, when false logs can contain request-level logs
  - fieldLogLevel: defaults to 'none', supported values include 'none', 'error', 'info', 'debug', and 'all'
  - retention: defaults to '1 week', supported values include '1 day', '3 days', '5 days', '1 week', '2 weeks', '1 month', and others up to 'infinite'

The Data manager page in the Amplify Console is a user-friendly interface for managing the backend GraphQL API data of an application. It allows you to create and update application data in real-time, eliminating the need to build separate admin views.

To use the Data manager, you need to have already created a data resource. If you haven't, you can visit the Data setup guide to get started.

To access the Data manager, follow these steps:
1. Log in to the Amplify console and choose your app.
2. Select the branch you want to access.
3. Select Data from the left navigation bar.
4. Then, select Data manager.

Once you're on the Data manager page, you can perform various actions:
- To create a record, select a table from the dropdown, click Create, enter your custom values, and submit.
- To update a record, select a table, choose a record, make changes, and submit.
- To delete a record(s), select a table, choose the record(s), and select delete item(s) from the Actions dropdown.
- To seed records, select a table, choose Auto-generate data from the Actions dropdown, specify the number of rows and constraints, and generate data. Note that you can generate up to 100 records at a time, but this feature is not available for tables with certain field types.
- To download records, select a table, choose an option from the Actions dropdown (Download selected items or Download all items), and your data will be downloaded as a CSV file.

To create, update, and delete application data using Amplify Libraries' Data client in a React application, you will need to have an application connected to the API. 

## Create an item

To create an item in your React application, first generate the Data client with your backend Data schema. Then, you can add an item like this:

```javascript
import { generateClient } from 'aws-amplify/data';

const client = generateClient();

const { errors, data: newTodo } = await client.models.Todo.create({
  content: "My new todo",
  isDone: true,
})
```

Note that you do not need to specify `createdAt` or `updatedAt` fields because Amplify automatically populates these fields for you.

## Update an item

To update the item, use the `update` function:

```javascript
const todo = {
  id: 'some_id',
  content: 'Updated content',
};

const { data: updatedTodo, errors } = await client.models.Todo.update(todo);
```

Note that you do not need to specify the `updatedAt` field. Amplify will automatically populate this field for you. If you specify extra input fields not expected by the API, this query will fail.

## Delete an item

You can then delete the Todo by using the delete mutation. To specify which item to delete, you only need to provide the `id` of that item:

```javascript
const toBeDeletedTodo = {
  id: '123123213'
}

const { data: deletedTodo, errors } = await client.models.Todo.delete(toBeDeletedTodo)
```

Note that when deleting items in many-to-many relationships, the join table records must be deleted before deleting the associated records.

## Troubleshoot unauthorized errors

If you get unauthorized errors, you may need to update your authorization mode. To override the default authorization mode defined in your **amplify/data/resource.ts** file, pass an `authMode` property to the request or the client. 

```javascript
const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
    isDone: true,
  },
  {
    authMode: 'apiKey',
  }
);
```

## Cancel create, update, and delete requests

You can cancel any mutation API request by calling `.cancel` on the mutation request promise that's returned by `.create(...)`, `.update(...)`, or `.delete(...)`.

```javascript
const promise = client.models.Todo.create({ content: 'New Todo' });

try {
  await promise;
} catch (error) {
  console.log(error);
  if (client.isCancelError(error)) {
    console.log(error.message); 
    // handle user cancellation logic
  }
}

// To cancel the above request
client.cancel(promise, 'my message for cancellation');
```

Remember that you need to ensure that the promise returned from `.create()`, `.update()`, and `.delete()` has not been modified.

In conclusion, you have now learned how to create, update, and delete application data using Amplify Libraries' Data client in a React application. The recommended next steps include using the API to query data and subscribe to real-time events to look for mutations in your data. Some resources that will help with this work include reading application data and subscribing to real-time events.

Amplify Data can be used with TanStack Query to implement optimistic UI, allowing CRUD operations to be rendered immediately on the UI before the request roundtrip has completed. Using Amplify Data with TanStack additionally makes it easy to render loading and error states, and allows you to rollback changes on the UI when API calls are unsuccessful.

To get started, you need to install TanStack Query and its devtools by running the command `npm i @tanstack/react-query @tanstack/react-query-devtools` in an existing Amplify project with a React frontend.

You then need to modify your Data schema to use a specific example, such as a "Real Estate Property" example, and deploy the changes to your backend cloud sandbox by running `npx ampx sandbox`.

Next, at the root of your project, you need to add the required TanStack Query imports and create a client. You can do this by creating a new file, for example `main.tsx`, and adding the following code:

```tsx
import React from 'react'
import ReactDOM from 'react-dom/client'
import App from './App.tsx'
import './index.css'
import { Amplify } from 'aws-amplify'
import outputs from '../amplify_outputs.json'
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";
import { ReactQueryDevtools } from "@tanstack/react-query-devtools";

Amplify.configure(outputs)

const queryClient = new QueryClient()

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <QueryClientProvider client={queryClient}>
      <App />
      <ReactQueryDevtools initialIsOpen={false} />
    </QueryClientProvider>
  </React.StrictMode>,
)
```

To render a list of items returned from the Amplify Data API, you can use the TanStack `useQuery` hook, passing in the Data API query as the `queryFn` parameter. For example:

```tsx
import { generateClient } from 'aws-amplify/data'
import type { Schema } from '../amplify/data/resource'
import { useQuery } from '@tanstack/react-query'

const client = generateClient<Schema>();

function App() {
  const {
    data: realEstateProperties,
    isLoading,
    isSuccess,
    isError: isErrorQuery,
  } = useQuery({
    queryKey: ["realEstateProperties"],
    queryFn: async () => {
      const response = await client.models.RealEstateProperty.list();

      const allRealEstateProperties = response.data;

      if (!allRealEstateProperties) return null;

      return allRealEstateProperties;
    },
  });
  // return...
}
```

To optimistically render a newly created item, you can use the TanStack `useMutation` hook, passing in the Amplify Data API mutation as the `mutationFn` parameter. For example:

```tsx
import { generateClient } from 'aws-amplify/api'
import type { Schema } from '../amplify/data/resource'
import { useQueryClient, useMutation } from '@tanstack/react-query'

const client = generateClient<Schema>();

function App() {
  const queryClient = useQueryClient();

  const createMutation = useMutation({
    mutationFn: async (input: { name: string, address: string }) => {
      const { data: newRealEstateProperty } = await client.models.RealEstateProperty.create(input)
      return newRealEstateProperty;
    },
    // When mutate is called:
    onMutate: async (newRealEstateProperty) => {
      // Cancel any outgoing refetches
      // (so they don't overwrite our optimistic update)
      await queryClient.cancelQueries({ queryKey: ["realEstateProperties"] });

      // Snapshot the previous value
      const previousRealEstateProperties = queryClient.getQueryData([
        "realEstateProperties",
      ]);

      // Optimistically update to the new value
      if (previousRealEstateProperties) {
        queryClient.setQueryData(["realEstateProperties"], (old: Schema["RealEstateProperty"]["type"][]) => [
         ...old,
          newRealEstateProperty,
        ]);
      }

      // Return a context object with the snapshotted value
      return { previousRealEstateProperties };
    },
    // If the mutation fails,
    // use the context returned from onMutate to rollback
    onError: (err, newRealEstateProperty, context) => {
      console.error("Error saving record:", err, newRealEstateProperty);
      if (context?.previousRealEstateProperties) {
        queryClient.setQueryData(
          ["realEstateProperties"],
          context.previousRealEstateProperties
        );
      }
    },
    // Always refetch after error or success:
    onSettled: () => {
      queryClient.invalidateQueries({ queryKey: ["realEstateProperties"] });
    },
  });
  // return...
}
```

To query a single item with TanStack Query, you can use the `useQuery` hook, passing in the `get` query as the `queryFn` parameter. For example:

```tsx
import { generateClient } from 'aws-amplify/data'
import type { Schema } from '../amplify/data/resource'
import { useQuery } from '@tanstack/react-query'

const client = generateClient<Schema>();

function App() {
  const currentRealEstatePropertyId = "SOME_ID"
  const {
    data: realEstateProperty,
    isLoading,
    isSuccess,
    isError: isErrorQuery,
  } = useQuery({
    queryKey: ["realEstateProperties", currentRealEstatePropertyId],
    queryFn: async () => {
      if (!currentRealEstatePropertyId) { return }

      const { data: property } = await client.models.RealEstateProperty.get({
        id: currentRealEstatePropertyId,
      });
      return property;
    },
  });
  // return...
}
```

To optimistically render updates for a record, you can use the TanStack `useMutation` hook, passing in the update mutation as the `mutationFn` parameter. For example:

```tsx
import { generateClient } from 'aws-amplify/data'
import type { Schema } from '../amplify/data/resource'
import { useQueryClient, useMutation } from "@tanstack/react-query";

const client = generateClient<Schema>();

function App() {
  const queryClient = useQueryClient();

  const updateMutation = useMutation({
    mutationFn: async (realEstatePropertyDetails: { id: string, name?: string, address?: string }) => {
      const { data: updatedProperty } = await client.models.RealEstateProperty.update(realEstatePropertyDetails);

      return updatedProperty;
    },
    // When mutate is called:
    onMutate: async (newRealEstateProperty: { id: string, name?: string, address?: string }) => {
      // Cancel any outgoing refetches
      // (so they don't overwrite our optimistic update)
      await queryClient.cancelQueries({
        queryKey: ["realEstateProperties", newRealEstateProperty.id],
      });

      await queryClient.cancelQueries({
        queryKey: ["realEstateProperties"],
      });

      // Snapshot the previous value
      const previousRealEstateProperty = queryClient.getQueryData([
        "realEstateProperties",
        newRealEstateProperty.id,
      ]);

      // Optimistically update to the new value
      if (previousRealEstateProperty) {
        queryClient.setQueryData(
          ["realEstateProperties", newRealEstateProperty.id],
          /**
           * `newRealEstateProperty` will at first only include updated values for
           * the record. To avoid only rendering optimistic values for updated
           * fields on the UI, include the previous values for all fields:
           */
          {...previousRealEstateProperty,...newRealEstateProperty }
        );
      }

      // Return a context with the previous and new realEstateProperty
      return { previousRealEstateProperty, newRealEstateProperty };
    },
    // If the mutation fails, use the context we returned above
    onError: (err, newRealEstateProperty, context) => {
      console.error("Error updating record:", err, newRealEstateProperty);
      if (context?.previousRealEstateProperty) {
        queryClient.setQueryData(
          ["realEstateProperties", context.newRealEstateProperty.id],
          context.previousRealEstateProperty
        );
      }
    },
    // Always refetch after error or success:
    onSettled: (newRealEstateProperty) => {
      if (newRealEstateProperty) {
        queryClient.invalidateQueries({
          queryKey: ["realEstateProperties", newRealEstateProperty.id],
        });
        queryClient.invalidateQueries({
          queryKey: ["realEstateProperties"],
        });
      }
    },
  });
  // return...
}
```

To optimistically render deleting a record, you can use the TanStack `useMutation` hook, passing in the delete mutation as the `mutationFn` parameter. For example:

```tsx
import { generateClient } from 'aws-amplify/data'
import type { Schema } from '../amplify/data/resource'
import { useQueryClient, useMutation } from '@tanstack/react-query'

const client = generateClient<Schema>();

function App() {
  const queryClient = useQueryClient();

  const deleteMutation = useMutation({
    mutationFn: async (realEstatePropertyDetails: { id: string }) => {
      const { data: deletedProperty } = await client.models.RealEstateProperty.delete(realEstatePropertyDetails);
      return deletedProperty;
    },
    // When mutate is called:
    onMutate: async (newRealEstateProperty) => {
      // Cancel any outgoing refetches
      // (so they don't overwrite our optimistic update)
      await queryClient.cancelQueries({
        queryKey: ["realEstateProperties", newRealEstateProperty.id],
      });

      await queryClient.cancelQueries({
        queryKey: ["realEstateProperties"],
      });

      // Snapshot the previous value
      const previousRealEstateProperty = queryClient.getQueryData([
        "realEstateProperties",
        newRealEstateProperty.id,
      ]);

      // Optimistically update to the new value
      if (previousRealEstateProperty) {
        queryClient.setQueryData(
          ["realEstateProperties", newRealEstateProperty.id],
          newRealEstateProperty
        );
      }

      // Return a context with the previous and new realEstateProperty
      return { previousRealEstateProperty, newRealEstateProperty };
    },
    // If the mutation fails, use the context we returned above
    onError: (err, newRealEstateProperty, context) => {
      console.error("Error deleting record:", err, newRealEstateProperty);
      if (context?.previousRealEstateProperty) {
        queryClient.setQueryData(
          ["realEstateProperties", context.newRealEstateProperty.id],
          context.previousRealEstateProperty
        );
      }
    },
    // Always refetch after error or success:
    onSettled: (newRealEstateProperty) => {
      if (newRealEstateProperty) {
        queryClient.invalidateQueries({
          queryKey: ["realEstateProperties", newRealEstateProperty.id],
        });
        queryClient.invalidateQueries({
          queryKey: ["realEstateProperties"],
        });
      }
    },
  });
  // return...
}
```

To render loading and error states for optimistically rendered data, you can use the `isLoading` and `isError` states returned by the `useQuery` and `useMutation` hooks. For example:

```tsx
function App() {
  const {
    data: realEstateProperties,
    isLoading,
    isSuccess,
    isError: isErrorQuery,
  } = useQuery({
    queryKey: ["realEstateProperties"],
    queryFn: async () => {
      const response = await client.models.RealEstateProperty.list();

      const allRealEstateProperties = response.data;

      if (!allRealEstateProperties) return null;

      return allRealEstateProperties;
    },
  });

  if (isLoading) {
    return <div>Loading...</div>;
  }

  if (isErrorQuery) {
    return <div>Error loading data</div>;
  }

  // return...
}
```

You can also use the `useIsFetching` hook from TanStack Query to render a global loading indicator. For example:

```tsx
function GlobalLoadingIndicator() {
  const isFetching = useIsFetching();

  return isFetching? <div>Loading...</div> : null;
}
```

This is a basic example of how to implement optimistic UI with Amplify Data and TanStack Query. You can customize the code to fit your specific needs and requirements.

You can modify the underlying AWS resources generated by the Amplify GraphQL API to optimize the deployed stack for your specific use case. Amplify uses a variety of auto-generated AWS services and resources, and you can customize these resources using CDK constructs.

To access the underlying resources, you can use CDK "L2" or "L1" constructs. You can access the generated resources as L2 constructs via the `.resources` property on the returned stack or access the generated resources as L1 constructs using the `.resources.cfnResources` property.

For example, to modify the resources, you can use the following code:
```typescript
const { cfnResources } = backend.data.resources;
```
You can then customize the resources, such as enabling X-Ray tracing for the AppSync GraphQL API:
```typescript
cfnResources.cfnGraphqlApi.xrayEnabled = true;
```
You can also modify the resources generated for specific data models, such as enabling time-to-live on a DynamoDB table:
```typescript
cfnResources.amplifyDynamoDbTables["Todo"].timeToLiveAttribute = {
  attributeName: "ttl",
  enabled: true,
};
```
Additionally, you can configure various settings for DynamoDB tables, such as:
* Billing mode: `cfnResources.amplifyDynamoDbTables['Todo'].billingMode = BillingMode.PAY_PER_REQUEST;`
* Provisioned throughput: `cfnResources.amplifyDynamoDbTables["Todo"].provisionedThroughput = { readCapacityUnits: 5, writeCapacityUnits: 5 };`
* Point-in-time recovery: `cfnResources.amplifyDynamoDbTables['Todo'].pointInTimeRecoveryEnabled = true;`

These are just a few examples of how you can customize the underlying AWS resources generated by the Amplify GraphQL API.

You can read application data using the Amplify Data client. This guide reviews the difference between reading data and getting data, how to filter query results to get just the data you need, and how to paginate results to make your data more manageable. You will also learn how to cancel these requests when needed.

Before you begin, you need an application connected to the API and data already created to view.

Queries are used to read data through the API and include the `list` and `get` operations. Amplify Data automatically creates `list` and `get` queries for any model in your schema. The `list` query retrieves multiple items, such as Todo items, without needing to specify an identifier for a particular record. This is best suited for getting an overview or summary of items, or for enhancing the `list` operation to filter the items by specific criteria. When you want to query a single entry by an identifier, you would use `get` to retrieve a specific Todo item.

You can list items by first generating the Data client with your backend Data schema. Then you can list items of your desired model. For example, to list all Todo items, you can use the following code:
```javascript
const client = generateClient<Schema>();
const { data: todos, errors } = await client.models.Todo.list();
```
To get a specific Todo item, you can use the following code:
```javascript
const { data: todo, errors } = await client.models.Todo.get({
  id: '...',
});
```
Each API request uses an authorization mode. If you get unauthorized errors, you may need to update your authorization mode. To override the default authorization mode defined in your amplify/data/resource file, pass an `authMode` property to the request or the client.

You can filter list queries by using the `filter` parameter. For example, to filter Todo items by content, you can use the following code:
```javascript
const { data: todos, errors } = await client.models.Todo.list({
  filter: {
    content: {
      beginsWith: 'hello'
    }
  }
});
```
You can also combine filters with `and`, `or`, and `not` Boolean logic.

To paginate list queries, you can use the `nextToken` and `limit` input variables. The `limit` variable limits how many results are returned. The response will include a `nextToken` you can use to request the next page of data.

In React, you can use the `usePagination` hook in Amplify UI to help with managing the pagination user experience. For example:
```javascript
import * as React from 'react';
import { Pagination } from '@aws-amplify/ui-react';

export const PaginationHasMorePagesExample = () => {
  const [pageTokens, setPageTokens] = React.useState([null]);
  const [currentPageIndex, setCurrentPageIndex] = React.useState(1);
  const [hasMorePages, setHasMorePages] = React.useState(true);

  const handleNextPage = async () => {
    if (hasMorePages && currentPageIndex === pageTokens.length) {
      const { data: todos, nextToken } = await client.models.Todo.list({
        nextToken: pageTokens[pageTokens.length - 1]
      });

      if (!nextToken) {
        setHasMorePages(false);
      }

      setPageTokens([...pageTokens, nextToken]);
    }

    setCurrentPageIndex(currentPageIndex + 1);
  };

  return (
    <Pagination
      currentPage={currentPageIndex}
      totalPages={pageTokens.length}
      hasMorePages={hasMorePages}
      onNext={handleNextPage}
      onPrevious={() => setCurrentPageIndex(currentPageIndex - 1)}
      onChange={(pageIndex) => setCurrentPageIndex(pageIndex)}
    />
  );
};
```
You can also fetch only the data you need with a custom selection set. A custom selection set allows consumers to specify, on a per-call basis, the fields the consumer wants to retrieve.

To cancel read requests, you can call `.cancel` on the query request promise that's returned by `.list(...)` or `.get(...)`.

Finally, you can use TypeScript type helpers for Amplify Data to specify data model types for type generics. For example:
```typescript
import { type Schema } from '@/amplify/data/resource';

type Post = Schema['Post']['type'];

const [posts, setPosts] = useState<Post[]>([]);
```
You can also combine the `Schema["MODEL_NAME"]["type"]` type with the `SelectionSet` helper type to describe the return type of API requests using the `selectionSet` parameter.

In this guide, you will learn how to set up Amplify Data. This includes building a real-time API and database using TypeScript to define your data model, and securing your API with authorization rules. We will also explore using AWS Lambda to scale to custom use cases.

Before you begin, you will need:

* Node.js v18.16.0 or later
* npm v6.14.4 or later
* git v2.14.1 or later

With Amplify Data, you can build a secure, real-time API backed by a database in minutes. After you define your data model using TypeScript, Amplify will deploy a real-time API for you. This API is powered by AWS AppSync and connected to an Amazon DynamoDB database. You can secure your API with authorization rules and scale to custom use cases with AWS Lambda.

## Building your data backend

If you've run `npm create amplify@latest` already, you should see an `amplify/data/resource.ts` file, which is the central location to configure your data backend. The most important element is the `schema` object, which defines your backend data models (`a.model()`) and custom queries (`a.query()`), mutations (`a.mutation()`), and subscriptions (`a.subscription()`).

```typescript
const schema = a.schema({
  Todo: a.model({
      content: a.string(),
      isDone: a.boolean()
    })
   .authorization(allow => [allow.publicApiKey()])
});
```

Every `a.model()` automatically creates the following resources in the cloud:

* a DynamoDB database table to store records
* query and mutation APIs to create, read (list/get), update, and delete records
* `createdAt` and `updatedAt` fields that help you keep track of when each record was initially created or when it was last updated
* real-time APIs to subscribe for create, update, and delete events of records

The `allow.publicApiKey()` rule designates that anyone authenticated using an API key can create, read, update, and delete todos.

To deploy these resources to your cloud sandbox, run the following CLI command in your terminal:

```bash
npx ampx sandbox
```

## Connect your application code to the data backend

Once the cloud sandbox is up and running, it will also create an `amplify_outputs.json` file, which includes the relevant connection information to your data backend, like your API endpoint URL and API key.

To connect your frontend code to your backend, you need to:

1. Configure the Amplify library with the Amplify client configuration file (`amplify_outputs.json`)
2. Generate a new API client from the Amplify library
3. Make an API request with end-to-end type-safety

Let's install the Amplify client library to your project:

```bash
npm add aws-amplify
```

In your app's entry point, typically **main.tsx** for React apps created using Vite, make the following edits:

```tsx
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
```

## Write data to your backend

Let's first add a button to create a new todo item. To make a "create Todo" API request, generate the data client using `generateClient()` in your frontend code, and then call `.create()` operation for the Todo model.

```tsx
const client = generateClient<Schema>()

export default function TodoList() {
  const createTodo = async () => {
    await client.models.Todo.create({
      content: window.prompt("Todo content?"),
      isDone: false
    })
  }

  return <div>
    <button onClick={createTodo}>Add new todo</button>
  </div>
}
```

## Read data from your backend

Next, list all your todos and then refetch the todos after a todo has been added:

```tsx
import { useState, useEffect } from "react";
import type { Schema } from "../amplify/data/resource";
import { generateClient } from "aws-amplify/data";

const client = generateClient<Schema>();

export default function TodoList() {
  const [todos, setTodos] = useState<Schema["Todo"]["type"][]>([]);

  const fetchTodos = async () => {
    const { data: items, errors } = await client.models.Todo.list();
    setTodos(items);
  };

  useEffect(() => {
    fetchTodos();
  }, []);

  const createTodo = async () => {
    await client.models.Todo.create({
      content: window.prompt("Todo content?"),
      isDone: false,
    });

    fetchTodos();
  }

  return (
    <div>
      <button onClick={createTodo}>Add new todo</button>
      <ul>
        {todos.map(({ id, content }) => (
          <li key={id}>{content}</li>
        ))}
      </ul>
    </div>
  );
}
```

## Subscribe to real-time updates

You can also use `observeQuery` to subscribe to a live feed of your backend data. Let's refactor the code to use a real-time observeQuery instead.

```tsx
import type { Schema } from "../amplify/data/resource";
import { useState, useEffect } from "react";
import { generateClient } from "aws-amplify/data";

const client = generateClient<Schema>();

export default function TodoList() {
  const [todos, setTodos] = useState<Schema["Todo"]["type"][]>([]);

  useEffect(() => {
    const sub = client.models.Todo.observeQuery().subscribe({
      next: ({ items }) => {
        setTodos([...items]);
      },
    });

    return () => sub.unsubscribe();
  }, []);

  const createTodo = async () => {
    await client.models.Todo.create({
      content: window.prompt("Todo content?"),
      isDone: false,
    });
    // no more manual refetchTodos required!
    // - fetchTodos()
  };

  return (
    <div>
      <button onClick={createTodo}>Add new todo</button>
      <ul>
        {todos.map(({ id, content }) => (
          <li key={id}>{content}</li>
        ))}
      </ul>
    </div>
  );
}
```

## Conclusion

Success! You've learned how to create your first real-time API and database with Amplify Data.

### Next steps

There's so much more to discover with Amplify Data. Learn more about:

* How to model your database table and their access patterns
* Secure your API with fine-grained authorization rules
* Create relationships between different database models
* Add custom business logic

To subscribe to real-time events in your React application using AWS Amplify, you will need to set up a real-time list query and a real-time event subscription. 

First, ensure you have an application connected to the API and data already created to modify. 

To set up a real-time list query, use `observeQuery` to get a real-time list of your app data at all times. You can integrate `observeQuery` with React's `useState` and `useEffect` hooks. 

Here's an example:

```javascript
import { useState, useEffect } from 'react';
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource';

type Todo = Schema['Todo']['type'];

const client = generateClient<Schema>();

export default function MyComponent() {
  const [todos, setTodos] = useState<Todo[]>([]);

  useEffect(() => {
    const sub = client.models.Todo.observeQuery().subscribe({
      next: ({ items, isSynced }) => {
        setTodos([...items]);
      },
    });
    return () => sub.unsubscribe();
  }, []);

  return (
    <ul>
      {todos.map((todo) => (
        <li key={todo.id}>{todo.content}</li>
      ))}
    </ul>
  );
}
```

To set up a real-time event subscription, use the `onCreate`, `onUpdate`, or `onDelete` methods provided by the `client.models.Todo` object. 

Here's an example:

```javascript
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource';

const client = generateClient<Schema>();

// Subscribe to creation of Todo
const createSub = client.models.Todo.onCreate().subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});

// Subscribe to update of Todo
const updateSub = client.models.Todo.onUpdate().subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});

// Subscribe to deletion of Todo
const deleteSub = client.models.Todo.onDelete().subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});

// Stop receiving data updates from the subscription
createSub.unsubscribe();
updateSub.unsubscribe();
deleteSub.unsubscribe();
```

If you want to filter your subscriptions, you can pass a `filter` argument to the `onCreate`, `onUpdate`, or `onDelete` methods. 

Here's an example:

```javascript
const sub = client.models.Todo.onCreate({
  filter: {
    content: {
      contains: 'groceries',
    },
  },
}).subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});
```

To unsubscribe from a subscription, call the `unsubscribe` method on the subscription object. 

Here's an example:

```javascript
sub.unsubscribe();
```

When dealing with related model mutations, note that mutations do not trigger real-time updates for related models. If you need to update a related model when a mutation occurs, you must manually "touch" the relevant record.

To monitor the connection state for changes, use the `Hub` local eventing system. 

Here's an example:

```javascript
import { CONNECTION_STATE_CHANGE, ConnectionState } from 'aws-amplify/data';
import { Hub } from 'aws-amplify/utils';

Hub.listen('api', (data: any) => {
  const { payload } = data;
  if (payload.event === CONNECTION_STATE_CHANGE) {
    const connectionState = payload.data.connectionState as ConnectionState;
    console.log(connectionState);
  }
});
```

Connection states include `Connected`, `ConnectedPendingDisconnect`, `ConnectedPendingKeepAlive`, `ConnectedPendingNetwork`, `Connecting`, `ConnectionDisrupted`, `ConnectionDisruptedPendingNetwork`, and `Disconnected`. 

When using server-side subscription filters, be aware of the limitations. For example, specifying an empty object `{}` as a filter is not recommended, and using dynamic group authorization may have limitations. 

To troubleshoot connection issues and automated reconnection, monitor the subscription status for changes and handle errors accordingly. Depending on your use case, you may want to take action to catch up when your app comes back online after being offline. 

In conclusion, setting up real-time events in your React application using AWS Amplify involves creating a real-time list query and a real-time event subscription, filtering subscriptions, and handling connection states. Be sure to unsubscribe from subscriptions when no longer needed and monitor connection states for changes. 

For further customization, consider exploring the AWS Amplify documentation on data modeling, authentication, and authorization. 

Next steps may include continuing to build out and customize your information architecture for your data, customizing your auth rules, customizing your data model, and adding custom business logic. 

Note that the examples provided are in JavaScript and use React hooks for state management. The code snippets demonstrate how to set up real-time events, filter subscriptions, and handle connection states. 

By following these steps and using the provided code snippets, you can effectively set up real-time events in your React application using AWS Amplify.

The Storage and GraphQL API categories in AWS Amplify can be used together to associate a file, such as an image or video, with a particular record. For example, you might create a User model with a profile picture, or a Post model with an associated image.

To set up your project, follow the instructions in the Quickstart guide. 

Next, define your model by opening the `amplify/data/resource.ts` file and adding the model as shown below:

```typescript
const schema = a.schema({
  Song: a
   .model({
      id: a.id().required(),
      name: a.string().required(),
      coverArtPath: a.string(),
    })
   .authorization((allow) => [allow.publicApiKey()]),
});
```

Then, configure Storage by creating a file `amplify/storage/resource.ts` and adding the following code:

```typescript
export const storage = defineStorage({
  name: "amplify-gen2-files",
  access: (allow) => ({
    "images/*": [allow.authenticated.to(["read", "write", "delete"])],
  }),
});
```

Configure the storage in the `amplify/backend.ts` file as demonstrated below:

```typescript
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { storage } from "./storage/resource";

export const backend = defineBackend({
  auth,
  data,
  storage,
});
```

To create a record with an associated file, use the Amplify Data client to create a record, upload a file to Storage, and then update the record to associate it with the uploaded file. 

Here's how to create a record and associate it with a file in React:

```typescript
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

// Create the API record:
const response = await client.models.Song.create({
  name: `My first song`,
});

const song = response.data;

if (!song) return;

// Upload the Storage file:
const result = await uploadData({
  path: `images/${song.id}-${file.name}`,
  data: file,
  options: {
    contentType: "image/png", // contentType is optional
  },
}).result;

// Add the file association to the record:
const updateResponse = await client.models.Song.update({
  id: song.id,
  coverArtPath: result?.path,
});

const updatedSong = updateResponse.data;
```

To add or update a file for an associated record, update the record with the path returned by the Storage upload.

Here's how to add or update a file for an associated record in React:

```typescript
// Upload the Storage file:
const result = await uploadData({
  path: `images/${currentSong.id}-${file.name}`,
  data: file,
  options: {
    contentType: "image/png", // contentType is optional
  },
}).result;

// Add the file association to the record:
const response = await client.models.Song.update({
  id: currentSong.id,
  coverArtPath: result?.path,
});

const updatedSong = response.data;
```

To query a record and retrieve the associated file, first query the record, then use Storage to get the signed URL.

Here's how to query a record and retrieve the associated file in React:

```typescript
const response = await client.models.Song.get({
  id: currentSong.id,
});

const song = response.data;

// If the record has no associated file, we can return early.
if (!song?.coverArtPath) return;

// Retrieve the signed URL:
const signedURL = await getUrl({ path: song.coverArtPath });
```

To delete and remove files associated with API records, you can remove the file association, continue to persist both file and record, remove the record association and delete the file, or delete both file and record.

Here's how to delete and remove files associated with API records in React:

```typescript
// Remove the file association, continue to persist both file and record
const updatedSong = await client.models.Song.update({
  id: song.id,
  coverArtPath: null,
});

// Remove the record association and delete the file
await remove({ path: song.coverArtPath });

// Delete both file and record
await client.models.Song.delete({ id: song.id });
```

To work with multiple files, you can add a list of file keys to the record.

Here's how to create a record with multiple associated files in React:

```typescript
// Upload all files to Storage:
const imagePaths = await Promise.all(
  Array.from(e.target.files).map(async (file) => {
    const result = await uploadData({
      path: `images/${photoAlbum.id}-${file.name}`,
      data: file,
      options: {
        contentType: "image/png", // contentType is optional
      },
    }).result;

    return result.path;
  })
);

// Add the file association to the record:
const updateResponse = await client.models.PhotoAlbum.update({
  id: photoAlbum.id,
  imagePaths: imagePaths,
});
```

To add new files to an associated record, update the record with the paths returned by the Storage uploads.

Here's how to add new files to an associated record in React:

```typescript
// Upload all files to Storage:
const newimagePaths = await Promise.all(
  Array.from(e.target.files).map(async (file) => {
    const result = await uploadData({
      path: `images/${currentPhotoAlbum.id}-${file.name}`,
      data: file,
      options: {
        contentType: "image/png", // contentType is optional
      },
    }).result;

    return result.path;
  })
);

// Update the record with the merged file associations:
const response = await client.models.PhotoAlbum.update({
  id: currentPhotoAlbum.id,
  imagePaths: [...newimagePaths,...photoAlbum.imagePaths],
});
```

To update the file for an associated record, update the list of file keys.

Here's how to update the file for an associated record in React:

```typescript
// Upload new file to Storage:
const result = await uploadData({
  path: `images/${currentPhotoAlbum.id}-${file.name}`,
  data: file,
  options: {
    contentType: "image/png", // contentType is optional
  },
}).result;

// Update the record with the updated file associations:
const response = await client.models.PhotoAlbum.update({
  id: currentPhotoAlbum.id,
  imagePaths: [
   ...photoAlbum.imagePaths.filter((path) => path!== lastImagePath),
    result.path,
  ],
});
```

To query a record and retrieve the associated files, first query the record, then use Storage to retrieve all of the signed URLs.

Here's how to query a record and retrieve the associated files in React:

```typescript
// Query the record to get the file paths:
const response = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});

const photoAlbum = response.data;

// If the record has no associated files, we can return early.
if (!photoAlbum?.imagePaths) return;

// Retrieve the signed URLs for the associated images:
const signedUrls = await Promise.all(
  photoAlbum.imagePaths.map(async (imagePath) => {
    if (!imagePath) return;
    return await getUrl({ path: imagePath });
  })
);
```

To delete and remove files associated with API records when working with multiple files, you can remove the file association, continue to persist both files and record, remove the record association and delete the files, or delete both files and record.

Here's how to delete and remove files associated with API records when working with multiple files in React:

```typescript
// Remove the file association, continue to persist both files and record
const updatedPhotoAlbum = await client.models.PhotoAlbum.update({
  id: photoAlbum.id,
  imagePaths: null,
});

// Remove the record association and delete the files
await Promise.all(
  photoAlbum?.imagePaths.map(async (imagePath) => {
    if (!imagePath) return;
    await remove({ path: imagePath });
  })
);

// Delete both files and record
await client.models.PhotoAlbum.delete({ id: photoAlbum.id });
```

It's also important to consider data consistency when working with records and files. The recommended access patterns may remove deleted files, but favor leaving orphans over leaving records that point to non-existent files. This optimizes for read latency by ensuring clients rarely attempt to fetch a non-existent file from Storage. However, any app that deletes files can inherently cause records on-device to point to non-existent files. 

To handle this, you can use real-time data / GraphQL subscriptions to keep your app's local state in sync with the global state. You can also add meaningful error handling around these cases and retry failed operations. 

Here's an example of a complete React application that demonstrates how to work with files and records:

```typescript
import React, { useState } from "react";
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl, remove } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

function App() {
  const [currentSong, setCurrentSong] = useState(null);
  const [currentImageUrl, setCurrentImageUrl] = useState(null);

  async function createSongWithImage(e) {
    // Create the API record:
    const response = await client.models.Song.create({
      name: `My first song`,
    });

    const song = response.data;

    if (!song) return;

    // Upload the Storage file:
    const result = await uploadData({
      path: `images/${song.id}-${e.target.files[0].name}`,
      data: e.target.files[0],
      options: {
        contentType: "image/png", // contentType is optional
      },
    }).result;

    // Add the file association to the record:
    const updateResponse = await client.models.Song.update({
      id: song.id,
      coverArtPath: result?.path,
    });

    const updatedSong = updateResponse.data;
    setCurrentSong(updatedSong);

    // If the record has no associated file, we can return early.
    if (!updatedSong?.coverArtPath) return;

    // Retrieve the file's signed URL:
    const signedURL = await getUrl({ path: updatedSong.coverArtPath });
    setCurrentImageUrl(signedURL.url.toString());
  }

  //...
}
```

This application demonstrates how to create a song with an associated image, add a new image to a song, get the image for a song, remove an image from a song, delete an image for a song, and delete a song and its associated image. It also handles data consistency by favoring leaving orphans over leaving records that point to non-existent files.

Amplify code-first DX (Gen 2) offers fullstack branch deployments that allow you to automatically deploy infrastructure and application code changes from feature branches. This enables testing changes in an isolated environment before merging to the main branch.

To set up feature branch deployments, start by logging in to the Amplify console and choosing your app. Navigate to App settings > Branch settings, select Edit, and enable Branch auto-detection and Branch auto-disconnection. This will connect any branch in your repository automatically and ensure that deleted branches are also disconnected.

You can define a pattern to connect only certain branches, such as setting dev, staging, and feature/* to connect all three branch types. Once you've enabled auto-detection, push a commit to your feature/A and staging branches that match the pattern, and you should start seeing deployments on the console page.

To promote changes to production, follow the normal Git-based workflow. Make a change in your feature/A branch, commit and push the changes, and then submit a pull request to your main branch. Once your team has validated the changes, merge the pull request to main, which will initiate a build on your main branch and update any frontend or backend resources that you changed.

To generate the config for a branch environment, you can run the following command in your terminal:
```bash
npx ampx generate outputs --app-id <your-amplify-app-id> --branch <your-git-branch-name> --out-dir <path/to/config>
```
However, for Android and Flutter, you may need to specify a different output directory. For Android, add a "raw" folder under app/src/main/res directory if it doesn't exist, and run:
```bash
npx ampx generate outputs --app-id <your-amplify-app-id> --branch <your-git-branch-name> --out-dir app/src/main/res/raw
```
For Flutter, run:
```bash
npx ampx generate outputs --app-id <your-amplify-app-id> --branch <your-git-branch-name> --format dart --out-dir lib
```
For Swift, simply run:
```bash
npx ampx generate outputs --app-id <your-amplify-app-id> --branch <your-git-branch-name>
```
Then, drag and drop the generated configuration file to your Xcode project. 

For example in a React application, after running the command to generate the config, you would import and use the config in your React app like this:
```javascript
import Amplify from 'aws-amplify';
import awsconfig from './aws-exports';

Amplify.configure(awsconfig);
```

This guide explains how to set up a cross-account deployment pipeline for applications built with AWS Amplify Gen 2. The pipeline will use Amazon CodeCatalyst and AWS Amplify Hosting.

First, you need to set up an Amazon CodeCatalyst space. This involves creating a new space and following the steps outlined in the Amazon CodeCatalyst guide.

Next, you need to deploy a full-stack Amplify Gen 2 app. You can use the Next.js starter template to create a repository in your GitHub account, and then sign in to the AWS Management Console to create a new app in the Amplify console. Once you've selected the repository and reviewed the details, you can save and deploy the app.

After deploying the app, you need to update the build specification. This involves adding a command to the build spec to generate the latest amplify_outputs.json file for the specified environment. You can do this by adding the following command to the build spec: `npx ampx generate outputs --branch $AWS_BRANCH --app-id $AWS_APP_ID`.

You also need to disable automatic builds on the branch. You can do this by navigating to the app in the Amplify console, selecting App settings, and then selecting Branch settings. From there, you can select the branch and choose Disable auto build from the Actions dropdown menu.

To trigger a build without committing code to your Git repository, you can set up an incoming webhook. You can create an incoming webhook in the Amplify Console by navigating to the app, selecting Hosting, and then selecting Build settings. From there, you can select Create webhook and provide a name for the webhook, as well as select the target branch to build on incoming webhook requests.

Once you've set up the incoming webhook, you can create a new Amazon CodeCatalyst project. This involves following the steps outlined in the Amazon CodeCatalyst guide to create a new project.

To achieve a cross-account deployment, you need to implement the previous steps in a different AWS account. You also need to add the target AWS account to the CodeCatalyst space, and create an IAM role in the target AWS account that will be assumed by the staging environment to perform actions and deploy resources in the production environment.

Finally, you can create a workflow in the Amazon CodeCatalyst project. A workflow is an automated procedure that describes how to build, test, and deploy your code as part of a continuous integration and continuous delivery system. You can create a workflow by navigating to the CI/CD feature in the CodeCatalyst project, selecting Workflows, and then selecting Create workflow.

In the workflow, you can add build actions that deploy the backend for your Amplify Gen 2 app, trigger frontend builds using incoming webhooks, and perform other actions as needed. You can also add environment variables, such as the AWS app ID and branch name, to the build actions.

Here is an example of how you might implement the build actions in the workflow using React:
```bash
// Perform a clean install of the dependencies
npm ci

// Deploy the backend for your Amplify Gen 2 app
npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID

// Trigger frontend build using incoming webhooks
if [ $AWS_BRANCH = "main" ]; then
  curl -X POST -d {} "`webhookUrl`&operation=startbuild" -H "Content-Type:application/json"
fi
```
Once you've created the workflow, you can validate it to ensure that the workflow definition yaml file is valid, and then commit the changes to save the workflow. The workflow will automatically start a new run when you commit the changes.

Overall, this guide provides a step-by-step overview of how to set up a custom cross-account pipeline to deploy your frontend and backend for apps built using Amplify Gen 2. By following these steps, you can create a pipeline that deploys your backend initially with your staging environment, and then deploys your production environment in a different AWS account.

While building with Amplify CI/CD provides benefits such as zero-config setup, full-stack previews, and centralized secrets management, Amplify Gen 2 allows you to integrate full-stack CI/CD into your custom pipelines, including AWS CodePipeline, Amazon CodeCatalyst, GitHub Actions, and more.

To set up backend deployments, follow these steps:

1. Create an Amplify app by connecting a full-stack Gen 2 branch from your Git repository. This is a one-time setup, as subsequent deployments will use a custom pipeline.

2. Disable Auto-build for your branch to prevent code commits from triggering a build.

3. Update the Amplify build specification file to include `npx ampx generate outputs --branch $AWS_BRANCH --app-id $AWS_APP_ID` and comment out the `pipeline-deploy` script. The `ampx pipeline-deploy` command deploys backend updates, while `ampx generate outputs` fetches the latest `amplify_outputs.json` for the specified environment.

4. Update your pipeline provider's build settings to include the following:
    * Run `npm ci`.
    * Run `export CI=1` to indicate a CI environment.
    * Run `npx ampx pipeline-deploy --branch BRANCH_NAME --app-id AMPLIFY_APP_ID`. Replace `BRANCH_NAME` with the branch being deployed and `AMPLIFY_APP_ID` with the Amplify App ID.

For example, when using Amazon CodeCatalyst, your build specification might look like this:
```yaml
Actions:
  Build_82:
    Identifier: aws/build@v1.0.0
    Inputs:
      Sources:
        - WorkflowSource
      Variables:
        - Name: BRANCH_NAME
          Value: main
        - Name: AMPLIFY_APP_ID
          Value: #####
    Configuration:
      Steps:
        - Run: export CI=1
        - Run: npm ci
        - Run: npx ampx pipeline-deploy --branch $BRANCH_NAME --app-id $AMPLIFY_APP_ID
```

5. Trigger a `git push` to your branch. Your build logs should show an AWS CloudFormation deployment underway.

To set up frontend deployments and complete the full-stack CI/CD setup, follow these additional steps:

1. Create an incoming webhook in the Amplify Console.

2. Navigate to the frontend app, select **Create webhook** under **Hosting > Build settings**, and provide a name for the webhook and the target branch to build on incoming webhook requests.

3. Copy the `curl` command that will be used to trigger a build for the frontend app.

4. Update your custom pipeline build settings to include the `curl` command to trigger a frontend build after the `pipeline-deploy` succeeds. For example, using Amazon CodeCatalyst:
```yaml
Configuration:
  Steps:
    - Run: export CI=1
    - Run: npm ci
    - Run: npx ampx pipeline-deploy --branch $BRANCH_NAME --app-id $AMPLIFY_APP_ID
    - Run: if [ $BRANCH_NAME = "main" ]; then curl -X POST -d {}
        "https://webhooks.amplify.us-west-2.amazonaws.com/prod/webhooks?id=WEBHOOK-ID&token=TOKEN&operation=startbuild"
        -H "Content-Type:application/json"; fi
```

This will trigger a build in your Amplify app, and Amplify CI will build and deploy the frontend.

You might have different frontend and backend teams that maintain their own repositories. With AWS Amplify Gen 2, you can deploy repositories that have backend-only code, so frontend and backend teams can operate independently of each other.

To deploy the backend app, you can follow these steps:
1. Set up a backend-only Amplify project by running `mkdir backend-app && cd backend-app && npm create amplify@latest` and committing the code to a Git provider of your choice.
2. Connect the `backend-app` in the new console by navigating to the Amplify console and selecting **Create new app**.
3. When you connect the repository, notice that the only auto-detected framework is Amplify.
4. Once you choose **Save and deploy**, your backend project will build.

To deploy the frontend app, you can follow these steps:
1. Set up the frontend app by running `npm create next-app@14 -- multi-repo-example --typescript --eslint --no-app --no-src-dir --no-tailwind --import-alias '@/*'`.
2. Install Amplify dependencies by running `npm add @aws-amplify/backend-cli aws-amplify @aws-amplify/ui-react`.
3. To connect to the deployed backend, run `npx ampx generate outputs --branch main --app-id <your-backend-app-id>`, which will generate the `amplify_outputs.json` file containing information about your backend.
4. Validate that your frontend can connect to the backend by adding the `Authenticator` login form to your app.

To connect the frontend to the backend, you can use the following code:
```javascript
import { withAuthenticator } from '@aws-amplify/ui-react';
import { Amplify } from 'aws-amplify';
import outputs from '@/amplify_outputs.json';

Amplify.configure(outputs);

function App({ Component, pageProps }) {
  return <Component {...pageProps} />;
}

export default withAuthenticator(App);
```

You can also add an `amplify.yml` build-spec to your repository:
```yml
version: 1
backend:
  phases:
    build:
      commands:
        - npm ci --cache.npm --prefer-offline
        - npx ampx generate outputs --branch main --app-id BACKEND-APPID
frontend:
  phases:
    build:
      commands:
        - npm run build
  artifacts:
    baseDirectory:.next
    files:
      - '**/*'
  cache:
    paths:
      -.next/cache/**/*
      -.npm/**/*
      - node_modules/**/*
```

To trigger a frontend build on backend updates, you can create an incoming webhook in the Amplify Console:
1. Navigate to the **multi-repo-example** app, under **Hosting > Build settings** select **Create webhook**.
2. Provide a **name** for the webhook and select the **target branch** to build on incoming webhook requests.
3. Copy the `curl` command to trigger a build for the **multi-repo-example** app.

You can then update the build settings for the `backend-app` to include the `curl` command:
```yml
version: 1
backend:
  phases:
    build:
      commands:
        - npm ci --cache.npm --prefer-offline
        - npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID
        - curl -X POST -d {} "https://webhooks.amplify.ca-central-1.amazonaws.com/prod/webhooks?id=WEBHOOK-ID&token=TOKEN&operation=startbuild" -H "Content-Type:application/json"
```

To share schema type definitions between the frontend and backend, you can add a `paths` entry in the `tsconfig.json` of your frontend app that points to the `amplify/data/resource.ts` file in your backend app:
```json
{
  "compilerOptions": {
    "paths": {
      "@/data-schema": ["../backend-app/amplify/data/resource"]
    }
  }
}
```
You can then import the `Schema` type from this path in your frontend code to get code completion and strong typing for your API calls:
```javascript
import { generateClient } from "aws-amplify/data";
import type { Schema } from "@/data-schema";

const client = generateClient<Schema>();

const createTodo = async () => {
  await client.models.Todo.create({
    content: window.prompt("Todo content?"),
    isDone: false,
  });
}
```

Some teams choose a monorepo approach, or single repositories that contain multiple packages or components to simplify the deployment process for shared libraries and components. Without a monorepo, you have to deploy each package individually, keep track of package versions and dependencies across packages, and ensure version compatibility. This can become exponentially more complex as the number of packages grows. With a monorepo, all packages and dependencies are contained within a single repository.

Amplify Gen 2 supports monorepo workflows for fullstack builds with monorepo tools such as Nx and yarn workspaces. When building with Gen 2, we recommend creating the amplify/ folder in a shared workspace. We will use the following example for this guide:

Consider a project with the following structure:
- apps/ 
  - admin-dashboard/ 
    - next.config.mjs
    - package.json
  - marketing-site/ 
    - astro.config.mjs
    - package.json
- packages/ 
  - my-shared-backend/ 
    - amplify/ 
      - auth/ 
        - resource.ts
      - data/ 
        - resource.ts
      - backend.ts
    - package.json
    - tsconfig.json
- package.json

Monorepos require a slightly different setup. To deploy, you need to deploy 3 Amplify apps: 
1. my-shared-backend 
2. admin-dashboard 
3. marketing-site

The first app, my-shared-backend, will be the only app that updates changes to the backend. The other apps will only run frontend builds that point to the shared backend. 

To deploy the shared backend Amplify app, navigate to the Amplify console and select Create new app. Once you connect your repository, select your monorepo project. Check the box that says My app is a monorepo and enter the path to your amplify backend. Your build settings should be automatically detected. Save and deploy.

For the frontend apps, connect the frontend projects in the Amplify console separately, and update the build commands to include:
npx ampx generate outputs --branch main --app-id BACKEND-APP-ID

Replace BACKEND-APP-ID with the App ID for your backend application, which can be found in the Amplify console under the project name.

If you're using Amplify Data, we recommend adding a paths entry in your tsconfig.json file that points to the amplify/data/resource.ts file to easily access your schema type definitions from your frontend apps. 

You can then import the Schema type from this path in your frontend code to get code completion and strong typing for your API calls:
```javascript
import { generateClient } from "aws-amplify/data";
import type { Schema } from "@/data-schema";

const client = generateClient<Schema>();

const createTodo = async () => {
  await client.models.Todo.create({
    content: window.prompt("Todo content?"),
    isDone: false,
  });
}
```

This is how you can set up monorepo workflows for fullstack builds with Amplify Gen 2.

Fullstack previews allow you to set up ephemeral fullstack environments on every pull request. This enables you to test features in isolation from production. 

The workflow for using fullstack previews would be as follows:
1. Your main production branch and feature branch are deployed on Amplify.
2. You and your team work on the feature branch until it's ready.
3. The feature branch is updated to the main branch head and then a pull request to the main branch is opened.
4. The pull request preview is deployed on Amplify and available at a unique URL.
5. Once the pull request is merged into the main branch, the request is closed and the fullstack environment is also automatically torn down.

To use fullstack previews, you need to have the following prerequisites:
- A fullstack Amplify app deployed
- A private git repository, as fullstack previews are disabled for public repositories with Amplify backend templates.

To enable fullstack web previews for your Amplify app, follow these steps:
1. Log in to the Amplify console and select your app.
2. Navigate to Hosting > Previews, select the main branch, and click on Edit settings.
3. Click on the Pull request previews toggle button and choose Confirm to enable previews.
4. Once enabled, ship updates to the dev branch. When you create a pull request for the main branch, Amplify will build and deploy your fullstack PR and provide you with a preview URL.

For GitHub repositories, you can access your preview URL directly on the pull request from the Amplify Hosting's bot comment. After the pull request is merged or closed, the preview URL is deleted and any ephemeral fullstack environment is also deleted.

If you want to share backend resources across preview branches, you can update your app build settings to reuse backend resources across your preview branches. This can be done by updating the build settings for the backend phase to generate the amplify_outputs.json file for all preview branches using the dev branch. 

For example, you can update the amplify.yml file as follows:
```yml
version: 1
backend:
    phases:
        build:
            commands:
                - 'npm ci --cache.npm --prefer-offline'
                - 'echo $AWS_BRANCH'
                - |
                  case "${AWS_BRANCH}" in
                      main)
                          echo "Deploying main branch..."
                          npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID
                          ;;
                      dev)
                          echo "Deploying dev branch..."
                          npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID
                          ;;
                      pr-*)
                          echo "Deploying pull request branch..."
                          npx ampx generate outputs --branch dev --app-id $AWS_APP_ID 
                          ;;
                      *)
                          echo "Deploying to staging branch..."
                          npx ampx generate outputs --branch staging --app-id $AWS_APP_ID 
                          ;;
                  esac
frontend:
    phases:
        build:
            commands:
                - 'npm run build'
    artifacts:
        baseDirectory:.amplify-hosting
        files:
            - '**/*'
    cache:
        paths:
            -.next/cache/**/*
            -.npm/**/*
            - node_modules/**/*
```
After this update, any new deployed preview branches will not deploy backend resources as part of the build and instead will use the deployed backend resources from the dev branch.

Amplify Gen 2 offers centralized management of secrets and environment variables for all fullstack branches. Secrets allow you to securely configure environment-specific values like social sign-in keys, function environment variables, function secrets, and other sensitive data needed by your application across environments.

This is different from Amplify Gen 1, where you need to define environment variables and secrets using the CLI and store keys in both AWS Parameter Store and a local team-provider.json file. In Amplify Gen 2, the management of secrets and environment variables is centralized in the Amplify console.

To set secrets, you can add them for branch deployments in the Amplify console. From the App home page, navigate to Hosting > Secrets, and then choose the Manage secrets button. You can add a secret key or value that applies to all deployed branches or just specific branches. Secrets are stored in AWS Systems Manager Parameter Store.

For local environments, you can add secrets while running the cloud sandbox with the command npx ampx sandbox secret set foo. Secrets set in a sandbox do not show up in the Amplify console, but you can view them in the AWS Parameter Store console.

To access secrets, you can call the secret() function in your code. For example, you can set up social sign-in with authentication in your app using the secret() function. Depending on your environment, Amplify will automatically load the correct secret value with no extra configuration.

To remove secrets, you need to manually delete them. For branch environments, secrets can be managed directly in the Amplify console. For local environments, you can remove a secret with the command npx ampx sandbox secret remove foo.

Environment variables work like key-value pairs to help manage configurable settings across different deployment environments. Unlike secrets, environment variables are typically nonconfidential and are used for controlling application behavior in different environments. Environment variables are stored and managed by the Amplify managed service.

To set environment variables, you can set them in the Amplify console. To access environment variables, you can enable access to them for your fullstack branch deployments or your local dev server. For branch environments, you can manage environment variables through the Amplify console. For local environments, you must manually load the sandbox's environment variables.

For example, you can create an environment variable in the Amplify console and update the build settings to pipe the environment variable into a file, such as an.env file. You can then access the environment variable in your client code using process.env.

Here is an example of how you can write the environment variable to an.env file in your amplify.yml file:
```
build:
  commands:
    - echo "REACT_APP_TEST_VARIABLE=$REACT_APP_TEST_VARIABLE" >>.env
    - npm run build
```
You can then access the environment variable in your client code using process.env:
```typescript
console.log('REACT_APP_TEST_VARIABLE', process.env.REACT_APP_TEST_VARIABLE);
```

You can share resources across branches in your app by updating the build settings. This is useful when you want to reuse seed data, users, and groups across different branches. For example, you can set up your feature branches to use the backend resources deployed by the dev branch.

To do this, go to the App overview page in the Amplify console and select Build settings under Hosting. This will show you your app's build specification YAML file. Update the build settings for the backend phase to generate the amplify_outputs.json file for all branches other than main or dev. 

You can achieve this by running the command `npx ampx generate outputs --branch dev app-id $AWS_APP_ID` for all branches other than main or dev. This will ensure that any new deployed branches will not deploy backend resources as part of the build and instead will use the deployed backend resources from the dev branch.

Here is an example of how you can update your amplify.yml file to achieve this:

you can use a case statement in your amplify.yml file to run different commands based on the current branch. 
For the main and dev branches, you can deploy the backend resources as usual. 
For other branches, you can generate the amplify_outputs.json file using the dev branch. 

This approach allows you to share resources across branches and reuse seed data, users, and groups. 

In react code, you don't need to do anything to share resources across branches, this is all handled in the amplify.yml file and in the amplify console.

AWS Amplify Hosting is a fully managed service that handles continuous integration and deployment, as well as hosting, for static and server-side rendered applications. It supports a range of modern web frameworks, including React, Angular, and Vue. 

This service provides fast, secure, and reliable scaling for applications, and because it is fully managed, its documentation is located on the AWS Documentation site. There, you can learn more about features such as custom domains and redirects. 

For more information on getting started with AWS Amplify Hosting, you can visit the official documentation.

Sandbox environments include additional features for managing secrets, deploying multiple sandboxes, config generation, and client codegen for your Amplify app.

Secure secrets in your sandbox are stored in AWS Parameter Store under the `/amplify` prefix. Secrets are similar to environment variables, but they are encrypted AWS Systems Manager Parameter Store key value pairs. Secrets set in a sandbox do not show up in the Amplify Console, you can view them in the AWS Systems Manager Parameter Store console.

You can add secrets to your sandbox environment using the command `npx ampx sandbox secret set`. For example, to add a secret named `foo`, you would run `npx ampx sandbox secret set foo` and enter the secret value when prompted. 

You can list all of the secret names available in your sandbox environment with the command `npx ampx sandbox secret list`. This will display a list of all the secrets in your sandbox.

To retrieve a secret, you can use the command `npx ampx sandbox secret get`. For example, to retrieve the value of a secret named `foo`, you would run `npx ampx sandbox secret get foo`. This will display the secret value in plain text, so be careful not to use this command in a environment where terminal logs may be stored.

To remove a secret from your sandbox, you can use the command `npx ampx sandbox secret remove`. For example, to remove a secret named `foo`, you would run `npx ampx sandbox secret remove foo`.

Once you have set a secret, you can reference the secret in your backend definition using the `secret()` function. The `secret()` function places a reference to the secret value in the backend definition, the secret value is only resolved during deployment of your backend. 

For example, to set up social sign-in with authentication in your app, you would use the `secret()` function to reference the secret values for the client ID and client secret. 
```javascript
import { defineAuth, secret } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      facebook: {
        clientId: secret('foo'),
        clientSecret: secret('bar')
      }
    }
  }
});
```

You can also work with multiple AWS profiles by using the `--profile` flag with the `ampx sandbox secret` commands. For example, to add a secret to the sandbox in a profile named `work`, you would run `npx ampx sandbox secret set foo --profile work`.

You can also work with multiple named sandboxes by using the `--identifier` option. For example, to start a sandbox named `feature1sandbox`, you would run `npx ampx sandbox --identifier feature1sandbox`. 

To manage secrets for named sandboxes, you can use the `--identifier` argument with the `sandbox secret` commands. For example, to add a secret to a sandbox named `feature1sandbox`, you would run `npx ampx sandbox --identifier feature1sandbox secret set baz`.

You can also stream function logs directly to your terminal or a file.

To generate client config, you can use the `npx ampx sandbox` command with the `--outputs-out-dir` and `--outputs-format` options. For example, to generate the client config in a directory named `config` with the format `json`, you would run 
```bash
npx ampx sandbox --outputs-out-dir./config --outputs-format json
```

To generate client codegen, you can use the `npx ampx generate graphql-client-code` command. For example, to generate client code with the format `modelgen`, you would run 
```bash
npx ampx generate graphql-client-code --format modelgen
```

To delete a sandbox, you can use the `npx ampx sandbox delete` command. You can also delete a sandbox by visiting the Amplify console and deleting the sandbox environment.

You can use a personal cloud sandbox environment that provides an isolated development space to rapidly build, test, and iterate on a full-stack app. Each developer on your team can use their own disposable sandbox environment connected to cloud resources. Cloud sandbox environments are not intended for production workloads.

To create a new sandbox environment, you need to have an Amplify app set up. If you haven't created an Amplify Gen 2 app, you can start by visiting the Quickstart guide. 

Once you have an Amplify app set up, you can create a new sandbox environment by running the command `npx ampx sandbox` in your terminal. This will deploy a cloud sandbox and create an AWS CloudFormation stack with the resources configured in your `amplify/` folder. The stack will be named according to the convention `amplify-<app-name>-<username>-sandbox`.

After a successful deployment, the `sandbox` command will watch for file changes in your `amplify/` folder and perform real-time updates to the associated CloudFormation stack. This allows you to see the changes you make to your code reflected in your sandbox environment immediately.

If you want to stop your sandbox environment, you can do so by pressing `Ctrl+C` in your terminal. If you want to delete all the resources in your sandbox environment, you can run the command `npx ampx sandbox delete`.

You can also view and manage all the sandbox environments for your team in the Amplify console. This allows you to see the number, status, and last updates for sandbox environments across your team, and delete sandbox environments when they are no longer needed.

When working with cloud sandbox environments, keep in mind the following best practices: 
- Sandboxes are identical in fidelity to your production environments.
- Code changes are continuously deployed to your sandbox on every save for fast iterations.
- Use sandboxes for experimentation and testing, not for production workloads.
- Deploy one sandbox per Amplify app per developer to prevent conflicts.
- Reset sandboxes occasionally to clear out unused resources and save costs. 

Here is an example of how you might create and delete a sandbox environment using React and Node:
```javascript
// Create a new sandbox environment
const { exec } = require('child_process');
exec('npx ampx sandbox', (error, stdout, stderr) => {
  if (error) {
    console.error(`exec error: ${error}`);
    return;
  }
  if (stderr) {
    console.error(`stderr: ${stderr}`);
    return;
  }
  console.log(`stdout: ${stdout}`);
});

// Delete a sandbox environment
const { exec } = require('child_process');
exec('npx ampx sandbox delete', (error, stdout, stderr) => {
  if (error) {
    console.error(`exec error: ${error}`);
    return;
  }
  if (stderr) {
    console.error(`stderr: ${stderr}`);
    return;
  }
  console.log(`stdout: ${stdout}`);
});
```

This page is for formatting only.

Amplify allows you to add layers to your functions, which contain your library dependencies. This makes it easier to manage shared components across multiple functions and reduces deployment package sizes. 

To add a Lambda layer to your function, first create and set up your Lambda layer in AWS through the AWS Console or using the AWS CLI. Then, reference it in your Amplify project by specifying the layers property in defineFunction. 

For example, if you're using React, you can specify the layers property like this:
```javascript
import { defineFunction } from "@aws-amplify/backend";

export const myFunction = defineFunction({
  name: "my-function",
  layers: {
    "@aws-lambda-powertools/logger": 
      "arn:aws:lambda:us-east-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:12",
  },
});
```
The Lambda layer is represented by an object of key/value pairs where the key is the module name that is exported from your layer and the value is the ARN of the layer. You can also specify the layer as myLayer:1 where myLayer is the name of the layer and 1 is the version of the layer. 

For example:
```javascript
import { defineFunction } from "@aws-amplify/backend";

export const myFunction = defineFunction({
  name: "my-function",
  layers: {
    "some-module": "myLayer:1"
  },
});
```
Amplify will automatically convert this to the full layer ARN format using your existing account ID and region. 

When using layers, be mindful of versioning and ensure you're using the appropriate version and have a strategy for updating layers when new versions are released. 

To use the locally installed module in the function handler, you can do something like this:
```javascript
import { Logger } from "@aws-lambda-powertools/logger";
import type { Handler } from "aws-lambda";

const logger = new Logger({ serviceName: "serverlessAirline" });

export const handler = async (event, context) => {
  logger.info("Hello World");
};
```
For more information on creating and managing layers, refer to the AWS documentation for Lambda layers. 

Note that configuring or adding layers in defineFunction is not supported for Custom Functions.

To configure functions, you can use the `defineFunction` option with various settings. 

The `name` option allows you to explicitly set the name of the function. By default, the function name is based on the directory where `defineFunction` is called. For example, you can set the name like this:
```javascript
export const myDemoFunction = defineFunction({
  entry: './demo-function-handler.ts',
  name: 'overrideName'
});
```

The `timeoutSeconds` option allows you to set the timeout for the function, which defaults to 3 seconds. You can set it to any whole number of seconds up to 15 minutes. For example:
```javascript
export const myDemoFunction = defineFunction({
  timeoutSeconds: 60
});
```

The `memoryMB` option allows you to set the amount of memory allocated to the function, which defaults to 512 MB. You can set it to any value from 128 MB to 10240 MB. For example:
```javascript
export const myDemoFunction = defineFunction({
  memoryMB: 256
});
```

The `ephemeralStorageSizeMB` option allows you to set the amount of ephemeral storage allocated to the function, which defaults to 512 MB. You can set it to any value from 512 MB to 10240 MB. For example:
```javascript
export const myDemoFunction = defineFunction({
  ephemeralStorageSizeMB: 1024
});
```

The `runtime` option allows you to set the Node version used by the function, which defaults to Node 18. For example:
```javascript
export const myDemoFunction = defineFunction({
  runtime: 20
});
```

The `entry` option allows you to specify the location of the function handler, which defaults to a file called `handler.ts` in the same directory as the file where `defineFunction` is called. For example:
```javascript
export const myDemoFunction = defineFunction({
  entry: './path/to/handler.ts'
});
```

The `resourceGroupName` option allows you to group related functions with other Amplify resources, which defaults to `function`. For example:
```javascript
export const myDemoFunction = defineFunction({
  resourceGroupName: 'data'
});
```

Note that some options, such as `name`, `timeoutSeconds`, `memoryMB`, `ephemeralStorageSizeMB`, `runtime`, and `entry`, are not supported for custom functions, except for `resourceGroupName`.

AWS Amplify Gen 2 functions are AWS Lambda functions used to perform tasks and customize workflows in your Amplify app. These functions can be written in Node.js, Python, Go, or any other language supported by AWS Lambda.

To create a custom function, you can use languages like Python or Go. When creating a function, you should define it using the `defineFunction` method. This method allows you to specify the function's handler, runtime, timeout, and code.

For Python functions, you'll need to create a handler file, typically named `index.py`, which exports a function named `handler`. This is the entry point to your function. You can also include Python packages by adding them to a `requirements.txt` file in the same directory as your handler file.

For Go functions, you'll need to create a handler file, typically named `main.go`, which contains the function code. You'll also need to run the `go mod init` and `go mod tidy` commands to build the Go function.

Once you've defined your function, you'll need to add it to your backend by importing it into your `amplify/backend.ts` file and including it in the `defineBackend` method.

To invoke your function, you can add it as a handler for a custom query with your Amplify Data resource. This involves specifying a new query in your schema and using the `a.handler.function` method to link it to your custom function.

It's also important to note that custom functions may require Docker to build and bundle the function's code. If you're using a Fullstack Git-based environment, you'll need to provide your own image that meets Amplify requirements and includes a Docker installation.

Here's an example of how you might define a Python function in React:
```javascript
import { defineFunction } from '@aws-amplify/backend';

const functionDir = './amplify/functions/say-hello';

export const sayHelloFunctionHandler = defineFunction(
  (scope) => 
    new Function(scope, 'say-hello', {
      handler: 'index.handler',
      runtime: 'python3.9',
      timeout: 20,
      code: Code.fromAsset(functionDir, {
        bundling: {
          local: {
            tryBundle(outputDir) {
              // install Python packages
              return true;
            },
          },
        },
      }),
    }),
  {
    resourceGroupName: 'auth',
  }
);
```

And here's an example of how you might define a Go function in React:
```javascript
import { defineFunction } from '@aws-amplify/backend';

const functionDir = './amplify/functions/say-hello';

export const sayHelloFunctionHandler = defineFunction(
  (scope) => 
    new Function(scope, 'say-hello', {
      handler: 'bootstrap',
      runtime: 'provided.al2',
      timeout: 3,
      code: Code.fromAsset(functionDir, {
        bundling: {
          local: {
            tryBundle(outputDir) {
              // build Go function
              return true;
            },
          },
        },
      }),
    }),
  {
    resourceGroupName: 'auth',
  }
);
```

To add the function to your backend, you would import it into your `amplify/backend.ts` file:
```javascript
import { sayHelloFunctionHandler } from './functions/say-hello/resource';

defineBackend({
  sayHelloFunctionHandler,
});
```

And to invoke the function, you would add it as a handler for a custom query in your `amplify/data/resource.ts` file:
```javascript
import { sayHelloFunctionHandler } from '../functions/say-hello/resource';

const schema = a.schema({
  sayHello: a
   .query()
   .arguments({
      name: a.string(),
    })
   .returns(a.string())
   .handler(a.handler.function(sayHelloFunctionHandler)),
});
```

To configure and consume environment variables and secrets in AWS Amplify Gen 2, you can use the `environment` property of `defineFunction`. Environment variables can be set using this property, and they will be available to the function at runtime. 

However, do not store secret values in environment variables, as they are rendered in plaintext to the build artifacts and may be emitted to CloudFormation stack event messages. Instead, use the `secret` function to reference a secret value that has been defined separately.

To access environment variables within your function handler, you can use the `process.env` global object provided by the Node runtime. Alternatively, you can use the `env` symbol generated by Amplify, which provides typings for all variables that will be available at runtime.

To use the `env` symbol, you need to import it from `$amplify/env/<function-name>`. If you created your project with `create-amplify`, then Amplify has already set up your project to use the `env` symbol. Otherwise, you need to manually configure your project by adding a `paths` compiler option to your `amplify/tsconfig.json` file.

Here is an example of how to define a function with environment variables and secrets:

```javascript
import { defineFunction, secret } from '@aws-amplify/backend';

export const sayHello = defineFunction({
  environment: {
    NAME: "World",
    API_ENDPOINT: process.env.API_ENDPOINT,
    API_KEY: secret('MY_API_KEY') 
  }
});
```

And here is an example of how to access environment variables and secrets within your function handler:

```javascript
import { env } from '$amplify/env/say-hello';

export const handler = async (event) => {
  const request = new Request(env.API_ENDPOINT, {
    headers: {
      Authorization: `Bearer ${env.API_KEY}`
    }
  })
  //...
  return `Hello, ${env.NAME}!`;
};
```

Note that environment variables and secrets configuration in `defineFunction` is not supported for Custom Functions. Also, be aware that generated files are created before deployments when executing `ampx sandbox` or `ampx pipeline-deploy`. If you encounter issues with the generated file, you can visit the troubleshooting guide for `Cannot find module $amplify/env/<function-name>`.

To add a user to a group in AWS Amplify, you can use a Post Authentication trigger, also known as a Cognito post confirmation Lambda trigger. This trigger extends the behavior of your application to perform an action when a user is confirmed, such as adding them to a group.

A user is considered confirmed when they verify their account, typically through email verification. However, this trigger will not be triggered for federated sign-ins, such as social sign-ins.

To get started, you will need to install the AWS SDK v3 package and the `@types/aws-lambda` package. You can install these packages using npm by running the command:
```bash
npm add --save-dev @aws-sdk/client-cognito-identity-provider @types/aws-lambda
```
Next, create a new directory and a resource file, `amplify/auth/post-confirmation/resource.ts`. Then, define the Function with `defineFunction`:
```javascript
// amplify/auth/post-confirmation/resource.ts
import { defineFunction } from '@aws-amplify/backend';

export const postConfirmation = defineFunction({
  name: 'post-confirmation',
  environment: {
    GROUP_NAME: 'EVERYONE'
  },
  resourceGroupName: 'auth'
});
```
After creating the Function definition, you will need to create the `EVERYONE` group, grant access to your auth resource to ensure it can perform the `addUserToGroup` action, and set the Function as the post confirmation trigger:
```javascript
// amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend";
import { postConfirmation } from "./post-confirmation/resource"

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  groups: ["EVERYONE"],
  triggers: {
    postConfirmation,
  },
  access: (allow) => [
    allow.resource(postConfirmation).to(["addUserToGroup"]),
  ],
})
```
Then, create the Function's corresponding handler file, `amplify/auth/post-confirmation/handler.ts`, with the following contents:
```javascript
// amplify/auth/post-confirmation/handler.ts
import type { PostConfirmationTriggerHandler } from 'aws-lambda';
import {
  CognitoIdentityProviderClient,
  AdminAddUserToGroupCommand
} from '@aws-sdk/client-cognito-identity-provider';

const client = new CognitoIdentityProviderClient();

export const handler = async (event) => {
  const command = new AdminAddUserToGroupCommand({
    GroupName: 'EVERYONE',
    Username: event.userName,
    UserPoolId: event.userPoolId
  });
  const response = await client.send(command);
  console.log('processed', response.$metadata.requestId);
  return event;
};
```
After deploying the changes, whenever a user signs up and verifies their account, they will be automatically added to the group named "EVERYONE". 

In a react application this would be used in conjunction with Amplify's Auth library to manage user authentication and group membership. 

To use this in a react application, you would set up your Amplify Auth configuration and then define the Post Confirmation trigger in your Amplify Backend configuration. 

For example, in your react application you might have an Amplify Auth configuration like this:
```javascript
import Amplify from 'aws-amplify';
import awsconfig from './aws-exports';

Amplify.configure(awsconfig);
```
And then in your Amplify Backend configuration you would define the Post Confirmation trigger:
```javascript
import { defineAuth } from "@aws-amplify/backend";
import { postConfirmation } from "./post-confirmation/resource"

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  groups: ["EVERYONE"],
  triggers: {
    postConfirmation,
  },
  access: (allow) => [
    allow.resource(postConfirmation).to(["addUserToGroup"]),
  ],
})
```

You can create a user profile record automatically when a user confirms their account by using an Auth Post Authentication trigger. This trigger is a Lambda function that runs after a user verifies their account, typically by confirming their email address. 

To set this up, you'll need to define a data model for the user's profile and create a Lambda function to handle the post confirmation trigger. 

First, you need to define a data model for the user's profile. This model should include the email address and the profile owner. The profile owner is typically the user's ID. 

Here is an example of how you might define this model in a React application:
```javascript
const UserProfileModel = {
  email: '',
  profileOwner: '',
}
```
Next, you need to create a Lambda function to handle the post confirmation trigger. This function will create a new user profile record when a user confirms their account. 

In a React application, you might use the AWS Amplify library to interact with your backend APIs. Here is an example of how you might create a post confirmation handler:
```javascript
import { Amplify } from 'aws-amplify';
import { API } from 'aws-amplify';

const postConfirmationHandler = async (event) => {
  const userProfile = {
    email: event.request.userAttributes.email,
    profileOwner: event.request.userAttributes.sub,
  };

  try {
    const response = await API.post('user-profile', '/user-profile', {
      body: userProfile,
    });
    return response;
  } catch (error) {
    console.error(error);
  }
};
```
Then you need to set up the Auth Post Authentication trigger to call this Lambda function when a user confirms their account. 

In a React application, you might use the AWS Amplify library to configure your Auth settings. Here is an example of how you might set up the post confirmation trigger:
```javascript
import Amplify from 'aws-amplify';
import Auth from '@aws-amplify/auth';

Amplify.configure({
  Auth: {
    mandatorySignIn: true,
    region: 'your-region',
    userPoolId: 'your-user-pool-id',
    userPoolWebClientId: 'your-user-pool-web-client-id',
    oauth: {
      domain: 'your-domain',
      scope: ['email', 'profile'],
      redirectSignIn: 'http://localhost:3000',
      redirectSignOut: 'http://localhost:3000',
      responseType: 'code',
    },
    triggers: {
      postConfirmation: postConfirmationHandler,
    },
  },
});
```
After deploying the changes, whenever a user signs up and verifies their account, a profile record is automatically created. 

Note: A user is considered "confirmed" when they verify their account, typically by confirming their email address. The post confirmation handler will not be triggered for federated sign-ins, such as social sign-in.

Secure Remote Password (SRP) is a cryptographic protocol that allows password-based authentication without transmitting the password over the network. Amazon Cognito custom authentication flows use two types of custom authentication, CUSTOM_WITH_SRP and CUSTOM_WITHOUT_SRP. CUSTOM_WITH_SRP incorporates SRP steps for enhanced security, while CUSTOM_WITHOUT_SRP bypasses these steps for a simpler process.

To implement custom authentication flows using AWS Amplify with Lambda triggers, you can use the defineAuth and defineFunction functions to create an authentication experience that uses CUSTOM_WITH_SRP and CUSTOM_WITHOUT_SRP. This is done by leveraging Amazon Cognito's feature to define a custom authentication flow and three triggers: create auth challenge, define auth challenge, and verify auth challenge response.

To get started, install the aws-lambda package, which is used to define the handler type. Then, create the three triggers: create-auth-challenge, define-auth-challenge, and verify-auth-challenge-response.

The create-auth-challenge trigger is responsible for creating the reCAPTCHA challenge after a password is verified. The define-auth-challenge trigger defines the authentication flow, and the verify-auth-challenge-response trigger verifies the challenge response.

For CUSTOM_WITHOUT_SRP, the define-auth-challenge trigger checks if it's the first authentication attempt and starts with the custom challenge. If it's the second attempt and the custom challenge was successful, it issues tokens and completes the authentication.

For CUSTOM_WITH_SRP, the define-auth-challenge trigger starts with SRP_A (Secure Remote Password protocol, step A) on the first attempt. On the second attempt, if SRP_A was successful, it moves to PASSWORD_VERIFIER. On the third attempt, if PASSWORD_VERIFIER was successful, it moves to CUSTOM_CHALLENGE. On the fourth attempt, if CUSTOM_CHALLENGE was successful, it issues tokens and completes the authentication.

The verify-auth-challenge-response trigger verifies the challenge response and always returns true for the purpose of this example.

Finally, import and set the three triggers on your auth resource using the defineAuth function. After deploying the changes, whenever a user attempts to sign in with CUSTOM_WITH_SRP or CUSTOM_WITHOUT_SRP, the Lambda challenges will be triggered.

Here is an example of how you can implement this in React:
```javascript
import Amplify from 'aws-amplify';
import { withAuthenticator } from '@aws-amplify/ui-react';

// Define the auth resource
const auth = {
  // Configure your auth resource
  loginWith: {
    email: true,
  },
  triggers: {
    createAuthChallenge: (event) => {
      // Generate a random code for the custom challenge
      const challengeCode = "123456";

      event.response.challengeMetadata = "TOKEN_CHECK";

      event.response.publicChallengeParameters = {
        trigger: "true",
        code: challengeCode,
      };

      event.response.privateChallengeParameters = { trigger: "true" };
      event.response.privateChallengeParameters.answer = challengeCode;
      return event;
    },
    defineAuthChallenge: (event) => {
      // Check if this is the first authentication attempt
      if (event.request.session.length === 0) {
        // For the first attempt, we start with the custom challenge
        event.response.issueTokens = false;
        event.response.failAuthentication = false;
        event.response.challengeName = "CUSTOM_CHALLENGE";
      } else if (
        event.request.session.length === 1 &&
        event.request.session[0].challengeName === "CUSTOM_CHALLENGE" &&
        event.request.session[0].challengeResult === true
      ) {
        // If this is the second attempt (session length 1),
        // it was a CUSTOM_CHALLENGE, and the result was successful
        event.response.issueTokens = true;
        event.response.failAuthentication = false;
      } else {
        // If we reach here, it means either:
        // 1. The custom challenge failed
        // 2. We've gone through more attempts than expected
        // In either case, we fail the authentication
        event.response.issueTokens = false;
        event.response.failAuthentication = true;
      }
      return event;
    },
    verifyAuthChallengeResponse: (event) => {
      // Verify the challenge response
      event.response.answerCorrect = true;
      return event;
    },
  },
};

// Configure Amplify
Amplify.configure({
  Auth: auth,
});

// Use the withAuthenticator component to wrap your app
const App = () => {
  // Your app content
};

export default withAuthenticator(App);
```

To customize the message sent to users in AWS Amplify, you can use an Auth custom message authentication trigger. This trigger allows you to send a custom email or phone verification message, or a multi-factor authentication (MFA) code.

To get started, you need to create a new directory and a resource file, then define the function using `defineFunction`. 

```typescript
import { defineFunction } from '@aws-amplify/backend';

export const customMessage = defineFunction({
  name: "custom-message",
  resourceGroupName: 'auth'
});
```

Next, create the corresponding handler file with the following contents:

```typescript
import type { CustomMessageTriggerHandler } from "aws-lambda";

export const handler: CustomMessageTriggerHandler = async (event) => {
  if (event.triggerSource === "CustomMessage_ForgotPassword") {
    const locale = event.request.userAttributes["locale"];
    if (locale === "en") {
      event.response.emailMessage = `Your new one-time code is ${event.request.codeParameter}`;
      event.response.emailSubject = "Reset my password";
    } else if (locale === "es") {
      event.response.emailMessage = `Tu nuevo código de un solo uso es ${event.request.codeParameter}`;
      event.response.emailSubject = "Restablecer mi contraseña";
    }
  }

  return event;
};
```

Lastly, set the newly created function resource on your auth resource:

```typescript
import { defineAuth } from '@aws-amplify/backend';
import { customMessage } from "./custom-message/resource";

export const auth = defineAuth({
  triggers: {
    customMessage,
  }
});
```

In a React application, you would use this custom message trigger in the same way, by defining the function and handler, and then setting the trigger on your auth resource. After deploying the changes, whenever a user attempts to reset a password, they will receive an email with a one-time code in the language specified by their `locale` attribute.

To integrate AWS Lambda with Amazon DynamoDB Streams, you can trigger a Lambda function in response to real-time events, enabling you to build responsive, event-driven applications. This feature allows you to react to changes in data or system state without the need for polling services.

In this example, we will configure a Lambda function with an Amazon DynamoDB stream as an event source, using a `Todo` table created by a data model on the GraphQL API. 

First, install the required packages, including the AWS Lambda Powertools Logger for structured logging capabilities and the `aws-lambda` package to define the handler type, by running `npm add --save-dev @aws-lambda-powertools/logger @types/aws-lambda` in your terminal.

Next, create a new directory and a resource file, and define the Lambda function using `defineFunction`. 

Then, create a corresponding handler file and define the function handler, which will be triggered whenever an item is added, updated, or deleted from the table. The handler function will process the event records and log information about the event.

Lastly, create a DynamoDB table as an event source in the `amplify/backend` file and attach the necessary policy to the Lambda function's role.

Here's how you could write the handler function in React, although note that the handler function itself is typically written in a serverless environment and not directly in a React application:

```javascript
import { DynamoDBStreamHandler } from "aws-lambda";
import { Logger } from "@aws-lambda-powertools/logger";

const logger = new Logger({
  logLevel: "INFO",
  serviceName: "dynamodb-stream-handler",
});

export const handler: DynamoDBStreamHandler = async (event) => {
  for (const record of event.Records) {
    logger.info(`Processing record: ${record.eventID}`);
    logger.info(`Event Type: ${record.eventName}`);

    if (record.eventName === "INSERT") {
      // business logic to process new records
      logger.info(`New Image: ${JSON.stringify(record.dynamodb?.NewImage)}`);
    }
  }
  logger.info(`Successfully processed ${event.Records.length} records.`);

  return {
    batchItemFailures: [],
  };
};
```

In a React application, you would typically interact with the Lambda function through an API Gateway or other serverless API. However, the actual handling of the DynamoDB stream event would occur in the Lambda function, not in the React application itself.

You can use defineAuth and defineFunction to create a Cognito pre sign-up Lambda trigger that performs filtering based on the user's email address. This can allow or deny user signups based on their email address.

To get started, you need to install the aws-lambda package. 

Next, create a new directory and a resource file, then define the Function with defineFunction. For example, you can define the Function like this:
```javascript
const preSignUp = defineFunction({
  name: 'pre-sign-up',
  environment: {
    ALLOW_DOMAIN: 'amazon.com'
  }
});
```

Then, create the corresponding handler file with the following contents:
```javascript
const handler = async (event) => {
  const email = event.request.userAttributes['email'];

  if (!email.endsWith(process.env.ALLOW_DOMAIN)) {
    throw new Error('Invalid email domain');
  }

  return event;
};
```

Lastly, set the newly created Function resource on your auth resource. For example:
```javascript
const auth = defineAuth({
  triggers: {
    preSignUp
  }
});
```

After deploying the changes, whenever a user attempts to sign up without an amazon.com email address they will receive an error.

To protect against spam, you can use Google reCAPTCHA in your AWS Amplify Gen 2 application. This involves creating an authentication flow that includes a custom challenge. 

You will need to set up three triggers: 
1. Create auth challenge: This trigger creates the reCAPTCHA challenge after a password is verified.
2. Define auth challenge: This trigger defines the authentication flow, which includes the custom challenge.
3. Verify auth challenge response: This trigger verifies the reCAPTCHA token.

To set up the create auth challenge trigger, create a function that sends a request to Amazon Cognito to create the challenge. The function will include a condition to check if the session has two steps (SRP and password verification) and if the challenge name is CUSTOM_CHALLENGE. If the condition is met, the function will set the public challenge parameters, private challenge parameters, and optionally, the challenge metadata.

```javascript
// Create auth challenge trigger
export const createAuthChallenge = async (event) => {
  const { request, response } = event;

  if (
    request.session.length === 2 &&
    request.challengeName === "CUSTOM_CHALLENGE"
  ) {
    response.publicChallengeParameters = { trigger: "true" };
    response.privateChallengeParameters = { answer: "" };
    // optionally set challenge metadata
    response.challengeMetadata = "CAPTCHA_CHALLENGE";
  }

  return event;
};
```

To set up the define auth challenge trigger, create a function that defines the authentication flow. The function will check the session and challenge name, and update the response accordingly.

```javascript
// Define auth challenge trigger
export const defineAuthChallenge = async (event) => {
  const { response } = event;
  const [srp, password, captcha] = event.request.session;

  // deny by default
  response.issueTokens = false;
  response.failAuthentication = true;

  if (srp?.challengeName === "SRP_A") {
    response.failAuthentication = false;
    response.challengeName = "PASSWORD_VERIFIER";
  }

  if (
    password?.challengeName === "PASSWORD_VERIFIER" &&
    password.challengeResult === true
  ) {
    response.failAuthentication = false;
    response.challengeName = "CUSTOM_CHALLENGE";
  }

  if (
    captcha?.challengeName === "CUSTOM_CHALLENGE" &&
    // check for the challenge metadata set in "create-auth-challenge"
    captcha?.challengeMetadata === "CAPTCHA_CHALLENGE" &&
    captcha.challengeResult === true
  ) {
    response.issueTokens = true;
    response.failAuthentication = false;
  }

  return event;
};
```

To set up the verify auth challenge response trigger, create a function that verifies the reCAPTCHA token. You will need to register your application and retrieve a reCAPTCHA secret key. Then, create a function that sends a request to Google reCAPTCHA to verify the token.

```javascript
// Verify auth challenge response trigger
export const verifyAuthChallengeResponse = async (event) => {
  if (!event.request.challengeAnswer) {
    throw new Error("Missing challenge answer");
  }

  // https://developers.google.com/recaptcha/docs/verify#api_request
  const url = new URL("https://www.google.com/recaptcha/api/siteverify");
  const params = new URLSearchParams({
    secret: process.env.GOOGLE_RECAPTCHA_SECRET_KEY,
    response: event.request.challengeAnswer,
  });
  url.search = params.toString();

  const request = new Request(url, {
    method: "POST",
  });

  const response = await fetch(request);
  const result = await response.json();

  if (!result.success) {
    throw new Error("Verification failed", { cause: result["error-codes"] });
  }

  // indicate whether the answer is correct
  event.response.answerCorrect = result.success;

  return event;
};
```

Finally, you will need to configure your auth resource to include the three triggers.

```javascript
// Configure auth resource
import { createAuthChallenge } from "./create-auth-challenge/resource";
import { defineAuthChallenge } from "./define-auth-challenge/resource";
import { verifyAuthChallengeResponse } from "./verify-auth-challenge-response/resource";

export const auth = {
  loginWith: {
    email: true,
  },
  triggers: {
    createAuthChallenge,
    defineAuthChallenge,
    verifyAuthChallengeResponse,
  },
};
```

To use the reCAPTCHA in your React application, you can use the `useGoogleReCaptcha` hook to get the reCAPTCHA token.

```javascript
import React, { useState, useEffect } from "react";
import { useGoogleReCaptcha } from "react-google-recaptcha-v3";

function Example() {
  const [token, setToken] = useState(null);
  const { executeRecaptcha } = useGoogleReCaptcha();

  useEffect(() => {
    if (executeRecaptcha) {
      executeRecaptcha("your_action").then((token) => setToken(token));
    }
  }, [executeRecaptcha]);

  return (
    <div>
      <p>reCAPTCHA token: {token}</p>
    </div>
  );
}

export default Example;
```

This page is for formatting only

With AWS Lambda, you can integrate various event sources, such as Amazon Kinesis, Amazon SQS, and others, to trigger Lambda functions in response to real-time events. This feature enables you to build responsive, event-driven applications that react to changes in data or system state without the need for polling services.

To configure a Lambda function with a Kinesis data stream as an event source, you need to follow these steps. 

First, install the AWS Lambda Powertools Logger and the `aws-lambda` package. 

```bash
npm add @aws-lambda-powertools/logger @types/aws-lambda
```

Next, create a new directory and a resource file for your Lambda function, and define the function using the AWS Amplify `defineFunction` method.

In a React application, you would define the function in a separate file, for example `amplify/functions/kinesis-function/resource.js`.

```javascript
import { defineFunction } from "@aws-amplify/backend";

export const myKinesisFunction = defineFunction({
  name: "kinesis-function",
});
```

Then, create the corresponding handler file for your Lambda function, and import the necessary types and handlers from `aws-lambda`. 

In a React application, you would define the handler in a separate file, for example `amplify/functions/kinesis-function/handler.js`.

```javascript
import type {
  KinesisStreamBatchResponse,
  KinesisStreamHandler,
  KinesisStreamRecordPayload,
} from "aws-lambda";
import { Buffer } from "buffer";
import { Logger } from "@aws-lambda-powertools/logger";

const logger = new Logger({
  logLevel: "INFO",
  serviceName: "kinesis-stream-handler",
});

export const handler = async (event, context) => {
  for (const record of event.Records) {
    try {
      logger.info(`Processed Kinesis Event - EventID: ${record.eventID}`);
      const recordData = await getRecordDataAsync(record.kinesis);
      logger.info(`Record Data: ${recordData}`);
    } catch (err) {
      logger.error(`An error occurred ${err}`);
      return {
        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],
      };
    }
  }
  logger.info(`Successfully processed ${event.Records.length} records.`);
  return { batchItemFailures: [] };
};

async function getRecordDataAsync(payload) {
  const data = Buffer.from(payload.data, "base64").toString("utf-8");
  return data;
}
```

Finally, create the Kinesis stream and add it as an event source in your backend configuration file, for example `amplify/backend.js`.

```javascript
import { defineBackend } from "@aws-amplify/backend";
import { Stream } from "aws-cdk-lib/aws-kinesis";
import { StartingPosition } from "aws-cdk-lib/aws-lambda";
import { KinesisEventSource } from "aws-cdk-lib/aws-lambda-event-sources";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { myKinesisFunction } from "./functions/kinesis-function/resource";

const backend = defineBackend({
  auth,
  data,
  myKinesisFunction,
});

const kinesisStack = backend.createStack("kinesis-stack");

const kinesisStream = new Stream(kinesisStack, "KinesisStream", {
  streamName: "myKinesisStream",
  shardCount: 1,
});

const eventSource = new KinesisEventSource(kinesisStream, {
  startingPosition: StartingPosition.LATEST,
  reportBatchItemFailures: true,
});

backend.myKinesisFunction.resources.lambda.addEventSource(eventSource);
```

For examples on streaming analytics data to the Kinesis stream from your frontend, see the relevant documentation.

To override ID token claims in AWS Amplify, you can use the `defineAuth` and `defineFunction` features to create an Amazon Cognito Pre token generation AWS Lambda trigger. This trigger allows you to add new claims or modify the user's group membership in the ID token.

To get started, you need to create a new Lambda function. First, install the required package. 

Then, create a new directory and file to define the function. 

In this file, you define the function with a name and resource group name. 

Next, create a corresponding handler file with the function that will handle the pre-token generation event. This event is where you can add new claims or modify the user's group membership. 

The handler function takes an event object as input and returns the modified event object. In this function, you can override the claims by specifying the claims to add or override. 

You can also override the user's group membership by specifying the groups to override. 

Finally, you need to set the newly created function resource on your auth resource. 

After deploying the changes, the ID token of the user will be modified according to the trigger. You can verify this by checking the ID token, which should now contain the new claims and group membership. 

For example, you can add a new claim called "amplfy_attribute" to the ID token, and also add the user to a Cognito group called "amplify_group_1". 

To achieve this in React, you can define the function and handler in a JavaScript file, like this:
```javascript
import { defineFunction } from '@aws-amplify/backend';

const preTokenGeneration = defineFunction({
  name: 'pre-token-generation',
  resourceGroupName: 'auth'
});

export const handler = async (event) => {
  event.response = {
    claimsOverrideDetails: {
      groupOverrideDetails: {
        groupsToOverride: ["amplify_group_1"],
      },
      claimsToAddOrOverride: {
        amplfy_attribute: "amplify_gen_2",
      },
    },
  };
  return event;
};
```

And then set the newly created function resource on your auth resource:
```javascript
import { defineAuth } from '@aws-amplify/backend';
import { preTokenGeneration } from './pre-token-generation/resource';

const auth = defineAuth({
  loginWith: {
    email: true,
  },
  triggers: {
    preTokenGeneration
  }
});
```

To confirm uploading files in AWS Amplify Gen 2, you can use a trigger. This is done by defining a storage function with an onUpload trigger. 

First, you need to install the @types/aws-lambda package, which can be done by running the command `npm add --save @types/aws-lambda` in your terminal.

Next, you need to update your storage definition to include the onUpload trigger. This can be done by defining a storage function like so:
```javascript
import { defineFunction, defineStorage } from "@aws-amplify/backend";

export const storage = defineStorage({
  name: 'myProjectFiles',
  triggers: {
    onUpload: defineFunction({
      entry: './on-upload-handler.ts'
      resourceGroupName: 'storage',
    })
  }
});
```

Then, create a file named on-upload-handler.ts and add the following code to log the object keys whenever an object is uploaded to the bucket. You can also add your custom logic to this function as needed.
```javascript
import type { S3Handler } from 'aws-lambda';

export const handler = async (event) => {
  const objectKeys = event.Records.map((record) => record.s3.object.key);
  console.log(`Upload handler invoked for objects [${objectKeys.join(', ')}]`);
};
```

When you deploy your backend, this function will be invoked whenever an object is uploaded to the bucket, allowing you to confirm the upload and add any custom logic as needed.

To validate user attributes with an Auth trigger in AWS Amplify Gen 2, you can create a Cognito pre sign-up Lambda trigger. This trigger extends the sign-up behavior to validate attribute values. 

To get started, create a new function that will act as the pre sign-up trigger. In a React application, you can define this function using `defineFunction` from `@aws-amplify/backend`. 

For example, you can create a file called `preSignUp.js` with the following contents:
```javascript
import { defineFunction } from '@aws-amplify/backend';

export const preSignUp = defineFunction({
  name: "pre-sign-up",
  resourceGroupName: 'auth'
});
```

Next, create a corresponding handler file called `handler.js` with the following contents:
```javascript
function isOlderThan(date, age) {
  const comparison = new Date()
  comparison.setFullYear(comparison.getFullYear() - age)
  return date.getTime() > comparison.getTime()
}

export const handler = async (event) => {
  const birthdate = new Date(event.request.userAttributes["birthdate"])

  // you must be 13 years or older
  if (!isOlderThan(birthdate, 13)) {
    throw new Error("You must be 13 years or older to use this site")
  }

  return event
}
```

Lastly, set the newly created function resource on your auth resource. In a React application, you can do this by importing `defineAuth` from `@aws-amplify/backend` and setting the `triggers` property. For example:
```javascript
import { defineAuth } from '@aws-amplify/backend';
import { preSignUp } from './preSignUp';

export const auth = defineAuth({
  //...
  triggers: {
    preSignUp
  }
});
```

After deploying the changes, whenever a user attempts to sign up, this handler will verify that the submitter's age is above 13 years.

To grant Amplify Functions access to other resources, you must give them permission to do so. There are two ways to grant this access: 

1. Using the `access` property: This property is found in each of the `define*` functions for defining Amplify resources. It allows you to specify the necessary actions using common language. When you grant a function access to another resource in your Amplify backend, it will configure environment variables for that function to make SDK calls to the AWS services it has access to. These environment variables are typed and available as part of the `env` object.

For example, if you have a function that generates reports each month from your Data resource and needs to store the generated reports in Storage, you can use the `access` property as follows: 

```javascript
const storage = {
  name: 'myReports',
  access: (allow) => ({
    'reports/*': [
      allow.resource(generateMonthlyReports).to(['read', 'write', 'delete'])
    ]
  })
};
```

This will add the environment variable `myReports_BUCKET_NAME` to the function. You can then use this environment variable to upload content to S3.

```javascript
const s3Client = new S3Client();
const command = new PutObjectCommand({
  Bucket: env.MY_REPORTS_BUCKET_NAME,
  Key: `reports/${new Date().toISOString()}.csv`,
  Body: new Blob([''], { type: 'text/csv;charset=utf-8;' })
});
await s3Client.send(command);
```

2. Using the AWS Cloud Development Kit (CDK): When permissions are needed to access resources beyond the capabilities of the `access` property, you must use CDK. Functions are created with an execution role, which is an IAM role that contains policies that dictate what resources your Function can interact with when it executes. This role can be extended using the `addToRolePolicy()` method.

For example, to grant a function access to an SNS topic, you can add a policy statement to the function's role.

```javascript
const statement = new iam.PolicyStatement({
  sid: "AllowPublishToDigest",
  actions: ["sns:Publish"],
  resources: [topic.topicArn],
});
weeklyDigestLambda.addToRolePolicy(statement);
```

Alternatively, some constructs provide a `grant*` method to grant access to common policy actions. For example, you can use the `grantPublish` method to grant a function access to an SNS topic.

```javascript
topic.grantPublish(weeklyDigestLambda);
```

To modify the underlying resources of an Amplify-generated Lambda function, you can use the AWS Cloud Development Kit (CDK). Amplify Functions use the NodejsFunction construct from CDK, which allows you to modify, override, or extend the resources after setting them on your backend.

In your backend configuration, you can access the CDK constructs for a function and modify its resources. For example, if you have a function named `myFunction`, you can access its resources like this:
```
const backend = defineBackend({
  myFunction
})

// Access the Lambda function resources
const lambdaFunction = backend.myFunction.resources.lambda
```
The `lambda` property is an instance of `IFunction`, which represents a Lambda function.

You can also add IAM policies to a function's execution role using CDK. To learn how to do this, you can visit the documentation for granting access to other resources. 

Note: This page is referring to react as one of the platforms that can utilize this feature, but since the content is primarily focused on backend configuration with AWS CDK, the information can be applied to a react application by following the provided guidance on using CDK to modify the underlying resources of an Amplify-generated Lambda function. 

Lambda Layers are mentioned but not explained in this context. If information about Lambda Layers is needed, it would be in a different section of the documentation.

Amplify offers the ability to schedule functions to run at specific intervals using natural language or cron expressions. To get started, you need to specify the schedule property in defineFunction.

Note that configuring the schedule in defineFunction is not supported for Custom Functions.

Function schedules are powered by Amazon EventBridge rules and can be used to address various use cases such as generating reports or sending notifications.

You can define a schedule using natural language, such as "every week", or using cron expressions like "0 9? * 3 *". The schedule can be a single interval or multiple intervals.

Here's how you can define a function with a schedule in React:
```javascript
import { defineFunction } from "@aws-amplify/backend";

export const weeklyDigest = defineFunction({
  name: "weekly-digest",
  schedule: "every week",
});
```
You can also use cron expressions to define a schedule:
```javascript
import { defineFunction } from "@aws-amplify/backend";

export const remindMe = defineFunction({
  name: "remind-me-to-take-the-trash-out",
  schedule: [
    // every tuesday at 9am
    "0 9? * 3 *",
    // every friday at 9am
    "0 9? * 6 *",
  ]
})
```
Additionally, you can use shorthand syntax to define schedules using minutes or hours:
```javascript
import { defineFunction } from "@aws-amplify/backend";

export const drinkSomeWater = defineFunction({
  name: "drink-some-water",
  schedule: "every 1h"
})
```
The schedule can also be combined to create complex schedules:
```javascript
import { defineFunction } from "@aws-amplify/backend";

export const remindMe = defineFunction({
  name: "remind-me",
  schedule: [
    // every sunday at midnight
    "every week",
    // every tuesday at 5pm
    "0 17? * 3 *",
    // every wednesday at 5pm
    "0 17? * 4 *",
    // every thursday at 5pm
    "0 17? * 5 *",
    // every friday at 5pm
    "0 17? * 6 *",
  ]
})
```
You can use natural language expressions to define schedules using terms like "day", "week", "month", "year", "m" for minutes, and "h" for hours. Natural language expressions are prefixed with "every". For example:
```javascript
import { defineFunction } from "@aws-amplify/backend";

export const drinkSomeWater = defineFunction({
  name: "drink-some-water",
  schedule: "every 1h"
})
```

To set up a function in AWS Amplify, you will be using AWS Lambda functions to perform tasks and customize workflows. Functions can respond to events from other resources, execute some logic in-between events, or act as standalone jobs. They are used in various settings, including authentication flow customizations, resolvers for GraphQL APIs, handlers for individual REST API routes, and scheduled jobs.

To get started, you need to create a new directory and a resource file. Then, define the function using `defineFunction`. 

```javascript
// amplify/functions/say-hello/resource.js
import { defineFunction } from '@aws-amplify/backend';

export const sayHello = defineFunction({
  name: 'say-hello',
  entry: './handler.js'
});
```

Next, create the corresponding handler file. This is where your function code will go.

```javascript
// amplify/functions/say-hello/handler.js
export const handler = async (event, context) => {
  // your function code goes here
  return 'Hello, World!';
};
```

The handler file must export a function named "handler". This is the entry point to your function.

Lastly, this function needs to be added to your backend.

```javascript
// amplify/backend.js
import { defineBackend } from '@aws-amplify/backend';
import { sayHello } from './functions/say-hello/resource';

defineBackend({
  sayHello
});
```

Now when you run `npx ampx sandbox` or deploy your app on Amplify, it will include your function.

To invoke your function, you can add your function as a handler for a custom query with your Amplify Data resource. This will enable you to strongly type function arguments and the return statement, and use this to author your function's business logic.

```javascript
// amplify/data/resource.js
import { defineData } from '@aws-amplify/backend';
import { sayHello } from '../functions/say-hello/resource';

const schema = {
  sayHello: {
    type: 'query',
    args: {
      name: 'string'
    },
    returns: 'string',
    handler: sayHello
  }
};

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "iam"
  }
});
```

Now you can use this query from the schema export to strongly type your function handler.

```javascript
// amplify/functions/say-hello/handler.js
import { schema } from '../../data/resource';

export const handler = async (event) => {
  const { name } = event.arguments;
  return `Hello, ${name}!`;
};
```

Finally, use the data client to invoke your function by calling its associated query.

```javascript
// src/App.js
import { DataStore } from 'aws-amplify';
import { sayHello } from './amplify/data/resource';

DataStore.query(sayHello, { name: "Amplify" })
 .then((data) => console.log(data))
 .catch((error) => console.error(error));
```

You can also explore additional features, such as environment variables and secrets, granting access to other resources, example use cases, and modifying underlying resources with CDK.

AWS Amplify allows you to stream logs from your function directly to your terminal while running the `ampx sandbox` command. To do this, you need to specify the `--stream-function-logs` option when starting the sandbox. 

This feature is only available for Sandbox environments. It enables faster debug iterations and provides greater insight into your functions' executions.

You can filter the logs by specifying a filter by function name or a regular expression for function names using the `--logs-filter` option. For example, if you have a collection of Auth triggers where the function names include "auth", you can filter the logs by running the command with the `--logs-filter auth` option.

After deploying your personal cloud sandbox, starting your frontend application, and signing up for the first time, you will see logs from your triggers' executions printed to the terminal where the sandbox is running.

You can also write the logs to a file instead of printing them to the terminal by specifying the `--logs-out-file` option. This can be combined with the `--logs-filter` option to create a log file of just your Auth-related functions. However, you cannot write logs to multiple files at the same time.

To stream logs, run the following command in your terminal:
```
npx ampx sandbox --stream-function-logs
```
To filter logs by function name, run:
```
npx ampx sandbox --stream-function-logs --logs-filter auth
```
To write logs to a file, run:
```
npx ampx sandbox --stream-function-logs --logs-out-file sandbox.log
```
To filter logs by function name and write to a file, run:
```
npx ampx sandbox --stream-function-logs --logs-filter auth --logs-out-file sandbox-auth.log
```

Amplify Geo provides solutions for common use cases with Amazon Location Service, but for any functionality that is not currently supported by Amplify Geo, you can access the Amazon Location Service SDK directly.

To get started with the AWS SDK for Amazon Location Service using Amplify Auth credentials, follow this guide.

First, install the necessary dependencies with the command npm add @aws-sdk/client-location.

To connect your app to the Amazon Location Service, initialize the Amazon Location Service client by calling the following function in your React app:

```javascript
import { Amplify } from 'aws-amplify';
import { fetchAuthSession } from 'aws-amplify/auth';
import {
  LocationClient,
  AssociateTrackerConsumerCommand
} from '@aws-sdk/client-location';
import outputs from '../amplify_outputs.json';
Amplify.configure(outputs);

const createClient = async () => {
  const session = await fetchAuthSession();
  const client = new LocationClient({
    credentials: session.credentials,
    region: amplifyconfig.aws_project_region
  });
  return client;
};
```

To use the Amazon Location Service APIs, ensure you've provisioned resources and configured your app using the instructions in the Amplify Geo Maps docs or the Amazon Location Service console. You can check out the Amazon Location API Reference documentation for a complete list of supported features.

For example, to update a device position and get a device position using the tracker, use the following code:

```javascript
// UpdateDevicePosition API
const params = {
  TrackerName: 'trackerId',
  Updates: [
    {
      DeviceId: 'deviceId',
      Position: [-122.431297, 37.773972],
      SampleTime: new Date()
    }
  ]
};
const command = new BatchUpdateDevicePositionCommand(params);
client.send(command, (err, data) => {
  if (err) console.error(err);
  if (data) console.log(data);
});

// GetDevicePosition API
const client = await createClient();
const params = {
  TrackerName: 'trackerId',
  DeviceId: 'deviceId'
};
const command = new GetDevicePositionCommand(params);
client.send(command, (err, data) => {
  if (err) console.error(err);
  if (data) console.log(data);
});
```

If you need functionality in the AWS services used by the Amplify Geo category that isn't available, Amplify provides an escape hatch to access the low-level client instance for Amazon Location Service.

For platforms other than React, the escape hatch is also available.

Documentation resources are available for managing Amazon Location Service resources, using Amazon Location Maps, searching place and geolocation data, and managing tracker resources.

A Geofence is a virtual perimeter for a real-world geographic area, formed by points or vertices that create a closed boundary, defining an area of interest. Geofence collections store one or multiple Geofences. 

To set up a new Geofence Collection, you start by creating a location services geofence collection. This involves defining a collection name, pricing plan, and tags. For example, in a React application using AWS Amplify, you would use the AWS Location service to create a geofence collection.

To create a new geofence collection, you would use the AWS SDK for JavaScript, specifically the AWS Location service. Here is an example of how you might create a geofence collection in a React application:
```javascript
import { LocationClient, CreateGeofenceCollectionCommand } from "@aws-sdk/client-location";

const locationClient = new LocationClient({ region: "your-region" });
const createGeofenceCollectionCommand = new CreateGeofenceCollectionCommand({
  CollectionName: "myGeofenceCollection",
  PricingPlan: "RequestBasedUsage",
  Tags: [
    {
      Key: "name",
      Value: "myGeofenceCollection",
    },
  ],
});

locationClient.send(createGeofenceCollectionCommand).then((data) => {
  console.log(data);
}).catch((error) => {
  console.error(error);
});
```

The pricing plan for the Geofence Collection will be set to `RequestBasedUsage`. It's recommended to review the AWS Location service pricing and terms to learn more about the pricing plan.

To scope access permissions based on Cognito User Groups, you would create a Cognito User Pool Group and add permissions to the group role. For example:
```javascript
import { CognitoIdentityServiceProviderClient, AdminAddUserToGroupCommand } from "@aws-sdk/client-cognito-identity-service-provider";

const cognitoClient = new CognitoIdentityServiceProviderClient({ region: "your-region" });
const adminAddUserToGroupCommand = new AdminAddUserToGroupCommand({
  GroupName: "User",
  UserPoolId: "your-user-pool-id",
  Username: "username",
});

cognitoClient.send(adminAddUserToGroupCommand).then((data) => {
  console.log(data);
}).catch((error) => {
  console.error(error);
});
```

Note that if you combine `Auth/Guest user access` and `Individual Group access`, users who are members of a group will only be granted the permissions of the group, and not the authenticated user permissions. The permissions apply to ALL Geofences in a collection.

After provisioning the Geofence Collection, you can add Geofences to the collection programmatically using the AWS SDK for JavaScript. Refer to the API documentation for more information. For example:
```javascript
import { LocationClient, CreateGeofenceCommand } from "@aws-sdk/client-location";

const locationClient = new LocationClient({ region: "your-region" });
const createGeofenceCommand = new CreateGeofenceCommand({
  CollectionName: "myGeofenceCollection",
  GeofenceId: "geofence-id",
  // geofence details
});

locationClient.send(createGeofenceCommand).then((data) => {
  console.log(data);
}).catch((error) => {
  console.error(error);
});
```

Amplify's geo category allows you to search by places, addresses, and coordinates in your app with place index resources. 

To set up a new location search index, you need to create a location services map and a place index. The map is used to store the geospatial data, and the place index is used to search for places in your application.

In a React application, you can use the Amplify Location library to interact with the location services map and place index. 

Here's an example of how to create a location services map and place index using Amplify Location in a React application:

First, you need to set up the Amplify Location library in your React application. 

Next, you can use the Amplify Location library to create a location services map and place index. 

To create a location services map, you can use the following code:
```javascript
import Amplify from 'aws-amplify';
import { Location } from 'aws-amplify';

// Create a location services map
const map = await Location.createMap({
  mapName: 'myMap',
  description: 'Map',
  configuration: {
    style: 'VectorEsriNavigation',
  },
  pricingPlan: 'RequestBasedUsage',
  tags: [
    {
      key: 'name',
      value: 'myMap',
    },
  ],
});
```

To create a location services place index, you can use the following code:
```javascript
// Create a location services place index
const placeIndex = await Location.createPlaceIndex({
  indexName: 'myPlaceIndex',
  dataSource: 'Here',
  dataSourceConfiguration: {
    intendedUse: 'SingleUse',
  },
  pricingPlan: 'RequestBasedUsage',
  tags: [
    {
      key: 'name',
      value: 'myPlaceIndex',
    },
  ],
});
```

The pricing plan for the search index will be set to RequestBasedUsage. It's recommended to review the location service pricing and terms to learn more about the pricing plan.

You can also configure the data provider and result storage location for your location search index. The available data providers for geospatial data are Here and Esri. 

To use Here as the data provider, you can specify the dataSource as 'Here' when creating the place index:
```javascript
const placeIndex = await Location.createPlaceIndex({
  indexName: 'myPlaceIndex',
  dataSource: 'Here',
  //...
});
```

To use Esri as the data provider, you can specify the dataSource as 'Esri' when creating the place index:
```javascript
const placeIndex = await Location.createPlaceIndex({
  indexName: 'myPlaceIndex',
  dataSource: 'Esri',
  //...
});
```

Note that if your application is tracking or routing assets you use in your business, you may only use Here as your geolocation provider.

You can also specify the result storage location for the search operation. You can choose to store the results in a database or cache them. 

To specify the result storage location, you can use the intendedUse property when creating the place index:
```javascript
const placeIndex = await Location.createPlaceIndex({
  indexName: 'myPlaceIndex',
  dataSourceConfiguration: {
    intendedUse: 'SingleUse',
  },
  //...
});
```

You can also specify the result storage location as 'Storage' to store the results in a database or cache:
```javascript
const placeIndex = await Location.createPlaceIndex({
  indexName: 'myPlaceIndex',
  dataSourceConfiguration: {
    intendedUse: 'Storage',
  },
  //...
});
```

To use existing Amazon Location Services resources with your Amplify backend or frontend application, you need to surface backend resource outputs to the `amplify_outputs.json` file. This can be achieved by using the `addOutput` method.

For example, you can add your existing Amazon Location Service resources to your Amplify backend configuration like this:
```javascript
const backend = {
  geo: {
    awsRegion: "your-aws-region",
    maps: {
      items: {
        "your-friendly-map-name": {
          name: "your-map-name",
          style: "your-map-style",
        },
      },
      default: "your-friendly-map-name",
    },
  },
}
```
Before you can use your existing Amazon Location Service resources with Amplify Geo, you need to ensure your role has the right authorization permissions through Cognito. There are two roles created by Cognito: an "authenticated role" that grants signed-in-user-level access and an "unauthenticated role" that allows unauthenticated access to resources. You need to attach the necessary policies for the appropriate resources and roles.

The policies should include the following actions:
- `geo:GetMapTile`
- `geo:GetMapSprites`
- `geo:GetMapGlyphs`
- `geo:GetMapStyleDescriptor`
- `geo:SearchPlaceIndexForPosition`
- `geo:SearchPlaceIndexForText`
- `geo:GetGeofence`
- `geo:PutGeofence`
- `geo:BatchPutGeofence`
- `geo:BatchDeleteGeofence`
- `geo:ListGeofences`

These policies should be attached to the Amazon Location Service resources, including maps, place indices, and geofence collections.

Here is an example of what the policy might look like:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "GetTiles",
      "Effect": "Allow",
      "Action": [
        "geo:GetMapTile",
        "geo:GetMapSprites",
        "geo:GetMapGlyphs",
        "geo:GetMapStyleDescriptor"
      ],
      "Resource": "arn:aws:geo:your-geo-region:your-account-id:map/your-map-name"
    },
    {
      "Sid": "Search",
      "Effect": "Allow",
      "Action": [
        "geo:SearchPlaceIndexForPosition",
        "geo:SearchPlaceIndexForText"
      ],
      "Resource": "arn:aws:geo:your-geo-region:your-account-id:place-index/your-index-name"
    },
    {
      "Sid": "Geofence",
      "Effect": "Allow",
      "Action": [
        "geo:GetGeofence",
        "geo:PutGeofence",
        "geo:BatchPutGeofence",
        "geo:BatchDeleteGeofence",
        "geo:ListGeofences",
      ],
      "Resource": "arn:aws:geo:your-geo-region:your-account-id:geofence-collection/your-collection-name"
    }
  ]
}
```
To configure the client library directly, you can import and configure the generated `amplify_outputs.json` file, then manually configure Amplify Geo. Here is an example of how to do this:
```javascript
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
Amplify.configure({
  Geo: {
    LocationService: {
      maps: {
        items: {
          "your-map-name": {
            style: 'VectorEsriStreets'
          }
        },
        default: 'your-preferred-default-map'
      },
      searchIndices: {
        items: ['your-geo-index'],
        default: 'your-default-index'
      },
      geofenceCollections: {
        items: ['your-geo-collection'],
        default: 'your-default-collection'
      },
      region: 'your-geo-region'
    }
  }
});
```
After configuring Amplify Geo, you can proceed to display a map or add location search to your app.

To work with geofences in your application using Amplify Geo, you need to provision a geofence collection resource and configure your app. You can do this by following the instructions in either Configure a geofence collection or Use existing Amazon Location Service resources, and also set up displaying a map in your application.

To manage geofences in your application, you can use the amplify-geofence-control component. First, install the necessary dependencies with the command npm add aws-amplify @aws-amplify/geo @aws-amplify/ui-react @aws-amplify/ui-react-geo. Make sure that aws-amplify @aws-amplify/geo version 6.0.0 or above are installed.

To add the geofence management component to your map, create a map and then import AmplifyGeofenceControl from maplibre-gl-js-amplify, create a new instance of this control, and add it to your MapLibre map instance. The user will need to be authenticated with the administrative Cognito user associated with the Geofence Collection you created. 

Here is an example of how to use AmplifyGeofenceControl in a React application:
```javascript
import { useEffect, useRef } from "react";
import { createMap, AmplifyGeofenceControl } from "maplibre-gl-js-amplify";
import { withAuthenticator } from "@aws-amplify/ui-react";
import "@aws-amplify/ui-react/styles.css";
import "maplibre-gl-js-amplify/dist/public/amplify-ctrl-geofence.css";
import "maplibre-gl/dist/maplibre-gl.css";

function Map() {
  const mapRef = useRef(null); 

  useEffect(() => {
    let map;
    async function initializeMap() {
      if (mapRef.current!= null) {
        map = await createMap({
          container: mapRef.current,
          center: [-122.431297, 37.773972],
          zoom: 11,
        });
      }

      const control = new AmplifyGeofenceControl()
      map.addControl(control);
    }
    initializeMap();

    return function cleanup() {
      if (map!= null) map.remove();
    };
  }, []);

 return (
   <div className="App">
     <div ref={mapRef} id="map" />
   </div>
 );
}

export default withAuthenticator(Map);
```

Alternatively, you can use the Amplify React MapView component and the useControl hook from react-map-gl to render the Geofence control component.
```javascript
import React from 'react';
import { Amplify } from 'aws-amplify';
import { withAuthenticator } from '@aws-amplify/ui-react';
import { MapView } from '@aws-amplify/ui-react-geo';
import { useControl } from 'react-map-gl';
import { AmplifyGeofenceControl } from 'maplibre-gl-js-amplify';

function Geofence() {
  useControl(() => new AmplifyGeofenceControl());

  return null;
}

function App({ signOut }) {
  return (
    <div className="App">
      <MapView
        initialViewState={{
          latitude: 37.8,
          longitude: -122.4,
          zoom: 14
        }}
      >
        <Geofence />
      </MapView>
    </div>
  );
}

export default withAuthenticator(App);
```

If you are using a different mapping library or need a programmatic approach to managing geofences, you can use the @aws-amplify/geo package. This package provides methods for managing geofences, including saveGeofences, getGeofence, listGeofences, and deleteGeofences.

The saveGeofences method is used to save geofences to your collection. It can take a single geofence or an array of geofences.
```javascript
let saveGeofenceResults;
try {
  saveGeofenceResults = await Geo.saveGeofences({
    geofenceId: 'my-geofence',
    geometry: {
      polygon: [
        [-123.14695358276366, 49.290090146520434],
        [-123.1358814239502, 49.294960279811974],
        [-123.15021514892577, 49.29300108863353],
        [-123.14909934997559, 49.29132171993048],
        [-123.14695358276366, 49.290090146520434]
      ]
    }
  });
} catch (error) {
  throw error;
}
```

The getGeofence method is used to get a single geofence from a collection.
```javascript
let response;
try {
  response = await Geo.getGeofence('geofenceId');
} catch (error) {
  throw error;
}
```

The listGeofences method is used to get a list of geofences from a collection. It has pagination built in and will return 100 geofences per page.
```javascript
let response;
try {
  response = await Geo.listGeofences();
  response.entries.forEach((geofence) => console.log(geofence.geofenceId));
} catch (error) {
  throw error;
}
```

The deleteGeofences method is used to delete a geofences from a collection. It can delete a single or multiple geofences at once.
```javascript
let response;
try {
  response = await Geo.deleteGeofences(
    [
      "geofence1",
      "geofence2",
      "geofence3",
    ]
  )
} catch (error) {
  throw error;
}
```

Are you using Google Maps or another similar Map Provider and would like to switch over to using Amplify Geo or Amazon Location Service? This tutorial will show you how to take your existing Google Maps APIs and switch over to using Amplify Geo.

To get started with Amplify Geo, you should be familiar with the Google Maps JavaScript API and with front-end web development concepts including HTML, CSS, and JavaScript. 
You will need Amplify Geo and a text editor to complete this tutorial.

A key difference to notice between using Amplify Geo and Google Maps is the convention for specifying coordinates. With Google Maps Platform, the convention is [lat, lng], but with Amplify Geo, the order is swapped to be [lng, lat]. This was done to match the geojson spec which is also used by MapLibre.

When using Google Maps Platform or other similar services like Mapbox, you will first be prompted to go to the Google Cloud Console to set up APIs and create an API key. With Amplify Geo, you will instead setup Amplify Auth and the MapView component will read the auth configuration from the amplify_outputs.json file. Behind the scenes, Amplify Auth uses Amazon Cognito to set up client credentials with access to Location Service and Geo will use those credentials when making any location-related API calls.

To create a webpage with a map using Amplify Geo, you can start by creating a new HTML file and adding the necessary scripts and styles to import MapLibre GL JS and CSS, and Amplify JS. You will also need to create a div element with an id of 'map' that will be the map's container.

To display a map, you can use the createMap function from AmplifyMapLibre, passing in the container, center coordinates, and zoom level as options. For example:
```js
const map = await createMap({
  container: document.getElementById('map'), 
  center: [-122.4783, 37.8199], 
  zoom: 13 
});
```
To display a marker, you can use the Marker class from maplibregl, setting the lngLat and adding it to the map. For example:
```js
const marker = new maplibregl.Marker().setLngLat([-122.4783, 37.8199]).addTo(map);
```
To add a popup, you can use the Popup class from maplibregl, setting the HTML content and adding it to the marker. For example:
```js
const popup = new maplibregl.Popup().setHTML(
  `<h3>Golden Gate Bridge</h3><p>The hex code for the bridge's color is: #c0362c</p>`
);

const marker = new maplibregl.Marker()
 .setLngLat([-122.4783, 37.8199])
 .setPopup(popup)
 .addTo(map);
```
To add a search component, you can use the createAmplifyGeocoder function from AmplifyMapLibre, adding the geocoder control to the map. For example:
```js
const geocoder = createAmplifyGeocoder();
map.addControl(geocoder);
```
To add a standalone search component, you can create a div element and append the geocoder control to it. For example:
```js
const el = document.createElement("div");
el.setAttribute("id", "search");
document.body.appendChild(el);

const geocoder = createAmplifyGeocoder();
document.getElementById("search").appendChild(geocoder.onAdd());
```

To add location search functionality to a map in a React application, you can use the `maplibre-gl-geocoder` library in conjunction with Amplify Geo. First, ensure you have provisioned a search index resource and configured your app using the instructions in either Configure Location Search or Use existing Amazon Location Service resources, and that you have already set up displaying a map in your application.

You can use the `Amplify UI Location Search` component to generate and display search results. To add a location search UI component to your map, you will use the `maplibre-gl-geocoder` library. Install the necessary dependencies with the command `npm add @maplibre/maplibre-gl-geocoder maplibre-gl@1 maplibre-gl-js-amplify`.

Create a map onto which you want to add the location search UI component. Then, use the `createAmplifyGeocoder()` function from `maplibre-gl-js-amplify` to get a new instance of `MaplibreGeocoder` and add the location search UI component to the map.

Here's an example of how to initialize the map and add the location search UI component:

```javascript
import { createMap, createAmplifyGeocoder } from "maplibre-gl-js-amplify";
import maplibregl from "maplibre-gl";
import "maplibre-gl/dist/maplibre-gl.css";
import "@maplibre/maplibre-gl-geocoder/dist/maplibre-gl-geocoder.css";
import "maplibre-gl-js-amplify/dist/public/amplify-geocoder.css"; 

async function initializeMap() {
    const el = document.createElement("div");
    el.setAttribute("id", "map");
    document.body.appendChild(el);

    const map = await createMap({
        container: "map",
        center: [-123.1187, 49.2819], 
        zoom: 11,
    })

    map.addControl(createAmplifyGeocoder());
}

initializeMap();
```

You can also use `maplibre-gl-geocoder` to display the location search UI component anywhere in your application, even outside the map, by extracting the HTML element using the `onAdd()` function and attaching it anywhere in your DOM instead of adding it via the map's `addControl()` function.

```javascript
const geocoder = createAmplifyGeocoder();
document.getElementById("search").appendChild(geocoder.onAdd());
```

To customize the search icons used by the `maplibre-gl-geocoder`, you can pass a custom image to the `createAmplifyGeocoder()` function.

```javascript
import myIcon from "./myIcon.svg" 

const icon = new Image(100, 100);
icon.src = myIcon;

const geocoder = createAmplifyGeocoder({ showResultMarkers: { element: icon } });
map.addControl(geocoder);
```

Amplify Geo enables you to search for locations by text, addresses, or geo-coordinates using the `Geo.searchByText()`, `Geo.searchByCoordinates()`, `Geo.searchForSuggestions()`, and `Geo.searchByPlaceId()` APIs.

To search for locations by text, you can use the `Geo.searchByText()` API, which enables you to search for places or points of interest by free-form text, such as an address, name, city, or region.

```javascript
import { Geo } from "@aws-amplify/geo"

Geo.searchByText("Amazon Go Store")
```

You can customize your search results by providing parameters such as `countries`, `maxResults`, `biasPosition`, `searchAreaConstraints`, and `searchIndexName`.

```javascript
const searchOptionsWithBiasPosition = {
  countries: string[], 
  maxResults: number, 
  biasPosition: [
    longitude 
    latitude 
  ], 
  searchIndexName: string, 
}

const searchOptionsWithSearchAreaConstraints = {
  countries: ["USA"], 
  maxResults: 25, 
  searchAreaConstraints: [SWLongitude, SWLatitude, NELongitude, NELatitude], 
  searchIndexName: string, 
}

Geo.searchByText('Amazon Go Stores', searchOptionsWithBiasPosition)
```

To search for locations by coordinates, you can use the `Geo.searchByCoordinates()` API, which is a reverse Geocoder that takes a coordinate point and returns information about what it finds at that point on the map.

```javascript
import { Geo } from "@aws-amplify/geo"

Geo.searchByCoordinates([longitudePoint, latitudePoint])
```

You can also search for suggestions by using the `Geo.searchForSuggestions()` API, which enables you to search for suggestions by free-form text, such as a place, address, city, or region.

```javascript
import { Geo } from "@aws-amplify/geo"

Geo.searchForSuggestions("Amazon Go Store")
```

Additionally, you can search for a place by its `placeId` using the `Geo.searchByPlaceId()` API.

```javascript
import { Geo } from "@aws-amplify/geo"

Geo.searchByPlaceId(placeId)
```

To work with maps in your application, you need to provision an Amazon Location Service Map resource and configure your app using the instructions in the guides for setting up maps or using existing resources. Here's how you can display a map in your React app:

First, you need to install the required libraries. You can do this by running the following command in your terminal:
```
npm add maplibre-gl maplibre-gl-js-amplify
```
Then, you need to import the library into your application:
```javascript
import { createMap } from 'maplibre-gl-js-amplify';
import 'maplibre-gl/dist/maplibre-gl.css';
```
Next, you need to create and render the map with the help of the `createMap` function:
```javascript
async function initializeMap() {
  const map = await createMap({
    container: 'map', 
    center: [-123.1187, 49.2819], 
    zoom: 11
  });
}

initializeMap();
```
Make sure you have a `div` with an `id="map"` in your HTML file before making the call to `createMap`.

To render a map using a class name or something other than the ID, you can pass in a reference to the HTML element itself:
```javascript
const element = document.getElementsByClassName("class")[0];

const map = await createMap({
  container: element,
 ...
})
```
The MapLibre canvas requires a defined height to display properly. You can add some CSS to set the height of the map component. For example:
```css
html,
body,
#root {
  height: 100%;
}

#map {
  height: 50%;
}
```
To display markers on a map, you can use the `drawPoints` function. This function expects the source name, coordinate data, and a maplibre-gl-js map:
```javascript
import { drawPoints } from 'maplibre-gl-js-amplify';

map.on('load', function () {
  drawPoints(
    'mySourceName', 
    [
      {
        coordinates: [-122.483696, 37.833818], 
        title: 'Golden Gate Bridge',
        address: 'A suspension bridge spanning the Golden Gate'
      },
      {
        coordinates: [-122.477, 37.8105] 
      }
    ], 
    map,
    {
      showCluster: true,
      unclusteredOptions: {
        showMarkerPopup: true
      },
      clusterOptions: {
        showCount: true
      }
    }
  );
});
```
If you want to display different map styles, you can use the `getAvailableMaps` API to fetch information for all maps that are available to be displayed. Then, you can set a different style to your map using the `setStyle` method:
```javascript
const availableMaps = await Geo.getAvailableMaps();

map.setStyle(availableMaps[0].mapName);
```
Note that when changing a map with Amplify and MapLibre, the `setStyle` function should be called with the name of the Location Service map, not the style.

Finally, when it's time to remove the map from the DOM, you can use the `remove` method of the generated map:
```javascript
map.remove();
```
This will clean up and release all resources associated with the map. After calling `remove`, you must not call any other methods on the map.

To set up Amplify Geo, you need to create a Geo resource powered by Amazon Location Services. You can use the AWS Cloud Development Kit (AWS CDK) to create the resource. 

First, you need to install the necessary dependencies, including `aws-amplify` and `@aws-amplify/geo`. You can do this by running the command `npm add aws-amplify @aws-amplify/geo` in your terminal.

Next, you need to import and load the configuration file in your app. You can do this by adding the following code to your app's root entry point:
```javascript
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';
Amplify.configure(outputs);
```
If you are using Next.js, you need to add the following code to your `pages/_app.js` file instead:
```javascript
import { Amplify } from 'aws-amplify';
import outputs from '@/amplify_outputs.json';
Amplify.configure(outputs);
```
Make sure to call `Amplify.configure` as early as possible in your application's life cycle.

To initialize Amplify Geo, you need to add the AWS Location Geo plugin to your app. You can do this by using the `Amplify.addPlugin` method.

To display a map in your application, you can use the Amplify React MapView component or the MapLibre GL library with the `maplibre-gl-js-amplify` library.

Note that the Geo plugin has a dependency on Cognito Auth, so you need to install and configure Cognito Auth as well.

For Android and iOS, you need to install the Amplify Libraries and initialize Amplify Geo using the `Amplify.addPlugin` method.

If you want to use existing Amazon Location Service resources, you can follow a different guide. If you want to use Amazon Location Service APIs not directly supported by Geo, you can use the escape hatch to access the Amazon Location Service SDK.

The pricing plan for the Map example is set to `RequestBasedUsage`. You should review the location service pricing and terms to learn more about the pricing plan. 

Here is an example of how to create a map using the Amplify MapView component:
```javascript
import { MapView } from '@aws-amplify/geo';

const MyMap = () => {
  return (
    <MapView
      style={{
        flex: 1,
        height: '100%',
        width: '100%',
      }}
    />
  );
};
```
This will render a map in your application. You can customize the map by using various props and methods provided by the MapView component.

AWS Amplify Gen 2 is a TypeScript-based, code-first developer experience for defining backends. It offers a unified Amplify developer experience with hosting, backend, and UI-building capabilities, and a code-first approach. Amplify enables frontend developers to deploy cloud infrastructure by expressing their app's data model, business logic, authentication, and authorization rules in TypeScript. Amplify automatically configures the correct cloud resources, removing the need to manually stitch together underlying AWS services.

You can use Amplify for end-to-end full-stack development. With the Gen 2 developer experience, you can provision backend infrastructure by writing TypeScript code in files following a file-based convention. This approach provides strict typing and IntelliSense in Visual Studio Code, preventing errors. A breaking change in the backend code immediately reflects as a type error in the co-located frontend code.

Amplify also provides faster local development with per-developer cloud sandbox environments. These environments are optimized for faster iterations, allowing each developer to work on full-stack features independently without disrupting others. Additionally, Amplify offers full-stack Git-based environments, where all shared environments map 1:1 to Git branches in your repository. This enables testing of new features in ephemeral environments before merging into production.

The Amplify console provides a single place to manage builds, hosting settings, deployed resources, and environment variables. You can access deployed resources directly in other AWS service consoles, but the Amplify console offers a first-party experience for common app needs like data, authentication, storage, and functions.

To build an app with Amplify, you can start with data. The @aws-amplify/backend library provides a TypeScript-first Data library for setting up fully typed real-time APIs and NoSQL databases. You define your app's data schema in a file like amplify/data/resource.ts, and the defineData function turns the schema into a fully functioning data backend.

For example, a data model for a chat app might look like this:
```typescript
const schema = {
  Chat: {
    name: 'string',
    message: 'hasMany(Message, chatId)',
  },
  Message: {
    text: 'string',
    chat: 'belongsTo(Chat, chatId)',
    chatId: 'id'
  },
};
```
On the frontend, you can use the generateClient function to get a typed client instance, making it easy to integrate CRUD operations into your app code. For example:
```typescript
const client = generateClient<Schema>();
const { data } = await client.models.Message.list();
const { errors, data: newMessage } = await client.models.Message.create({
  text: 'My message text'
});
```
Amplify also provides authentication capabilities. You can configure authentication settings in amplify/auth/resource.ts and customize the sign-in and registration flows, multi-factor authentication, and third-party social providers. Amplify deploys an Amazon Cognito instance when you add authentication to your app.

To add authentication to your React app, you can use the Amplify Authenticator component:
```typescript
import { withAuthenticator } from '@aws-amplify/ui-react';

function App({ signOut, user }) {
  return (
    <>
      <h1>Hello {user.username}</h1>
      <button onClick={signOut}>Sign out</button>
    </>
  );
}

export default withAuthenticator(App);
```
Amplify makes it easy to build web app user interfaces using the UI component library, Figma-to-code generation, and CRUD form-generation capabilities.

Beyond Amplify, you can connect to any AWS resource using the AWS Cloud Development Kit (CDK). The Data and Auth capabilities in @aws-amplify/backend wrap L3 AWS CDK constructs, making it easy to extend the resources generated by Amplify. For example, you can add Amazon Location Services by creating a new file: amplify/custom/maps/resource.ts:
```typescript
import * as locations from 'aws-cdk-lib/aws-location';

export class LocationMapStack extends Stack {
  constructor(scope: Construct, id: string, props?: StackProps) {
    super(scope, id, props);

    const map = new locations.CfnMap(this, 'LocationMap', {
      configuration: {
        style: 'VectorEsriStreets' 
      },
      description: 'My Location Map',
      mapName: 'MyMap'
    });

    new CfnOutput(this, 'mapArn', {
      value: map.attrArn,
      exportName: 'mapArn'
    });
  }
}
```
This stack can be included in the amplify/backend.ts file to deploy as part of your Amplify app. Amplify is designed to work with existing AWS resources and configurations, allowing you to adopt its capabilities incrementally into your current workflows.

Is there a way to upgrade an existing Amplify project from Gen 1 to Gen 2?

Amplify is still developing migration tooling to aid in transitioning projects from Gen 1 to Gen 2. Until then, it's recommended to continue working with Gen 1 Amplify projects. A feature support matrix comparing Gen 1 and Gen 2 is available. For new projects, it's recommended to adopt Gen 2 to take advantage of its enhanced capabilities. 

If I have a Gen 1 app, can I use Gen 2 in it?

Amplify Gen 1 and Gen 2 follow different architectural and tooling paradigms. Migration tooling is needed to move from a Gen 1 to Gen 2 app. It's not possible to use Amplify Gen 1 and Gen 2 in the same app.

Should I use Amplify Gen 1 or Gen 2 in new apps?

For new apps, it's recommended to use Amplify Gen 2.

Does Amplify Gen 2 support DataStore?

Amplify Gen 2 supports GraphQL APIs without DataStore. Migration support for moving DataStore Gen 1 apps to Gen 2 will be released.

What programming languages does Amplify Gen 2 support?

Amplify Gen 2 supports multiple programming languages, including JavaScript, TypeScript, Dart, Java, Kotlin, and Swift, for client-side development. For backend development, Amplify Gen 2 uses TypeScript.

In Gen 1, Amplify offered a set of use case categories for building applications. Are those same categories available in Gen 2?

Amplify Gen 2 offers built-in support for Auth, Data, Storage, and Functions. Other use cases can be implemented using AWS Cloud Development Kit constructs.

Can I use Gen 2 with a JavaScript frontend that doesn't use TypeScript?

Yes, Amplify Gen 2's TypeScript backend definition works with JavaScript frontends, providing a typed data fetching experience.

What if we want to add a feature like AI/ML or Amazon Location Service to our application in Gen 2?

Any AWS services supported by the AWS CDK can be added to an app using custom resources and L2/L1 AWS CDK constructs.

What happens once my application grows too big and I want to do more configuration with my application?

Amplify is layered on top of the AWS CDK and AWS CloudFormation, allowing the addition of any AWS services supported by CDK to an Amplify app. Configuration of resources can be overridden using the CDK, and any deployment pipeline can be used for more control over CI.

How much does it cost to operate Amplify Gen2?

Pricing information for Amplify is available on the Amplify pricing page.

Which Amplify JavaScript version is compatible with Gen 2?

Amplify JavaScript version 6.2.0 and above is compatible with backends created by Amplify Gen 2. 

Can I use any other database storage other than Amazon DynamoDB? 

Yes, it's possible to use an existing MySQL or PostgreSQL database in an Amplify app. With custom query and mutation support, it's possible to integrate with any existing data source through a Lambda function.

To create an in-app messaging campaign on the AWS Console, you can follow these steps. This is an alternative to writing AWS Cloud Development Kit (CDK) code. 

1. Log in to the AWS Console and search for Pinpoint.
2. Click on your project from the list of available projects. Your project name would be the name you provided when you created the Pinpoint project using CDK.
3. Click on Campaigns from the left navigation menu, and then click on Create a campaign.
4. Add a name to your campaign and select the following options: 
   - Campaign type: Standard campaign
   - Channel: In-App messaging
   - Set prioritization: Fairly important
   Then click Next.
5. Click on the Create a segment radio button, add a name for your segment, and then click Next. 
   You can add as many segments as needed to the campaign. For this quickstart, you can use Include any audiences under the Segment group 1 section.
   You can also add criteria to your segments to ensure that audiences that satisfy that criteria can receive the in-app message.
6. Click on the Create a new in-app message radio button.
7. You can customize the following attributes of the in-app message: 
   - Layout: Which includes all of the different messaging layout options.
   - Header: Title of the in-app message, including the text color/alignment.
   - Message: The body of the message, including the text color/alignment.
   - Background: Control the background color of the in-app message.
   - Image URL: Add an image to be displayed as part of the in-app message body.
   - Primary button: Allows the addition of a button to add functionality to the in-app message.
   - Secondary button: Allows the addition of an extra button for additional functionality.
   - Custom Data: Allows the in-app message to pass additional data to the frontend app once it is triggered by an event.
8. Create a simple message and click on Next.
9. Under Trigger events, add the name of the analytics trigger that will be sent from your frontend app. 
   You can customize the trigger to allow only certain attributes or metrics that are passed with the analytics event to trigger the in-app message.
10. Update the threshold for the number of messages shown per session if necessary.
11. Review your campaign and then click on Launch campaign.

Note that the campaign start time must be at least 15 minutes in the future. In-app messages can only be synced to a local device once the campaign becomes active. 

When configuring In-App Messaging for React Native, note that SVG rendering is not supported out of the box. For SVG image support with In-App Messaging, a custom UI implementation is required. 

To implement this in your React app, you would need to set up an analytics trigger that will be sent from your frontend app to trigger the in-app message, and then handle the in-app message display in your app. This could be done by adding an event listener to your app to listen for the analytics trigger, and then displaying the in-app message when the trigger is received. 

For example, in your React app, you might have a function to handle the display of in-app messages:
```javascript
function handleInAppMessage(message) {
  // Display the in-app message to the user
  // This could involve rendering a modal or alert with the message
}
```
Then, when the analytics trigger is received, you would call this function to display the in-app message:
```javascript
// Set up an event listener to listen for the analytics trigger
window.addEventListener('analyticsTrigger', (event) => {
  // Get the in-app message from the event data
  const message = event.detail.message;
  
  // Call the function to display the in-app message
  handleInAppMessage(message);
});
```

In-app messages are displayed when an In-App Messaging or analytics event is sent and matches the criteria defined by your active In-App Messaging campaigns.

An analytics event triggers the display of an in-app message if it matches the attributes and criteria defined in the message. Any events recorded using the Analytics record API are automatically picked up and processed by In-App Messaging. For example, you can record an event like this:
```
import { Analytics } from 'aws-amplify';

Analytics.record({
  name: 'first_event',
  attributes: { color: 'red' },
  metrics: { quantity: 10 }
});
```
If the event name, attributes, and metrics match those set forth by one of your In-App Messaging campaigns, you should see the in-app message displayed in your app.

In addition to or instead of Amplify Analytics events, you can also dispatch In-App Messaging events to trigger an in-app message display programmatically. For example:
```
import { InAppMessaging } from 'aws-amplify';

InAppMessaging.dispatchEvent({
  name: 'first_event',
  attributes: { color: 'red' },
  metrics: { quantity: 10 }
});
```
If the event name, attributes, and metrics match those set forth by one of your In-App Messaging campaigns, you should see the in-app message displayed in your app.

To fully harness the potential of In-App Messaging, you must segment and target your In-App Messaging campaigns to specific user subsets. By identifying users with additional information, including their device demographics, location and any attributes of your choosing, you will be able to display intelligent, targeted in-app messages to the right users.

To identify a user, you can use the `identifyUser` function from the `aws-amplify/in-app-messaging` library. This function takes an object with two properties: `userId` and `userProfile`. The `userId` is a unique identifier for the user, and the `userProfile` is an object that contains additional information about the user. 

The `userProfile` object can have several properties, including `email`, `name`, and `plan`, which are used to store basic user information. It can also have a `customProperties` object, which can store any additional attributes of your choosing, such as hobbies or interests. 

Additionally, the `userProfile` object can have a `demographic` property, which contains information about the user's device, such as the app version, locale, make, model, platform, and timezone. It can also have a `location` property, which contains information about the user's location, such as city, country, postal code, region, latitude, and longitude. 

Finally, the `userProfile` object can have a `metrics` property, which can store any metrics or statistics about the user, such as the number of logins. 

Here is an example of how to use the `identifyUser` function in a React application:
```js
import { identifyUser } from 'aws-amplify/in-app-messaging';

await identifyUser({
  userId: 'user-id',
  userProfile: {
    email: 'example@service.com',
    name: 'name-of-the-user',
    plan: 'plan-they-subscribe-to',
    customProperties: {
      hobbies: ['cooking', 'knitting'],
    },
    demographic: {
      appVersion: '1.0',
      locale: 'en_US',
      make: 'Apple',
      model: 'iPhone',
      modelVersion: '13',
      platform: 'iOS',
      platformVersion: '15',
      timezone: 'Americas/Los_Angeles'
    },
    location: {
      city: 'Seattle',
      country: 'US',
      postalCode: '98121',
      region: 'WA',
      latitude: 47.6062,
      longitude: -122.3321
    },
    metrics: {
      logins: 157
    },
  },
});
```

When using `identifyUser` with Amazon Pinpoint, you can also configure the `address`, `optOut`, and `userAttributes` properties under `options`. Here is an example:
```js
import { identifyUser } from 'aws-amplify/in-app-messaging';

await identifyUser({
  userId: 'user-id',
  options: {
    address: 'device-token-or-email-address',
    optOut: 'ALL',
    userAttributes: {
      interests: ['soccer', 'shoes'],
    }
  },
});
```

To integrate your React application with In-app Messaging, first install the required packages. For React Native, run the following command in your terminal:
```
npm add @aws-amplify/react-native @react-native-community/netinfo @react-native-async-storage/async-storage
```
For React, run the following command:
```
npm add @aws-amplify/ui-react @aws-amplify/ui-react-notifications
```
Next, install Amplify UI for your framework. For React Native, run:
```
npm add @aws-amplify/ui-react-native react-native-safe-area-context@^4.2.5
```
For React, run:
```
npm add @aws-amplify/ui-react @aws-amplify/ui-react-notifications
```
Now, integrate Amplify UI into your application. For React Native, wrap your application root component in the `withInAppMessaging` Higher-Order Component:
```javascript
import { withInAppMessaging } from '@aws-amplify/ui-react-native';

const App = () => (
  {/* Your application code */}
);

export default withInAppMessaging(App);
```
For React, do the same:
```javascript
import { withInAppMessaging } from '@aws-amplify/ui-react-notifications';
import '@aws-amplify/ui-react/styles.css';

const App = () => (
  {/* Your application code */}
);

export default withInAppMessaging(App);
```
Your entry file should look like this for React Native:
```jsx
import React, { useEffect } from 'react';
import { Button, View } from 'react-native';
import {
  initializeInAppMessaging,
  syncMessages,
  dispatchEvent
} from 'aws-amplify/in-app-messaging';
import { withInAppMessaging } from '@aws-amplify/ui-react-native';
import { record } from 'aws-amplify/analytics';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
initializeInAppMessaging();

const myFirstEvent = { name: 'my_first_event' };

const App = () => {
  useEffect(() => {
    syncMessages();
  }, []);

  return (
    <View>
      <Button
        onPress={() => {
          record(myFirstEvent);
        }}
        title="Record Analytics Event"
      />
      <Button
        onPress={() => {
          dispatchEvent(myFirstEvent);
        }}
        title="Send In-App Messaging Event"
      />
    </View>
  );
};

export default withInAppMessaging(App);
```
And like this for React:
```jsx
import React, { useEffect } from 'react';
import {
  initializeInAppMessaging,
  syncMessages,
  dispatchEvent
} from 'aws-amplify/in-app-messaging';
import { Button, View } from '@aws-amplify/ui-react';
import { withInAppMessaging } from '@aws-amplify/ui-react-notifications';
import { record } from 'aws-amplify/analytics';
import '@aws-amplify/ui-react/styles.css';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
initializeInAppMessaging();

const myFirstEvent = { name: 'my_first_event' };

const App = () => {
  useEffect(() => {
    syncMessages();
  }, []);

  return (
    <View>
      <Button
        onClick={() => {
          record(myFirstEvent);
        }}
      >
        Record Analytics Event
      </Button>
      <Button
        onClick={() => {
          dispatchEvent(myFirstEvent);
        }}
      >
        Send In-App Messaging Event
      </Button>
    </View>
  );
};

export default withInAppMessaging(App);
```
You can now build and run your app. If you click on one of the buttons, the in-app message you defined in the Pinpoint console should be displayed in your app.

When an event is sent and meets the criteria for multiple in-app messages, a conflict arises and the library must decide which message to return. To resolve this conflict, In-App Messaging sorts the messages by campaign expiration and returns the message closest to expiry. 

However, you can set a custom conflict handler to resolve conflicts according to your own strategy. Your custom handler must accept an array of in-app messages and return a single in-app message.

For example, you can create a custom conflict handler that returns a random message from the array of conflicting messages. Here's how you can set a custom conflict handler in a React application:
```
import { setConflictHandler } from 'aws-amplify/in-app-messaging';

const myConflictHandler = (messages) => {
  const randomIndex = Math.floor(Math.random() * messages.length);
  return messages[randomIndex];
};

setConflictHandler(myConflictHandler);
```

You can respond with additional behavior to your users interacting with in-app messages by adding interaction event listeners. 

To respond to an in-app message being received, add an `onMessageReceived` listener. This is necessary if you are implementing a custom UI so that your UI can respond to event-triggered campaign messages. Here is an example of how to add this listener in React:

```javascript
import { onMessageReceived } from 'aws-amplify/in-app-messaging';

const myMessageReceivedHandler = (message) => {
  // Do something with the received message
};

const listener = onMessageReceived(myMessageReceivedHandler);

listener.remove(); // Remember to remove the listener when it is no longer needed
```

To respond to an in-app message being displayed, add an `onMessageDisplayed` listener. Here is an example:

```javascript
import { onMessageDisplayed } from 'aws-amplify/in-app-messaging';

const myMessageDisplayedHandler = (message) => {
  // Do something with the displayed message
};

const listener = onMessageDisplayed(myMessageDisplayedHandler);

listener.remove(); // Remember to remove the listener when it is no longer needed
```

To respond to an in-app message being dismissed, add an `onMessageDismissed` listener. Here is an example:

```javascript
import { onMessageDismissed } from 'aws-amplify/in-app-messaging';

const myMessageDismissedHandler = (message) => {
  // Do something with the dismissed message
};

const listener = onMessageDismissed(myMessageDismissedHandler);

listener.remove(); // Remember to remove the listener when it is no longer needed
```

To respond to an action being taken on an in-app message, add an `onMessageActionTaken` listener. Here is an example:

```javascript
import { onMessageActionTaken } from 'aws-amplify/in-app-messaging';

const myMessageActionTakenHandler = (message) => {
  // Do something with the message action was taken against
};

const listener = onMessageActionTaken(myMessageActionTakenHandler);

listener.remove(); // Remember to remove the listener when it is no longer needed
```

If you are implementing your own UI, it is recommended to notify listeners of interaction events through your UI code so that the library can take further actions. Here is an example:

```javascript
import { notifyMessageInteraction } from 'aws-amplify/in-app-messaging';

const message = {
  // In-app message that you want to record an interaction on
}

// Interaction events that can be notified correspond to their respective listeners:
//    'messageReceived'
//    'messageDisplayed'
//    'messageDismissed'
//    'messageActionTaken'
notifyMessageInteraction({ message, type: 'messageDisplayed' });
```

Amplify allows you to interact with In-App Messaging APIs, which enables you to send messages to your app users. In-App Messaging is a powerful tool to engage with your users and provide them with relevant information. 

A campaign is a messaging initiative that engages a specific audience segment. A campaign sends tailored messages according to a schedule that you define. You can use the AWS Cloud Development Kit (AWS CDK) to create a campaign that sends messages through any single channel that is supported by Amazon Pinpoint, such as Mobile Push, In-App, Email, SMS, or Custom channels.

To create an In-App Messaging resource, you can use the AWS CDK. Note that there are no official hand-written constructs for this service yet. 

When creating a campaign, the start time must be at least 15 minutes in the future. In-app messages can only be synced to the local device once the campaign becomes active, which is indicated by a "Status" of "In Progress" in the campaigns screen of the Pinpoint console.

Here's an example of how to create an In-App Messaging resource using the AWS CDK. This example creates a Pinpoint app, a segment, and a campaign with an event and in-app message template.

To create a Pinpoint app, segment, and campaign in React, you can use the following code:
```javascript
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import {
  CfnApp,
  CfnCampaign,
  CfnSegment,
} from "aws-cdk-lib/aws-pinpoint";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { Stack } from "aws-cdk-lib/core";

const backend = defineBackend({
  auth, 
  data,
});

const inAppMessagingStack = backend.createStack("inAppMessaging-stack");

// create a Pinpoint app
const pinpoint = new CfnApp(inAppMessagingStack, "Pinpoint", {
  name: "myPinpointApp",
});

// create a segment 
const mySegment = new CfnSegment(inAppMessagingStack, "Segment", {
  applicationId: pinpoint.ref,
  name: "mySegment",
});

// create a campaign with event and in-app message template
new CfnCampaign(inAppMessagingStack, "Campaign", {
  applicationId: pinpoint.ref,
  name: "MyCampaign",
  segmentId: mySegment.attrSegmentId,
  schedule: {
    startTime: "2024-02-23T14:39:34Z", 
    endTime: "2024-02-29T14:32:40Z",
    frequency: "IN_APP_EVENT",
    eventFilter: {
      dimensions: {
        eventType: {
          dimensionType: "INCLUSIVE",
          values: ["my_first_event"],
        },
      },
      filterType: "ENDPOINT",
    },
  },

  messageConfiguration: {
    inAppMessage: {
      layout: "TOP_BANNER",
      content: [
        {
          bodyConfig: {
            alignment: "CENTER",
            body: "This is an example in-app message.",
            textColor: "#FFFFFF",
          },
          backgroundColor: "#000000",
          headerConfig: {
            alignment: "CENTER",
            header: "Welcome!",
            textColor: "#FFFFFF",
          },
        },
      ],
    },
  },
});
```

To install Amplify libraries, you need to first install the `aws-amplify` library. 

To initialize In-App Messaging, you need to configure your application using the `configure` API and then initialize In-App Messaging by calling the `initializeInAppMessaging` API. 

Here's how to initialize In-App Messaging in a React application:
```javascript
import { Amplify } from 'aws-amplify';
import { initializeInAppMessaging } from 'aws-amplify/in-app-messaging';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
initializeInAppMessaging();
```

Make sure you call `Amplify.configure` as early as possible in your application’s life-cycle to avoid any missing configuration or `NoCredentials` errors.

To trigger in-app messages, you need to sync them from your In-App Messaging campaigns to your users' devices. These messages are then displayed when a matching event is triggered, such as an analytics or In-App Messaging event. You have control over when and how often this sync is performed.

To sync messages in a React application, use the `syncMessages` function from the `aws-amplify/in-app-messaging` module. Here's an example:
```js
import { syncMessages } from 'aws-amplify/in-app-messaging';

await syncMessages();
```
Note that syncing messages will always overwrite any existing messages on the user's device, ensuring they are up to date after each sync.

When using the Amplify Logger in a React application, all logged messages are saved locally on the user's device first before sending them to CloudWatch. This section explains how to configure the maximum amount of local logs that are stored. This can be helpful in determining how much logs are stored locally depending on your network availability and offline use cases.

To change the local storage maximum size, you can update the `localStoreMaxSizeInMB` field in the Amplify configuration. For example, to set the local storage size to 2 MB, you can use the following configuration:
```json
{
  "awsCloudWatchLoggingPlugin": {
    "enable": true,
    "logGroupName": "<log-group-name>",
    "region": "<region>",
    "localStoreMaxSizeInMB": 2,
    "flushIntervalInSeconds": 60,
    "loggingConstraints": {
      "defaultLogLevel": "WARN"
    }
  }
}
```
In a React application, you would typically configure Amplify using the `Amplify.configure` method. To set the local storage size, you would create an `AWSCloudWatchLoggingPluginConfiguration` object and pass it to the `Amplify.addPlugin` method. Here is an example of how you might do this in React:
```jsx
import Amplify from 'aws-amplify';
import { AWSCloudWatchLoggingPlugin } from 'aws-amplify';

const loggingConfiguration = {
  logGroupName: '<log-group-name>',
  region: '<region>',
  localStoreMaxSizeInMB: 2,
};

const loggingPlugin = new AWSCloudWatchLoggingPlugin(loggingConfiguration);

Amplify.addPlugin(loggingPlugin);
```
Note that you will need to replace `<log-group-name>` and `<region>` with the actual values for your AWS CloudWatch log group and region.

You can configure the logging level in your application when using the Amplify logger. This helps you determine the logging level that works best for your use cases and which levels of errors or warnings you want to capture in Amazon Cloudwatch.

To change the default log level, you can update the `defaultLogLevel` field under `loggingConstraints`. Supported log levels include:
* `ERROR`
* `WARN`
* `INFO`
* `DEBUG`
* `VERBOSE`
* `NONE`

Setting the log level to `NONE` effectively disables logging. 

You can set the default log level in a configuration file or through code. In React, you would typically set the log level through code. 

For example, to set the default log level to `WARN`:
```javascript
const loggingConstraints = {
  defaultLogLevel: 'WARN'
};
const loggingConfiguration = {
  logGroupName: '<log-group-name>',
  region: '<region>',
  loggingConstraints: loggingConstraints
};
Amplify.addPlugin(new AWSCloudWatchLoggingPlugin(loggingConfiguration));
```

You can also configure the log level by category. Each Amplify category can be configured to have its own logging level. 

To set different logging levels for categories, you can add a `categoryLogLevel` section and specify each category and its log level in the configuration file:
```json
{
  "awsCloudWatchLoggingPlugin": {
    "enable": true,
    "logGroupName": "<log-group-name>",
    "region": "<region>",
    "localStoreMaxSizeInMB": 1,
    "flushIntervalInSeconds": 60,
    "loggingConstraints": {
      "defaultLogLevel": "ERROR",
      "categoryLogLevel": {
        "Authentication": "VERBOSE",
        "Storage": "DEBUG"
      }
    }
  }
}
```

Or, you can provide a dictionary of category and corresponding log levels at initialization and configuration of the `AWSCloudWatchLoggingPlugin`:
```javascript
const categoryLogLevels = {
  'Authentication': 'VERBOSE',
  'Storage': 'DEBUG'
};
const loggingConstraints = {
  defaultLogLevel: 'ERROR',
  categoryLogLevel: categoryLogLevels
};
const loggingConfiguration = {
  logGroupName: '<log-group-name>',
  region: '<region>',
  loggingConstraints: loggingConstraints
};
Amplify.addPlugin(new AWSCloudWatchLoggingPlugin(loggingConfiguration));
```

To disable logging for a specific category, set the log level to `NONE`. 

Existing Amplify category names that are used by default by Amplify when automatically logging errors from the library include:
* `Analytics`
* `API`
* `Authentication`
* `DataStore`
* `Geo`
* `Hub`
* `Logging`
* `Predictions`
* `PushNotifications`
* `Storage`

Each Amplify authenticated user can be configured to have their own unique logging configuration. This is helpful in enabling you to debug issues more granularly for your users.

To configure user log levels, you can retrieve the user ID using Amplify Auth. You can do this by using the Amplify Auth category.

In React, you can retrieve the user ID by using the Amplify Auth library. 

To configure user log levels, you can set different default and category log levels for an authenticated user. 

Here is an example of setting different default and category log levels for an authenticated user in React:

```javascript
import Amplify from 'aws-amplify';
import { AWSCloudWatchLoggingPlugin } from 'aws-amplify';

const categoryLogLevels = {
  "Storage": "VERBOSE",
  "Api": "VERBOSE"
};

const userLogLevel = {
  defaultLogLevel: "DEBUG",
  categoryLogLevel: categoryLogLevels
};

const userLogLevels = {
  "xyz-123": userLogLevel
};

const loggingConstraints = {
  defaultLogLevel: "ERROR",
  userLogLevel: userLogLevels
};

const loggingConfiguration = {
  logGroupName: "<log-group-name>",
  region: "<region>",
  loggingConstraints: loggingConstraints
};

Amplify.addPlugin(new AWSCloudWatchLoggingPlugin(loggingConfiguration));
```

Alternatively, you can also configure user log levels by using a configuration file. 

```json
{
  "awsCloudWatchLoggingPlugin": {
    "enable": true,
    "logGroupName": "<log-group-name>",
    "region": "<region>",
    "localStoreMaxSizeInMB": 1,
    "flushIntervalInSeconds": 60,
    "loggingConstraints": {
      "defaultLogLevel": "ERROR",
      "userLogLevel": {
        "xyz-123": {
          "defaultLogLevel": "DEBUG",
          "categoryLogLevel": {
            "Storage": "VERBOSE",
            "Api": "VERBOSE"
          }
        }
      }
    }
  }
}
```

To enable and disable logging when using the Amplify Logger, you can use the following methods. The Amplify Logger is enabled by default, unless it is disabled in the amplifyconfiguration_logging file.

For Android, you can enable the Amplify Logger using 
```java
Amplify.Logging.enable();
```
and disable it using 
```java
Amplify.Logging.disable();
```
In React, you would use the Amplify Logger like this 
```javascript
import Amplify from 'aws-amplify';

Amplify.Logging.enable();
Amplify.Logging.disable();
```
For Swift, you can enable the Amplify Logger using 
```swift
Amplify.Logging.enable()
```
and disable it using 
```swift
Amplify.Logging.disable()
```

When using the Amplify Logger, all logged messages are saved locally on the user's device first and then flushed at a set interval that you can customize. You can also choose to flush events manually if needed.

To customize the time interval for when logs are automatically flushed and sent to CloudWatch, you can set the `flushIntervalInSeconds` field in the logging configuration file. For example, to set the time interval to 120 seconds, you would update the configuration file as follows:
```json
{
    "awsCloudWatchLoggingPlugin": {
        "enable": true,
        "logGroupName": "<log-group-name>",
        "region": "<region>",
        "localStoreMaxSizeInMB": 1,
        "flushIntervalInSeconds": 120,
        "loggingConstraints": {
            "defaultLogLevel": "ERROR"
        }
    }
}
```
Alternatively, you can provide a `flushIntervalInSeconds` parameter when initializing and configuring the `AWSCloudWatchLoggingPlugin` in your code.

To manually flush logs, you can use the `flushLogs` function from the `AWSCloudWatchLoggingPlugin`. In React, you would first import the `AWSCloudWatchLoggingPlugin` and then execute the `flushLogs` function. Here's an example:
```javascript
import { Amplify } from 'aws-amplify';

// Get the AWSCloudWatchLoggingPlugin
const cloudWatchPlugin = await Amplify.Logging.getPlugin('awsCloudWatchLoggingPlugin');

// Flush the logs
cloudWatchPlugin.flushLogs(() => {
    // logs flushed successfully
}, (error) => {
    // failed to flush logs
});
```
Note that in React, you would typically use the `flushLogs` function provided by the `AWSCloudWatchLoggingPlugin` instance, rather than the `try await` syntax shown in the Swift example.

The Amplify Logger sends errors that occur when using it through Amplify Hub. To ensure that errors do not occur when logging, log messages should be validated and follow the best security practices. Additionally, you should ensure that log messages do not exceed the Amazon CloudWatch log event size of 256 KB.

You can get logging error events by listening/subscribing to the logging events from the Amplify Hub.

In React, you can listen to log events using the Amplify Hub. The Hub sends log events when there is an error writing to the local log or sending log events to CloudWatch. 

Here is an example of how you can listen to log events in React:

```javascript
import { Hub } from 'aws-amplify';

Hub.listen('logging', (data) => {
  if (data.eventName === 'writeLogFailure') {
    console.log('Error writing to local log');
  } else if (data.eventName === 'flushLogFailure') {
    console.log('Error sending log events to CloudWatch');
  }
});
```

You can remotely configure the Amplify Logger, which allows you to make changes to your logging levels or user allow list in your deployed applications. The logging configurations you set remotely will overwrite the local log level and persist for future app sessions.

To set up remote configuration, you need to create backend resources, including an Amazon CloudWatch log group, an AWS API Gateway, an AWS Lambda function, and an AWS S3 bucket. You can use the Amplify CDK to add custom resources.

The CDK construct provisions the necessary resources and deploys a remote configuration file to the S3 bucket. You can update this file to change the configuration level or user allow list. The construct also creates IAM policies and assigns them to the Amplify authenticated and unauthenticated roles.

To use the remote configuration, you need to replace the placeholder values with your own values, including the log group name, S3 bucket name, and Amplify role names. The CDK construct provides the location and lambda for reading from S3, as well as the location and file name of the log level configuration file.

The API endpoint, CloudWatch log group, and region will be printed out in the terminal. You can use this information to set up the Amplify library.

A sample lambda handler is provided that reads and returns the remote logging constraints from AWS S3. The handler caches the configuration by version using ETag, which allows it to be more efficient and save bandwidth.

A sample remote configuration file is also provided, which overwrites the local file in the mobile application. This file can be deployed to S3 and updated to change the application log levels.

To enable remote configuration in your app, you need to provide the API endpoint and refresh interval for updating the remote configuration locally on the user's device. You can do this by updating the amplify configuration file or using code.

For example, in React, you can enable remote configuration by adding a new section to the amplify configuration file:
```json
{
  "awsCloudWatchLoggingPlugin": {
    "enable": true,
    "logGroupName": "<log-group-name>",
    "region": "<region>",
    "localStoreMaxSizeInMB": 1,
    "flushIntervalInSeconds": 60,
    "loggingConstraints": {
      "defaultLogLevel": "ERROR"
    },
    "defaultRemoteConfiguration": {
      "endpoint": "<your-api-endpoint>",
      "refreshIntervalInSeconds": 1200
    }
  }
}
```
Alternatively, you can use code to enable remote configuration. For example:
```javascript
import Amplify from 'aws-amplify';

Amplify.configure({
  awsCloudWatchLoggingPlugin: {
    enable: true,
    logGroupName: '<log-group-name>',
    region: '<region>',
    localStoreMaxSizeInMB: 1,
    flushIntervalInSeconds: 60,
    loggingConstraints: {
      defaultLogLevel: 'ERROR'
    },
    defaultRemoteConfiguration: {
      endpoint: '<your-api-endpoint>',
      refreshIntervalInSeconds: 1200
    }
  }
});
```

For advanced use cases where Amplify does not provide the functionality, you can retrieve the escape hatch to access the underlying Amazon CloudWatch client.

On Android, the escape hatch provides access to the underlying `CloudWatchLogsClient` instance. You can retrieve the escape hatch with the following code:
```java
AWSCloudWatchLoggingPlugin plugin = (AWSCloudWatchLoggingPlugin)Amplify.Logging.getPlugin("awsCloudWatchLoggingPlugin");
CloudWatchLogsClient client = plugin.getEscapeHatch();
```
or in Kotlin:
```kotlin
val plugin = Amplify.Logging.getPlugin("awsCloudWatchLoggingPlugin") as AWSCloudWatchLoggingPlugin
val client = plugin.escapeHatch
```
You will also need to add the necessary Gradle imports:
```kotlin
implementation("aws.sdk.kotlin:cloudwatchlogs:KOTLIN_SDK_VERSION")
```
On iOS, you can get a direct reference to the instance of CloudWatchLogsClientProtocol and directly interact with AWSCloudWatch via the AWS SDK for Swift. First, add the necessary import statements:
```swift
import AWSCloudWatchLoggingPlugin
import AWSCloudWatchLogs
```
Then, you can retrieve the escape hatch with the following code:
```swift
let cloudWatchPlugin = try Amplify.Logging.getPlugin(for: "awsCloudWatchLoggingPlugin") as? AWSCloudWatchLoggingPlugin
let cloudWatchClient: CloudWatchLogsClientProtocol? = cloudWatchPlugin?.getEscapeHatch()
```

With the Amplify Logger, you can send logs to Amazon CloudWatch from errors that are caught by the Amplify library or by adding your own custom log messages. You can also customize which levels of log messages to send to CloudWatch.

When logging messages, you should follow best security practices, including validating log messages and ensuring they don't contain personally identifiable information and/or sensitive data.

You can log messages using the Amplify logger to a specific namespace to help you group logs that are similar when they are sent to CloudWatch. To accomplish this, get an instance of the Logger and specify a category name and/or namespace. Use the Logger instance to log messages at the desired log level. The category name and namespace values are used to tag your log messages that will appear in CloudWatch.

You can also log JSON formatted log messages to leverage AWS CloudWatch query and filter supports.

Here is an example in React:
```javascript
const logger = Amplify.Logging.logger('Authentication', 'my-namespace');
try {
  const result = doSomething();
  logger.debug(`result: ${result}`);
} catch (error) {
  logger.error('operation failed', error);
}
```
The following are existing Amplify category names that are used by default by Amplify when automatically logging errors from the library:
* ANALYTICS
* API
* AUTH
* DATASTORE
* HUB
* LOGGING
* NOTIFICATIONS
* PREDICTIONS
* STORAGE
* GEO

Note that the Amplify category names may vary depending on the platform being used.

The Amplify Logger enables you to troubleshoot and debug issues with your apps, to help you provide the best experience for your customers. You can log messages for errors by the Amplify library and add custom logs as well and send them to Amazon CloudWatch. With the Amplify Logger, you also can remotely change your logging configuration to adjust your logging levels, or add an allow list of customer IDs to help you detect issues more granularly for your apps in production.

## Prerequisites
To set up Amplify logging, you need to have an Amplify application with the Amplify libraries integrated. For Android, the Amplify Logger is available for versions 2.11.0 and beyond of the Amplify Android SDK. For iOS, the minimum target is iOS 13.0, using Xcode 14.1 or later.

## Install the Amplify library
To install the Amplify library, you need to add the following dependencies to your build.gradle file:
```kotlin
dependencies {
    implementation("com.amplifyframework:aws-auth-cognito:ANDROID_VERSION")
    implementation("com.amplifyframework:aws-logging-cloudwatch:ANDROID_VERSION")
}
```
For iOS, you can install the Amplify library using Swift Package Manager or CocoaPods.

## Set up the backend
To set up the backend, you need to create a log group in Amazon CloudWatch to send logs to. You can create and provision a log group by going through the AWS Console and creating your log group manually or using Amplify and AWS CDK to provision and deploy the AWS resources.

## Initialize Amplify Logging
To initialize Amplify logging, you need to add the AWSCloudWatchLoggingPlugin to your Amplify configuration. You can do this by creating a configuration file or by adding the plugin to your code.

### With Configuration File
You can create a configuration file named `amplifyconfiguration_logging.json` with the following content:
```json
{
    "awsCloudWatchLoggingPlugin": {
        "enable": true,
        "logGroupName": "<log-group-name>",
        "region": "<region>",
        "localStoreMaxSizeInMB": 1,
        "flushIntervalInSeconds": 60,
        "loggingConstraints": {
            "defaultLogLevel": "ERROR"
        }
    }
}
```
Then, you can add the following code to your app:
```java
Amplify.addPlugin(new AWSCognitoAuthPlugin());
Amplify.addPlugin(new AWSCloudWatchLoggingPlugin());
Amplify.configure(AmplifyOutputs.fromResource(R.raw.amplify_outputs), getApplicationContext());
```
### With Code
You can also add the plugin to your code without creating a configuration file:
```java
Amplify.addPlugin(new AWSCognitoAuthPlugin());
AWSCloudWatchLoggingPluginConfiguration config = new AWSCloudWatchLoggingPluginConfiguration (<log-group-name>,<region>,1,60);
Amplify.addPlugin(new AWSCloudWatchLoggingPlugin(config));
Amplify.configure(AmplifyOutputs.fromResource(R.raw.amplify_outputs), getApplicationContext());
```
Note: Replace `<log-group-name>` and `<region>` with your actual log group name and region.

For React, you would use the following code to initialize Amplify logging:
```javascript
import Amplify from 'aws-amplify';
import AWSCognitoAuthPlugin from '@aws-amplify/auth';
import AWSCloudWatchLoggingPlugin from '@aws-amplify/logging';

Amplify.addPlugin(new AWSCognitoAuthPlugin());
const loggingConfig = {
  logGroupName: '<log-group-name>',
  region: '<region>',
  localStoreMaxSizeInMB: 1,
  flushIntervalInSeconds: 60,
  loggingConstraints: {
    defaultLogLevel: 'ERROR'
  }
};
Amplify.addPlugin(new AWSCloudWatchLoggingPlugin(loggingConfig));
Amplify.configure({
  Auth: {
    // your auth configuration
  },
  Logging: {
    logGroupName: '<log-group-name>',
    region: '<region>',
  }
});
```

To view logs in Amazon CloudWatch, you need to access the log group that you created and specified during the initial setup. Each user's log messages are stored in a user-specific log stream within the log group. The log stream names are generated based on the user's device identifier and user identifier.

For authenticated users, the log stream name is a combination of the device identifier and user identifier, separated by a period. For unauthenticated users, the log stream name is a combination of the device identifier and the string "guest".

You can use the Amplify Auth category to retrieve the user identifier for a specific user if needed. Alternatively, you can retrieve the user identifier by visiting the Amazon Cognito console and inspecting the User ID in User pools.

To access your logs in the AWS Console, follow these steps:
1. Log into the AWS Console.
2. Navigate to Amazon CloudWatch.
3. In the left navigation panel, click on Logs and then click on Log groups.
4. Enter your log group name in the Filter field.
5. Click on your log group in the filtered results to view all log streams. 

In a React application using AWS Amplify, you would use the `Auth` category from `@aws-amplify/auth` to retrieve the user identifier. For example:
```javascript
import { Auth } from '@aws-amplify/auth';

Auth.currentAuthenticatedUser().then((user) => {
  const userId = user.username;
  // Use the user ID to construct the log stream name
});
```

This page is for formatting only

Amazon Q Developer is a generative artificial intelligence (AI) powered conversational assistant that can help you understand, build, extend, and operate AWS applications. You can ask questions about AWS architecture, your AWS resources, best practices, documentation, support, and more. Amazon Q is constantly updating its capabilities so your questions get the most contextually relevant and actionable answers. 

When used in an integrated development environment (IDE), Amazon Q provides software development assistance. Amazon Q can chat about code, provide inline code completions, generate net new code, scan your code for security vulnerabilities, and make code upgrades and improvements, such as language updates, debugging, and optimizations.

To get started with Amazon Q Developer, you need to install it as an extension in Visual Studio Code or a plugin in JetBrains. You can also use it in the AWS Toolkit for Visual Studio. 

Here's how you can use Amazon Q Developer's inline code suggestions in your Amplify project:

1. Open `amplify/data/resource.ts` and comment out the default schema for Todo provided.
2. In a new line below the commented schema, enter a comment to generate the schema using natural language. For example, `generate a restaurant model with the following fields: id, name, description, address, image, rating, style. Rating can be a float value. Authorization should allow public.` Press `Enter` for a new line and wait for Amazon Q Developer to generate inline code suggestion for your schema.
3. Select the inline code suggestion generated by Amazon Q developer. The inline code suggestion feature assists you in defining the schema and hover over the output to select from other options.
4. Make any required changes to the schema and save the `amplify/data/resource.ts` file. This will trigger a sandbox deployment and your new data model will be deployed.

You can also use Amazon Q Developer's workspace feature in your Amplify project. This feature allows you to incorporate the most relevant parts of your workspace code as context, using an index that updates periodically. 

To use the workspace feature, you need to download some markdown files that provide detailed guides on how to use Amazon Q Developer in your Amplify project. These files include `general.md`, `authentication.md`, `modeling-relationships.md`, and `modeling-schema.md`. 

Here's how you can use the workspace feature:

1. Create a folder in the root of your project and give a descriptive name such as `context`. Add the downloaded markdown files to this folder.
2. Open Amazon Q Developer Chat in your IDE and type `@workspace` to enable workspace indexing. Follow Amazon Q's prompts to set up indexing for your project directory.
3. After successful indexing, reference the markdown file content in your queries to Amazon Q. For example, you can type `@workspace follow AMPLIFYRULES to develop a data model schema for a freelance marketplace using Amplify Gen 2. Include models for freelancers, clients, projects, bids, and reviews. Use Amplify Gen 2 to fetch a list of projects` to get a data model schema for a freelance marketplace. 

You can also trigger the inline code suggestion feature manually by invoking Amazon Q Developer using the Option+C keyboard shortcut in VS Code.

When deploying an AWS Amplify Gen 2 app, you may encounter the error message "Cannot find module $amplify/env/<function-name>" in your frontend build on Amplify Console. This error occurs when your framework tsconfig.json configuration picks up the amplify directory and tries to resolve it as a module. This module is a placeholder for environment variables that are injected at build time by Amplify. To resolve this error, you need to exclude the amplify directory.

To exclude the amplify directory in your tsconfig.json, add the following lines to the exclude section:
```ts
{
  "exclude": ["amplify/**/*"]
}
```
Amplify will perform type-checking on sandbox and pipeline-deploy using the tsconfig local to the Amplify backend amplify/tsconfig.json. If you'd like to extend your base configuration you can add it to the localized tsconfig.

Alternatively, if you work within a monorepo you can move your backend to its own package and export the Schema and outputs for ease of sharing with your other apps. For example, in your backend package's package.json:
```json
{
  "name": "my-backend",
  "private": true,
  "exports": {
    "./schema": "./amplify/data/resource.ts",
    "./outputs": "./amplify_outputs.json"
  }
}
```
However, if you are using Vue, you will need to include the resource.ts files in your tsconfig.app.json file instead. For example, if you have a function resource dependent on the data resource, you will need to include both the resource.ts files in your tsconfig.app.json file:
```ts
{
  "include": [
    "amplify/data/resource.ts",
    "amplify/function/api-function/resource.ts",
  ]
}
```

To deploy resources into your AWS account using AWS Amplify, you need to prepare your AWS environment by bootstrapping it. This process involves setting up your AWS account and region to work with the AWS Cloud Development Kit (AWS CDK), which is used by Amplify to scaffold backend resource configurations and deployments.

Bootstrapping is a necessary step before deploying a CDK stack into your AWS environment. You can learn more about bootstrapping by visiting the AWS documentation.

When deploying an Amplify app, you may encounter an error message indicating that there is an issue with the CDKToolkit stack. This typically means that one or more resources within the stack has failed to create or update. To resolve this issue, you can navigate to the AWS CloudFormation console, select your CDKToolkit stack, and view the resource events to identify any problems.

You can fix the issue by manually updating your CDKToolkit stack using the AWS CloudShell or by running the bootstrap command using the AWS CDK CLI from your terminal. The command to update the stack is 
```bash
npx aws-cdk@latest bootstrap aws://<your-aws-account-id>/<your-aws-region>
```
If you continue to experience issues after applying this workaround, you should file an issue in the GitHub repository for Amplify Backend.

Another common error is the "Stack CDKToolkit already exists" error, which occurs when you are deploying an Amplify app for the first time and have previously bootstrapped your AWS account to work with CDK. To resolve this issue, you can also manually update your CDKToolkit stack using the AWS CloudShell or by running the bootstrap command using the AWS CDK CLI from your terminal. The command to update the stack is 
```bash
npx aws-cdk@latest bootstrap aws://<your-aws-account-id>/<your-aws-region>
```
If you continue to experience issues after applying this workaround, you should file an issue in the GitHub repository for Amplify Backend.

When deploying an Amplify Gen 2 app, you may encounter the error message "The CloudFormation deployment failed due to circular dependency" in your backend build on Amplify Console or while running a sandbox. This error occurs due to circular dependencies between CloudFormation nested stacks or between resources in a single CloudFormation stack.

If you see an error message indicating a circular dependency between nested stacks, it means that two or more nested stacks are dependent on each other. For example, if you're using a function as a query handler, but the function also needs access to the data API, you might run into this issue. To resolve this, group the function with other resources in the same stack. 

For instance, in React, if you have a query function, you can group it with other resources in the data stack by defining the function like this:
```javascript
export const queryFunction = {
  name: 'query-function',
  resourceGroupName: 'data',
};
```
Similarly, if you're using your function as an auth trigger, you can group your function with other resources in the auth stack to break the circular dependency.
```javascript
export const preSignUpTrigger = {
  name: 'pre-sign-up',
  resourceGroupName: 'auth',
};
```
If you're unable to resolve the error using the function's resourceGroupName property, you should create an issue on the GitHub repository for Amplify backend.

If you're creating resources using the AWS Cloud Development Kit (AWS CDK) and assigning them to a custom stack, you might also encounter a circular dependency error. To resolve this, try creating your resources in the same stack as the resources you're trying to interact with. For example, if a custom resource such as sqs needs to interact with the underlying Amazon S3 resource created by defineStorage, you can create that sqs resource in the stack created by Amplify.
```javascript
const queue = new sqs.Queue(backend.storage.stack, 'MyCustomQueue');
```
If you see an error message indicating a circular dependency between resources in the same stack, review the AWS Blog post for handling circular dependency errors for guidance on resolving the issue.

If you're experiencing missing configuration or `NoCredentials` error messages in your React application, even after calling `Amplify.configure`, it's likely that your Amplify API is being called before `Amplify.configure`. This can happen in several ways, and here are three possible checks to troubleshoot the issue.

First, ensure that `Amplify.configure` is called in the root file of your project. The root file varies depending on your frontend framework. For React, it's usually `src/main.tsx`. Make sure you're calling `Amplify.configure` in this file.

If you're using Next.js App Router, follow the suggestions in the Next.js documentation for root-level configuration. Be aware that if you're calling any APIs at the module-level (i.e., at the top of your file) in any child components, you may still run into this issue.

Second, move any module-level Amplify API invocations. When Amplify APIs are used outside of your application lifecycle, there's a risk that the JavaScript bundler may place that API call before `Amplify.configure`. This can happen when you have code like this:

```tsx
import { Amplify } from 'aws-amplify';
import ComponentX from 'module-fetch-auth';

Amplify.configure();

export default function App() {
  return (
    <div>
        <ComponentX />
    </div>
  );
}
```

```tsx
import { fetchAuthSession } from 'aws-amplify/auth';

fetchAuthSession(); // Will throw "AuthUserPoolException: Auth UserPool not configured."

export default function ComponentX() {
  return (
    <div className="box">
     ...
    </div>
  );
}
```

To fix this, move the Amplify API calls to within the application lifecycle. For instance, you can use the `useEffect` hook in React:

```tsx
import { Amplify } from 'aws-amplify';
import ComponentX from 'module-fetch-auth';

Amplify.configure();

export default function App() {
  return (
    <div>
        <ComponentX />
    </div>
  );
}
```

```tsx
import { type AuthSession, fetchAuthSession } from 'aws-amplify/auth';
import { useEffect, useState } from 'react';

export default function ComponentX() {
  const [session, setSession] = useState<AuthSession|undefined>();

  const getSession = async () => {
    try {
      const currentSession = await fetchAuthSession();
      setSession(currentSession);
    } catch (error: unknown) {
      console.log(error);
    }
  };

  useEffect(() => {
    getSession();
  }, []);

  return (
    <div className="box">
     ...
    </div>
  );
}
```

Lastly, if you're working in a multi-page app, you need to call `Amplify.configure()` for each page/route of your application. You can do this by calling `Amplify.configure` in a common source file and importing it into each page. This ensures that Amplify is properly configured for each page in your application.

The AWS Mobile Client and Amplify Android v2 are not compatible with each other. Amplify v2 migrates the credentials from AWS Mobile Client into a different format, leaving AWS Mobile Client unable to read the credentials. If AWS Mobile Client is launched after this migration has taken place, the Amplify v2 credentials will also be cleared.

To use Amplify v2 with the AWS Android SDK, you need to create an AmplifyCredentialsProvider that provides credentials to the AWS Android SDK plugins. This provider uses Amplify Android v2 to provide credentials.

Here is an example of how to create an AmplifyCredentialsProvider in React Native using JavaScript:
```
class AmplifyCredentialsProvider {
  async getCredentials() {
    try {
      const authSession = await Amplify.Auth.fetchAuthSession();
      const awsCredentials = authSession.getAwsCredentials();
      if (awsCredentials) {
        return {
          accessKeyId: awsCredentials.accessKeyId,
          secretAccessKey: awsCredentials.secretAccessKey,
          sessionToken: awsCredentials.sessionToken,
        };
      } else {
        throw new Error('Failed to get credentials');
      }
    } catch (error) {
      throw new Error('Failed to get credentials');
    }
  }

  async refresh() {
    try {
      await Amplify.Auth.fetchAuthSession({ forceRefresh: true });
    } catch (error) {
      throw new Error('Failed to refresh credentials');
    }
  }
}
```
You can then use this provider with AWS Android SDK plugins that accept an AWSCredentialsProvider.

For example, to use the S3 Storage plugin, you can create a TransferUtility instance like this:
```
const amplifyCredentialsProvider = new AmplifyCredentialsProvider();
const transferUtility = new TransferUtility({
  context: this,
  awsConfiguration: new AWSConfiguration(this),
  s3Client: new AmazonS3Client(amplifyCredentialsProvider, 'us-east-1'),
});
```
Similarly, you can use the IoT plugin like this:
```
const amplifyCredentialsProvider = new AmplifyCredentialsProvider();
const iotClient = new AWSIotClient(amplifyCredentialsProvider);
```
And the Android SDK generated by API Gateway like this:
```
const amplifyCredentialsProvider = new AmplifyCredentialsProvider();
const clientFactory = new ApiClientFactory();
clientFactory.credentialsProvider(amplifyCredentialsProvider);
```
Note that you need to ensure that the resources are in sync between the `amplify_outputs.json` file used by Amplify v2 and the `awsconfiguration.json` file used by the AWS Android SDK. Any manual customizations should be applied to both files.

To identify entities from images using Amplify, you need to use the `Predictions.identify` function. This function detects entities from an image and potentially related information such as position, faces, and landmarks. It can also identify celebrities and entities that were previously added.

Before you start, make sure to complete the getting started section where you set up the IAM roles with the right policy actions.

The `Predictions.identify` function returns a Promise that resolves to an object with the entities that were identified. The input can be sent directly from the browser using a File object or an ArrayBuffer object, or an Amazon S3 key from a project bucket.

Here are some examples of how to use the `Predictions.identify` function:

Detect entities directly from an image uploaded from the browser:
```javascript
const response = await Predictions.identify({
  entities: {
    source: {
      file,
    },
  }
});
```

Detect entities directly from an image binary from the browser:
```javascript
const response = await Predictions.identify({
  entities: {
    source: {
      bytes: imageArrayBuffer,
    },
  }
});
```

Detect entities from an Amazon S3 key:
```javascript
const response = await Predictions.identify({
  entities: {
    source: {
      key: pathToPhoto,
      level: 'guest' | 'private' | 'protected', 
    },
  }
});
```

You can also detect the bounding box of faces from an image with its landmarks:
```javascript
const { entities } = await Predictions.identify({
  entities: {
    source: {
      file,
    },
  }
})
for (const { boundingBox, landmarks } of entities) {
  const { 
    width, 
    height, 
    left, 
    top 
  } = boundingBox;
  
  for (const landmark of landmarks) {
    const {
      type, 
      x, 
      y 
    } = landmark;
  }
}
```

To detect celebrities on an image, you can use the `celebrityDetection` option:
```javascript
const { entities } = await Predictions.identify({
  entities: {
    source: {
      file,
    },
    celebrityDetection: true 
  }
})

for (const { boundingBox, landmarks, metadata } of entities) {
  const { 
    name,
    urls 
  } = metadata; 
  
  //...
}
```

You can also detect entities from previously uploaded images:
```javascript
const { entities } = await Predictions.identify({
  entities: {
    source: {
      file,
    },
    collection: true
  }
})

for (const { boundingBox, metadata } of entities) {
  const {
    width, 
    height, 
    left, 
    top 
  } = boundingBox;
  const { externalImageId } = metadata; 
}
```

To identify text from images and documents in your application using AWS Amplify, you first need to complete the getting started section where you set up the IAM roles with the right policy actions.

You can detect text in an input image by sending the input directly from the browser or an Amazon S3 key from your project bucket. To do this, you can use the Predictions.identify function from the @aws-amplify/predictions library.

```javascript
const response = await Predictions.identify({
  text: {
    source: {
      file
    }
  }
});
```

You can also identify an image stored in Amazon S3 by providing the key of the image instead of the file.

```javascript
const response = await Predictions.identify({
  text: {
    source: {
      key: pathToPhoto,
    }
  }
})
```

When using the Predictions.identify function, you can specify the format of the text asPLAIN, TABLE, FORM, or ALL. For example, to detect plain text, you can use the following code:

```javascript
const response = await Predictions.identify({
  text: {
    source: {
      file
    },
    format: 'PLAIN'
  }
});

const {
  text: {
    fullText, 
    lines, 
    linesDetailed,
    words
  }
} = response;
```

This will return the full text, lines, lines with detailed information, and words detected in the image.

To detect structured forms, you can use the following code:

```javascript
const response = await Predictions.identify({
  text: {
    source: {
      file
    },
    format: 'FORM'
  }
});

const {
  text: {
    keyValues
  }
} = response;
```

This will return an array of key-value pairs detected in the image, along with metadata such as the location of the key-value pairs.

To detect structured tables, you can use the following code:

```javascript
const response = await Predictions.identify({
  text: {
    source: {
      file
    },
    format: 'TABLE'
  }
});

const {
  text: {
    tables
  }
} = response;
```

This will return an array of tables detected in the image, along with metadata such as the size of the table and the text detected in each cell.

To detect both tables and forms, you can use the following code:

```javascript
const { text } = await Predictions.identify({
  text: {
    source: {
      file
    },
    format: 'ALL'
  }
});
```

This will return all the detected text, including plain text, tables, and forms.

Amplify provides a solution for using AI and ML cloud services to enhance your application. Some supported use cases include:

- converting text to speech
- transcribing audio to text
- translating text from one language to another
- identifying text from an image
- identifying entities from an image
- identifying real world objects from an image
- interpreting text

Predictions is broadly organized into 3 key use cases - Identify, Convert, and Interpret. 

- Identify will find text, entities, or real world objects from images.
- Convert allows you to translate text, generate speech audio from text input, or transcribe an audio input.
- Interpret allows you to analyze text for language, entities, key phrases, sentiment, and syntax.

Some common use cases are listed below. Predictions comes with built-in support for Amazon Translate, Amazon Polly, Amazon Transcribe, Amazon Rekognition, Amazon Textract, and Amazon Comprehend.

To interpret sentiment, you need to determine key phrases, sentiment, language, syntax, and entities from text using Amplify. Before you start, make sure to complete the getting started section, where you will set up the IAM roles with the right policy actions.

You can analyze text to find key phrases, sentiment (positive, negative, neutral), or the syntax (pronouns, verbs, etc.). You can also find entities in the text such as names or places, or perform language detection.

To do this, you can use the `Predictions` class from `@aws-amplify/predictions`. Here is an example of how to use it in a React application:
```javascript
import { Predictions } from '@aws-amplify/predictions';

const textToInterpret = 'Your text to interpret';
const result = await Predictions.interpret({
  text: {
    source: {
      text: textToInterpret,
    },
    type: 'ALL'
  }
})
```
This code will return an object with the interpretation results, including key phrases, sentiment, syntax, entities, and language detection.

To label objects in an image, you first need to complete the getting started section where you set up the IAM roles with the right policy actions. 

When working with the API, you can detect labels such as identifying objects like desks or chairs in an image. This can be achieved by using the Predictions.identify method, which takes an object with a source and type property. The source property contains the image file, and the type property is set to 'LABELS' to detect labels. 

Here is an example of how to use it in a React application:
```
import { Predictions } from '@aws-amplify/predictions';

Predictions.identify({
  labels: {
    source: {
      file: yourImageFile
    },
    type: 'LABELS'
  }
})
 .then((response) => {
    const { labels } = response;
    labels.forEach((object) => {
      const { name, boundingBoxes } = object;
      // do something with the label and bounding box
    });
  })
 .catch((err) => console.log({ err }));
```

You can also detect unsafe content in an image by setting the type property to 'UNSAFE'. 

Here is an example of how to use it in a React application:
```
import { Predictions } from '@aws-amplify/predictions';

const { unsafe } = await Predictions.identify({
  labels: {
    source: {
      file: yourImageFile
    },
    type: 'UNSAFE'
  }
})
// do something with the unsafe content
```

To detect both labels and unsafe content, you can set the type property to 'ALL'. 

Here is an example of how to use it in a React application:
```
import { Predictions } from '@aws-amplify/predictions';

const { labels, unsafe } = await Predictions.identify({
  labels: {
    source: {
      file: yourImageFile
    },
    type: 'ALL'
  }
})
// do something with the labels and unsafe content
```

To enable Predictions in your application, you need to set up the appropriate IAM policy for Roles in your Cognito Identity Pool. This policy should include the necessary actions and resources to use the desired machine learning capabilities.

The IAM policy should be configured to enable all supported ML capabilities, but you should only include the actions and resources relevant to your specific use cases. You can learn more about the available ML capabilities in the documentation for Amazon Translate, Amazon Polly, Amazon Transcribe, Amazon Rekognition, Amazon Textract, and Amazon Comprehend.

To configure the policy, you can use the following example as a starting point:
```javascript
const policy = new PolicyStatement({
  actions: [
    "translate:TranslateText",
    "polly:SynthesizeSpeech",
    "transcribe:StartStreamTranscriptionWebSocket",
    "comprehend:DetectSentiment",
    "comprehend:DetectEntities",
    "comprehend:DetectDominantLanguage",
    "comprehend:DetectSyntax",
    "comprehend:DetectKeyPhrases",
    "rekognition:DetectFaces",
    "rekognition:RecognizeCelebrities",
    "rekognition:DetectLabels",
    "rekognition:DetectModerationLabels",
    "rekognition:DetectText",
    "rekognition:DetectLabel",
    "rekognition:SearchFacesByImage",
    "textract:AnalyzeDocument",
    "textract:DetectDocumentText",
    "textract:GetDocumentAnalysis",
    "textract:StartDocumentAnalysis",
    "textract:StartDocumentTextDetection",
  ],
  resources: ["*"],
});
```
You will also need to add the `addOutput` method to patch the custom Predictions resource to the expected output configuration. This configuration should include the settings for the convert, identify, and interpret features.

To use the Predictions features in your application, you need to install the Amplify library. You can do this by running the following command in your project's root folder:
```
npm add aws-amplify @aws-amplify/predictions
```
After installing the library, you need to configure the frontend by importing and loading the configuration file in your app. You can do this by adding the following code to your app's root entry point:
```javascript
import Amplify from "aws-amplify";
import outputs from "./amplify_outputs.json";

Amplify.configure(outputs);

Amplify.configure({
 ...Amplify.getConfig(),
  Predictions: outputs.custom.Predictions,
});
```
Note that you should replace `./amplify_outputs.json` with the actual path to your configuration file.

To integrate text-to-speech capabilities into your React application using AWS Amplify, start by setting up the necessary IAM roles with the right policy actions as described in the getting started section. 

Once set up, you can use the Predictions API to generate an audio buffer for playback from a text input. You do this by calling the convert method on the Predictions object, passing in an object with the textToSpeech property. This property should contain a source object with the text you want to generate speech from, and a voiceId which specifies the voice to use. 

For example, you can use the following code to generate speech from a text input:
```javascript
import { Predictions } from '@aws-amplify/predictions';

const textToGenerateSpeech = 'Hello, world!';
const result = await Predictions.convert({
  textToSpeech: {
    source: {
      text: textToGenerateSpeech
    },
    voiceId: "Amy" 
  }
})
```
The voiceId should be one of the voices supported by Amazon Polly, such as "Amy". You can find the complete list of voiceId options in the Amazon Polly documentation.

To transcribe audio to text, also known as speech-to-text, in your React application using AWS Amplify, you need to have completed the getting started section first, where you set up the IAM roles with the right policy actions.

You can use the Predictions API to transcribe a PCM audio byte buffer to text, such as a recording from a microphone. 
```javascript
const { Predictions } = require('@aws-amplify/predictions');
const transcription = await Predictions.convert({
  transcription: {
    source: {
      bytes: // your audio byte buffer
    }
  }
})
```
The language data input type must support streaming for it to work with Amplify Predictions. For a complete list of supported languages and language-specific features, refer to the AWS Transcribe documentation.

To integrate translation capabilities into your application using AWS Amplify, you need to start by setting up the necessary IAM roles with the right policy actions, as described in the getting started section. 

Once you have completed the setup, you can use the Amplify Predictions API to translate text from one language to another. This is done by calling the convert method on the Predictions object, passing in an object with the text to translate, its source language, and the target language. 

For example, to translate text from Spanish to English in a React application, you can use the following code:
```javascript
import { Predictions } from '@aws-amplify/predictions';

const textToTranslate = 'Hola, ¿cómo estás?';
const result = await Predictions.convert({
  translateText: {
    source: {
      text: textToTranslate,
      language: 'es'
    },
    targetLanguage: 'en'
  }
})
```
The result will contain the translated text. You can find the complete list of supported languages and their corresponding language codes in the AWS documentation. 

This page is describing how to set up language translation in your react application. Make sure you complete the setup steps before attempting to use this api.

In Amplify Gen 2, the CLI generates an `amplify_outputs.json` file that contains your backend's outputs, such as your Data endpoint and Auth metadata. This file is used to configure client libraries to interact with your backend resources. It's created locally when using `ampx sandbox` and automatically in Amplify's CI/CD based on the Amplify app ID and git branch. You can also create it manually using `ampx generate outputs`.

The `amplify_outputs.json` file is designed to be extendable to suit your application's evolving needs. You can use the `addOutput` method from your `backend` to programmatically add configurations, which is useful for customizing outputs not directly exposed through Amplify constructs or for dynamically adjusting your app's configuration.

However, overriding Amplify-managed configurations on `amplify_outputs.json` is not supported.

You can add custom outputs or extend existing configurations without manual file edits. For example, you can add output parameters that specify an S3 bucket and its region for storing files. In your backend, you can use the `addOutput` method to add the configuration:
```javascript
const backend = defineBackend({
  auth, 
  data, 
});

backend.addOutput({
  storage: {
    aws_region: "us-east-1",
    bucket_name: "my-externally-managed-bucket",
  },
});
```
In your React application, you can configure Amplify using the `amplify_outputs.json` file:
```javascript
import Amplify from "aws-amplify";
import outputs from "@/amplify_outputs.json";

Amplify.configure(outputs);
```
You can also add custom output parameters to your `amplify_outputs.json` file. This is useful for surfacing arbitrary outputs, values from custom CDK resources, or any other information necessary for your application's logic or configuration. For example:
```javascript
const backend = defineBackend({
  auth, 
  data, 
});

backend.addOutput({
  custom: {
    api_id: "restAPIId",
    api_endpoint: "https://api.example.com",
    api_name: "restApiName",
  },
});
```
In your React application, you can access these custom configurations as follows:
```javascript
import Amplify from "aws-amplify";
import outputs from "@/amplify_outputs.json";

Amplify.configure(outputs);
const currentConfig = Amplify.getConfig(); 
Amplify.configure({
 ...currentConfig,
  API: {
    REST: {
      [outputs.custom.api_name]: {
        endpoint: outputs.custom.api_endpoint,
        region: "us-east-1",
      },
    },
  },
});
```
The Amplify outputs file is defined using a JSON schema, which can be found in the `aws-amplify/amplify-backend` repository. The schema defines the structure of the `amplify_outputs.json` file, including the available properties and their data types.

Constructs are the basic building blocks of AWS Cloud Development Kit (AWS CDK) apps. They simplify the process of configuring cloud resources, allowing you to focus on your application code. The available Amplify backend constructs are summarized below.

Amplify Data is a construct that provides a simplified way to work with the Amplify GraphQL API. It enables quick development and iteration of AppSync APIs that support the Amplify GraphQL directives. You can find more information about the AmplifyData construct on Construct Hub. For data modeling information, you can visit the data modeling documentation.

Amplify Auth is another construct that simplifies authentication in your AWS CDK apps. You can find the official AmplifyAuth construct on the npm registry. 

In a React application using AWS Amplify, you would use these constructs to configure your backend resources, such as setting up authentication and data storage. For example, you might use the `AmplifyData` construct to create a GraphQL API, and the `AmplifyAuth` construct to configure authentication for your app. 

Here is an example of how you might use these constructs in a React application:
```javascript
import { Amplify } from 'aws-amplify';
import { AmplifyData } from '@aws-amplify/data-construct';
import { AmplifyAuth } from '@aws-amplify/auth-construct';

// configure Amplify
Amplify.configure({
  // your AWS configuration
});

// create a GraphQL API using AmplifyData
const api = new AmplifyData({
  // your API configuration
});

// configure authentication using AmplifyAuth
const auth = new AmplifyAuth({
  // your authentication configuration
});
```

This page is a reference for commands found in the @aws-amplify/backend-cli package. All commands can be prefixed with AWS CLI environment variables to change the AWS account behavior with Amplify Gen 2 commands.

### npx ampx sandbox

The `npx ampx sandbox` command enables you to develop your backend alongside your frontend's development server. It deploys to your personal cloud sandbox and automatically watches for changes in the amplify/ folder, redeploying each time you save a file.

Options:
- `--dir-to-watch` (string) - Directory to watch for file changes. Defaults to the amplify directory.
- `--exclude` (string[]) - An array of paths or glob patterns to ignore.
- `--identifier` (string) - An optional name to distinguish between different sandbox environments. Default is the name of the system user executing the process.
- `--outputs-out-dir` (string) - A path to a directory where the client config file is written. If not provided, defaults to the working directory of the current process.
- `--outputs-format` (string) - Format in which the client config file is written (choices: json, dart).
- `--outputs-version` (string) - Version of the configuration. Version 0 represents classic amplify-cli config file amplify-configuration and 1 represents newer config file amplify_outputs (choices: 0, 1).
- `--profile` (string) - An AWS profile name.
- `--stream-function-logs` (boolean) - Whether to stream function execution logs. (default: false)
- `--logs-filter` (string[]) - Regex pattern to filter logs from only matched functions.
- `--logs-out-file` (string) - File to append the streaming logs.

Usage:
```bash
npx ampx sandbox
```

You can use the `--profile` flag to run sandbox with an AWS profile other than default:
```bash
npx ampx sandbox --profile my-other-profile
```
Alternatively, you can use AWS CLI environment variables to specify a different profile:
```bash
AWS_PROFILE=my-other-profile ampx sandbox
```

You can also use AWS environment variables to deploy to a Region other than your AWS profile's configured Region:
```bash
AWS_REGION=us-west-2 ampx sandbox
```

For mobile applications, you need to set the output directory and format of the generated configuration file:
```bash
# for Android
npx ampx sandbox --outputs-out-dir app/src/main/res
# for Swift/iOS
npx ampx sandbox
# for Flutter
npx ampx sandbox --outputs-format dart --outputs-out-dir lib
```

### npx ampx sandbox delete

The `npx ampx sandbox delete` command deletes your personal cloud sandbox. This should only be used if you have an active cloud sandbox that you opted to not delete when exiting `npx ampx sandbox`.

Options:
- `--name` (string) - An optional name to distinguish between different sandbox environments. Default is the name in your package.json.
- `--profile` (string) - An AWS profile name.
- `-y, --yes` (boolean) - Do not ask for confirmation before deleting the sandbox environment.

Usage:
```bash
npx ampx sandbox delete
```

### npx ampx sandbox secret

The `npx ampx sandbox secret` command manages backend secrets used with your personal cloud sandbox.

Options:
- `--profile` (string) - An AWS profile name.

Usage:
```bash
npx ampx sandbox secret
```

You can use the `--profile` flag to run sandbox with an AWS profile other than default:
```bash
npx ampx sandbox secret list --profile my-other-profile
```
Alternatively, you can use AWS environment variables to specify a different profile:
```bash
AWS_PROFILE=my-other-profile ampx sandbox secret list
```

To create a secret, use `sandbox secret set`:
```bash
npx ampx sandbox secret set LOGINWITHAMAZON_CLIENT_ID
```

To remove a secret, use `sandbox secret remove`:
```bash
npx ampx sandbox secret remove LOGINWITHAMAZON_CLIENT_ID
```

To list all available secrets, use:
```bash
npx ampx sandbox secret list
```

To get a secret and view its details, use:
```bash
npx ampx sandbox secret get LOGINWITHAMAZON_CLIENT_ID
```

### npx ampx generate

The `npx ampx generate` command is used to generate information or code that is supplemental to your frontend development.

Each subcommand requires either a CloudFormation stack name or an existing Amplify App ID and corresponding git branch:
```bash
# with CloudFormation stack name
npx ampx generate <subcommand> --stack <cloudformation-stack-name>
# with Amplify App ID and git branch
npx ampx generate <subcommand> --app-id <app-id> --branch <git-branch-name>
```

### npx ampx generate outputs

The `npx ampx generate outputs` command generates the backend outputs file (e.g. `amplify_outputs.json`) for your frontend application to consume.

Options:
- `--profile` (string) - An AWS profile name.
- `--format` (string) - The format into which the configuration should be exported (choices: json, dart).
- `--out-dir` (string) - A path to the directory where config is written. If not provided, it defaults to the working directory of the current process.
- `--outputs-version` (string) - Version of the configuration. Version 0 represents classic amplify-cli config file amplify-configuration and 1 represents newer config file amplify_outputs (choices: 0, 1).

Usage:
```bash
npx ampx generate outputs --stack amplify-nextamplifygen2-josef-sandbox-ca85e1081b
```

For mobile applications, you can specify an alternate outputs file format:
```bash
npx ampx generate outputs --stack amplify-nextamplifygen2-josef-sandbox-ca85e1081b
```

### npx ampx generate graphql-client-code

The `npx ampx generate graphql-client-code` command generates GraphQL statements and types for your frontend application to consume.

Options:
- `--stack` (string) - A stack name that contains an Amplify backend.
- `--app-id` (string) - The Amplify App ID of the project.
- `--branch` (string) - A git branch of the Amplify project.
- `--out` (string) - Specifies the path to the directory where the config is written. If not provided, defaults to the current process working directory.
- `--format` (string) - Specifies the format of the GraphQL client code to be generated.
- `--model-target` (string) - Specifies the modelgen export target.
- `--statement-target` (string) - Specifies the graphql-codegen statement export target.
- `--statement-max-depth` (integer) - Specifies the maximum depth of the generated GraphQL statements.
- `--type-target` (string) - Specifies the optional graphql-codegen type export target.
- `--all` (boolean) - Shows hidden options.
- `--profile` (string) - Specifies an AWS profile name.
- `--debug` (boolean) - Print debug logs to the console.
- `--help` (boolean) - Displays help information about the command.

Usage:
```bash
npx ampx generate graphql-client-code --app-id <your-amplify-app-id> --branch staging
```

You can generate GraphQL client code for a branch that is connected to Amplify:
```bash
npx ampx generate graphql-client-code --branch staging
```

You can also generate codegen for a CDK app using a joint "AmplifyBackendStack" construct:
```bash
npx ampx generate graphql-client-code --stack Backend --platform ts --out./src
```

You can generate codegen in a specific language and format:
```bash
npx ampx generate graphql-client-code --format modelgen --type-target angular
```

### npx ampx generate forms

The `npx ampx generate forms` command generates React form components derived from your backend data models for your frontend application to consume.

Options:
- `--stack` (string) - A stack name that contains an Amplify backend.
- `--branch` (string) - Name of the git branch being deployed.
- `--app-id` (string) - The app id of the target Amplify app.
- `--out-dir` (string) - A path to directory where generated forms are written. Defaults to the./ui-components directory.
- `--models` (array) - Model name to generate.
- `--profile` (string) - An AWS profile name.

Usage:
```bash
npx ampx generate forms --branch $BRANCH_NAME --app-id $AWS_APP_ID --out-dir./src
```

### npx ampx info

The `npx ampx info` command generates information on system, binaries, npm packages, and environment variables for troubleshooting Amplify issues.

Usage:
```bash
npx ampx info
```

### npx ampx pipeline-deploy

The `npx ampx pipeline-deploy` command deploys the Amplify project in a CI/CD pipeline for a specified Amplify app and branch.

Options:
- `--branch` (string) - Name of the git branch being deployed.
- `--app-id` (string) - The app id of the target Amplify app.
- `--outputs-out-dir` (string) - A path to a directory where the client config file is written. If not provided, defaults to the working directory of the current process.
- `--outputs-version` (string) - Version of the configuration. Version 0 represents classic amplify-cli config file amplify-configuration and 1 represents newer config file amplify_outputs (choices: 0, 1).

Usage:
```bash
npx ampx pipeline-deploy --branch $BRANCH_NAME --app-id $AWS_APP_ID
```

Amplify Gen 2 backends are defined using TypeScript and allow you to group resources based on their functionality. For example, you can create a post confirmation trigger for Amazon Cognito that generates a user profile record in the same file as your authentication resource.

When you create a new Amplify project, the scaffolding for data and authentication resources is automatically set up. The project structure will have an `amplify` folder with subfolders for `auth` and `data`, as well as a `backend.ts` file and a `package.json` file.

As your project grows, your project structure may become more complex, with additional subfolders and files for custom messages, resolvers, jobs, and storage. Backend resources are defined in `resource` files using helpers like `defineAuth`.

For instance, you can define an authentication resource like this:
```typescript
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true
  }
});
```
Then, you can set up the backend by importing the authentication resource and defining the backend:
```typescript
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';

defineBackend({
  auth,
  data
});
```
You can also extend your backend using the AWS Cloud Development Kit (AWS CDK), which allows you to use any AWS service. To get started with the CDK, you can add it to your backend and create an Amazon S3 bucket that authenticated users have read and write access to:
```typescript
import * as s3 from 'aws-cdk-lib/aws-s3';
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';

const backend = defineBackend({
  auth,
  data
});

const bucketStack = backend.getStack('BucketStack');
const bucket = new s3.Bucket(bucketStack, 'Bucket', {
  blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL
});

const authRole = backend.auth.resources.authenticatedUserIamRole;
bucket.grantReadWrite(authRole);

const unauthRole = backend.auth.resources.unauthenticatedUserIamRole;
bucket.grantRead(unauthRole);
```
To learn more, you can explore the concepts of Amplify and how to add AWS services to your backend.

Amplify Gen 2 collects anonymous telemetry data about general usage of the Command Line Interface (CLI). This means that when you use the Amplify CLI, some data about how you use it is sent back to Amplify. However, participating in this telemetry program is optional, and you can choose to opt out if you prefer.

If you opt out, none of the Amplify apps you work with on that computer will send telemetry data. To opt out, you can run the command `npx ampx configure telemetry disable` from the root of your Amplify app. This will store your decision to opt out for your user, so you won't have to do it again for each app.

If you change your mind and want to opt back in, you can do so by running the command `npx ampx configure telemetry enable` from the root of your Amplify app. 

In some cases, you might only want to opt out of telemetry for a single session. To do this, you can define an environment variable `AMPLIFY_DISABLE_TELEMETRY` and set it to 1. This will disable telemetry for that one session, without changing your overall preference. 

Note that telemetry collection is not enabled or disabled based on the React code itself, but rather through the use of the Amplify CLI and the commands provided above.

When determining the authorization mode for your REST endpoint, you can customize it in a few ways.

By default, the API uses IAM authorization, which has two modes: unauthenticated and authenticated. When the user is not signed in, the unauthenticated role is used, but once the user signs in, the authenticated role is used instead.

You can also configure a public REST API by setting an API key in Amazon API Gateway. To do this, you would set the API key header in the API configuration, which will be applied to all requests. This can be done by configuring Amplify, for example:
```
Amplify.configure({
  API: {
    REST: {
      headers: async () => {
        return { 'X-Api-Key': 'your-api-key' };
      }
    }
  }
});
```
Another option is to use the access token from a configured Cognito User Pool to authenticate against the REST endpoint. You can retrieve the JWT token from the Auth category, like this:
```
import { Auth } from 'aws-amplify';
const session = await Auth.currentSession();
const token = session.getAccessToken().getJwtToken();
```
Then, you can set the Authorization header in the API category configuration, like this:
```
Amplify.configure({
  API: {
    REST: {
      headers: async () => {
        return { Authorization: token };
      }
    }
  }
});
```
For more information on configuring API Gateway with custom authorization, you can refer to the AWS documentation.

It's also worth noting that you can use either the ID Token or the Access Token for authentication. The ID Token contains claims about the user's identity, while the Access Token contains scopes and groups. You can retrieve the ID Token like this:
```
import { Auth } from 'aws-amplify';
const session = await Auth.currentSession();
const token = session.getIdToken().getJwtToken();
```
And you can retrieve the Access Token like this:
```
import { Auth } from 'aws-amplify';
const session = await Auth.currentSession();
const token = session.getAccessToken().getJwtToken();
```
If you want to use a custom authorization token, you can set it in the API category configuration, like this:
```
Amplify.configure({
  API: {
    REST: {
      headers: async () => {
        return { Authorization: 'your-custom-token' };
      }
    }
  }
});
```
Finally, you can also set the authorization headers per request, rather than globally. For example, you could set a custom header named `Authorization` for a specific REST request, like this:
```javascript
import { API } from 'aws-amplify';
async function updateItem() {
  await API.del('myRestApi', 'items/1', {
    headers: {
      Authorization: 'your-token'
    }
  });
}
```

To delete data using the Delete API in AWS Amplify, you can make a DELETE request to the API endpoint. 

In React, you can use the `del` function from `aws-amplify/api` to send a DELETE request. Here's an example:
```javascript
import { del } from 'aws-amplify/api';

async function deleteItem() {
  try {
    const restOperation = del({
      apiName: 'myRestApi',
      path: 'items/1'
    });
    await restOperation.response;
    console.log('DELETE call succeeded');
  } catch (e) {
    console.log('DELETE call failed: ', JSON.parse(e.response.body));
  }
}
```
This code sends a DELETE request to the `myRestApi` API at the `items/1` path. If the request is successful, it logs 'DELETE call succeeded' to the console. If the request fails, it logs the error response to the console.

To use existing AWS resources with the Amplify Libraries, you need to configure the libraries to reference the existing Amazon API Gateway resources. This can be done by calling `Amplify.configure()` with the API Gateway API name and options.

You will need to provide the full resource configuration and library options objects when calling `Amplify.configure()`. Here is an example of how to do this in a React application:

```javascript
import Amplify from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);

const existingConfig = Amplify.getConfig();

Amplify.configure({
 ...existingConfig,
  API: {
   ...existingConfig.API,
    endpoints: [
      {
        name: 'YourAPIName',
        endpoint: 'https://abcdefghij1234567890.execute-api.us-east-1.amazonaws.com/stageName',
        region: 'us-east-1' // Optional
      }
    ]
  }
});
```

In this example, replace `YourAPIName` with a friendly name for your API, and `https://abcdefghij1234567890.execute-api.us-east-1.amazonaws.com/stageName` with the HTTPS endpoint of your API. The `region` field is optional, and if not specified, the region will be inferred from the endpoint.

Note that before you can add an AWS resource to your application, you must have the Amplify libraries installed. If you need to install the Amplify libraries, you can find instructions on how to do so in the Amplify documentation.

To invoke an endpoint, you need to set an input object with the required apiName option and optional headers, queryParams, and body options. API status code responses greater than 299 are thrown as an ApiError instance. The error instance provides name and message properties parsed from the response.

For GET requests, you can use the get function from aws-amplify/api. Here is an example of how to use it in a React application:
```javascript
import { get } from 'aws-amplify/api';

async function getItem() {
  try {
    const restOperation = get({ 
      apiName: 'myRestApi',
      path: 'items' 
    });
    const response = await restOperation.response;
    console.log('GET call succeeded: ', response);
  } catch (error) {
    console.log('GET call failed: ', JSON.parse(error.response.body));
  }
}
```
You can consume the response payload by accessing the body property of the response object. Depending on the use case and the content type of the body, you can consume the payload as a string, blob, or JSON:
```javascript
const { body } = await restOperation.response;
// consume as a string:
const str = await body.text();
// OR consume as a blob:
const blob = await body.blob();
// OR consume as a JSON:
const json = await body.json();
```
Note that you cannot consume the response payload more than once.

If the REST API handler throws an ApiError error instance, you can access the HTTP response from the error instance. The error instance will provide a response property if the error is caused by an HTTP response with a non-2xx status code:
```javascript
import { ApiError, get } from 'aws-amplify/api';

try {
  const restOperation = get({ 
    apiName: 'myRestApi',
    path: 'items' 
  });
  await restOperation.response;
} catch (error) {
  if (error instanceof ApiError) {
    if (error.response) {
      const { 
        statusCode, 
        headers, 
        body 
      } = error.response;
      console.error(`Received ${statusCode} error response with payload: ${body}`);
    }
    // Handle API errors not caused by HTTP response.
  }
  // Handle other errors.
}
```

To send a POST request with a JSON body in a React application using AWS Amplify, you can use the post method from the aws-amplify/api module. This method allows you to specify the API name, path, and options such as the request body.

Here's an example of how to use the post method:
```javascript
import { post } from 'aws-amplify/api';

async function postItem() {
  try {
    const restOperation = post({
      apiName: 'myRestApi',
      path: 'items',
      options: {
        body: {
          message: 'Mow the lawn'
        }
      }
    });

    const { body } = await restOperation.response;
    const response = await body.json();

    console.log('POST call succeeded');
    console.log(response);
  } catch (error) {
    console.log('POST call failed: ', JSON.parse(error.response.body));
  }
}
```
This code sends a POST request to the 'items' path of the 'myRestApi' API with a JSON body containing the message 'Mow the lawn'. The response from the server is then logged to the console. If the request fails, the error message is also logged to the console.

To set up an Amplify HTTP API, you can use the AWS Cloud Development Kit (AWS CDK) to configure Amplify Functions as resolvers for routes of an HTTP API powered by Amazon API Gateway.

First, create a new directory and a resource file, `amplify/functions/api-function/resource.ts`. Define the function with `defineFunction`. Then, create the corresponding handler file, `amplify/functions/api-function/handler.ts`, with the following contents:

```typescript
import type { APIGatewayProxyHandlerV2 } from "aws-lambda";

export const handler: APIGatewayProxyHandlerV2 = async (event) => {
  console.log("event", event);
  return {
    statusCode: 200,
    headers: {
      "Access-Control-Allow-Origin": "*", 
      "Access-Control-Allow-Headers": "*", 
    },
    body: JSON.stringify("Hello from api-function!"),
  };
};
```

Next, using the AWS CDK, create an HTTP API in your backend file. Create a new API stack, IAM authorizer, User Pool authorizer, and HTTP Lambda integration. Create a new HTTP API with IAM as the default authorizer and add routes to the API with a IAM authorizer and different methods.

To install the Amplify library for a React application, use npm to install the Amplify JavaScript library:

```bash
npm add aws-amplify
```

To initialize the Amplify API category, configure Amplify with `Amplify.configure()`. Import and load the configuration file in your app. Add the Amplify configuration step to your app's root entry point. For example:

```typescript
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
const existingConfig = Amplify.getConfig();
Amplify.configure({
 ...existingConfig,
  API: {
   ...existingConfig.API,
    REST: outputs.custom.API,
  },
});
```

Make sure to call `Amplify.configure` as early as possible in your application’s life-cycle to avoid a missing configuration or `NoCredentials` error.

To set up an Amplify REST API, you can use the AWS Cloud Development Kit (AWS CDK) to configure Amplify Functions as resolvers for routes of a REST API powered by Amazon API Gateway. 

To set up a REST API with a Lambda function, create a new directory and a resource file, then define the function with the defineFunction method. Create a corresponding handler file with the APIGatewayProxyHandler. 

Use the AWS CDK to create a REST API resource powered by Amazon API Gateway. Define the backend, create a new API stack, and a new REST API. Create a new Lambda integration and a new resource path with IAM authorization. Add methods to the resource path and create a new Cognito User Pools authorizer. Create a new resource path with Cognito authorization and add a new IAM policy to allow Invoke access to the API. Attach the policy to the authenticated and unauthenticated IAM roles.

To install Amplify libraries, use the package manager of your choice to install the Amplify JavaScript library. For example, with npm: 
```bash
npm add aws-amplify
```

To initialize the Amplify API, configure Amplify with Amplify.configure(). Import and load the configuration file in your app, and add the Amplify configuration step to your app's root entry point. For example, in React: 
```javascript
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
const existingConfig = Amplify.getConfig();
Amplify.configure({
 ...existingConfig,
  API: {
   ...existingConfig.API,
    REST: outputs.custom.API,
  },
});
``` 

Make sure to call Amplify.configure as early as possible in your application’s life-cycle to avoid missing configuration or NoCredentials errors. 

Here's an example of calling Amplify.configure in a React app: 
```javascript
import React from 'react';
import ReactDOM from 'react-dom';
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';
import App from './App';

Amplify.configure(outputs);
const existingConfig = Amplify.getConfig();
Amplify.configure({
 ...existingConfig,
  API: {
   ...existingConfig.API,
    REST: outputs.custom.API,
  },
});

ReactDOM.render(
  <React.StrictMode>
    <App />
  </React.StrictMode>,
  document.getElementById('root')
);
```

To test your REST API, you can use the terminal with the curl command-line tool. If you don't have curl installed, you can follow the installation instructions on the official curl documentation website.

To test your API using curl, replace `<your-api-endpoint>` and `<your-api-stage>` with your actual API endpoint and stage. 

For a GET request, use the following command:
```
curl <your-api-endpoint>/<your-api-stage>/items
```
For a POST request, use the following command:
```
curl -H "Content-Type: application/json" -d '{"name":"item-1"}' <your-api-endpoint>/<your-api-stage>/items
```
If you're using Windows, make sure to use double quotes around the JSON data:
```
curl -H "Content-Type: application/json" -d "{\"name\":\"item-1\"}" <your-api-endpoint>/<your-api-stage>/items
```
Alternatively, you can test your API using the API Gateway console. To do this, follow these steps:

1. Sign in to the API Gateway console.
2. Choose your REST API.
3. In the Resources pane, choose the method you want to test.
4. Select the `GET` method and add any query string parameters you want to test.
5. Choose **Test** to run the test.

The API Gateway console will display the request, status, latency, response body, response headers, and logs for the test.

To update data using Amplify, you can use HTTP methods such as PUT. Here's how you can create or update an item via an API endpoint in a React application:

To update an item, you would use the `put` method from `aws-amplify/api`. 

Here's an example of how to do it:
```javascript
import { API } from 'aws-amplify';

async function updateItems() {
  try {
    const item = { name: 'My first Item', message: 'Hello world!' };
    const restOperation = API.put('items/1', {
      body: item
    }, {
      apiName: 'myRestApi'
    });
    const response = await restOperation;
    console.log('PUT call succeeded: ', response);
  } catch (error) {
    console.log('PUT call failed: ', error);
  }
}
```

To use Amplify Auth and Data APIs from Next.js server-side runtimes, you need to install the Amplify Next.js adapter in addition to the Amplify libraries. You can do this by running the command `npm add aws-amplify @aws-amplify/adapter-nextjs` in your terminal.

Next, you need to configure Amplify APIs for server-side usage by creating a `runWithAmplifyServerContextRunner` function. This function is used to call Amplify APIs on the server-side of your Next.js app. You can create this function in a file called `amplifyServerUtils.ts` under a `utils` folder in your codebase.

In this file, you import the Amplify backend outputs from the `amplify_outputs.json` file generated by the Amplify CLI, and use the `createServerRunner` function to create the `runWithAmplifyServerContextRunner` function. For example:

```typescript
import { createServerRunner } from '@aws-amplify/adapter-nextjs';
import outputs from '@/amplify_outputs.json';

export const { runWithAmplifyServerContext } = createServerRunner({
  config: outputs
});
```

You can then use the exported `runWithAmplifyServerContext` function to call Amplify APIs within isolated request contexts.

To configure Amplify library for client-side usage, you need to call the `Amplify.configure` function as you would to use Amplify in a single-page application. You also need to set `ssr` to `true` when calling `Amplify.configure` to instruct the Amplify library to store tokens in the cookie store of a browser.

```typescript
import outputs from '@/amplify_outputs.json';
import { Amplify } from 'aws-amplify';

Amplify.configure(outputs, {
  ssr: true
});
```

Authentication with Next.js server-side runtime can be done using the Amplify Auth category APIs to sign up and sign in end users on the client side. You can also use the `fetchAuthSession` API to check the auth sessions attached to incoming requests in the middleware of your Next.js app.

To call Amplify category APIs on the server side, you need to import the API from the `/server` sub path and use the `runWithAmplifyServerContext` helper function. For example, you can use the `getCurrentUser` API to get the current user:

```typescript
import { getCurrentUser } from 'aws-amplify/auth/server';
import { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';

const user = await runWithAmplifyServerContext({
  nextServerContext: { request, response },
  operation: (contextSpec) => getCurrentUser(contextSpec)
});
```

You can also use Amplify APIs in route handlers, `getServerSideProps`, and `getStaticProps`. For example:

```typescript
export const getServerSideProps: GetServerSideProps = async ({ req, res }) => {
  const user = await runWithAmplifyServerContext({
    nextServerContext: { request: req, response: res },
    operation: (contextSpec) => getCurrentUser(contextSpec)
  });

  return { props: { user } };
};
```

Note that not all Amplify APIs are supported for server-side usage. You can check the supported APIs in the documentation. If you have a server-side use case that isn't currently supported in Amplify JS, you can consider using the AWS SDK for JavaScript. 

For React server components, you can use dynamic rendering to render pages based on user sessions. You can also use static rendering to render pages that don't require user sessions. 

In summary, to use Amplify Auth and Data APIs from Next.js server-side runtimes, you need to install the Amplify Next.js adapter, configure Amplify APIs for server-side usage, and use the `runWithAmplifyServerContext` function to call Amplify APIs within isolated request contexts. You can also use Amplify APIs in route handlers, `getServerSideProps`, and `getStaticProps`.

This quickstart guide will walk you through building a task list application with TypeScript, Next.js App Router with Server Components, and React. If you're new to these technologies, it's recommended that you go through the official React, Next.js, and TypeScript tutorials first.

To get started, you'll need to create a new project and set up the necessary prerequisites. 

Next, you'll create a new Next.js project with the App Router and set up Amplify. 

You'll then build a backend for your application using Amplify.

## Building the UI

To connect to the backend data and auth resources, you'll need to add UI to your application. 

### Configure Amplify Client Side

First, install the Amplify UI component library by running `npm add @aws-amplify/ui-react` in your terminal.

Next, create a new file called `ConfigureAmplify.tsx` in the `components` folder and add the following code:
```typescript
// components/ConfigureAmplify.tsx
"use client";

import { Amplify } from "aws-amplify";
import outputs from "@/amplify_outputs.json";

Amplify.configure(outputs, { ssr: true });

export default function ConfigureAmplifyClientSide() {
  return null;
}
```

Then, update `app/layout.tsx` to import and render the `ConfigureAmplifyClientSide` component:
```typescript
// app/layout.tsx
import "@aws-amplify/ui-react/styles.css";
import type { Metadata } from "next";
import { Inter } from "next/font/google";
import "./globals.css";

import ConfigureAmplifyClientSide from "@/components/ConfigureAmplify";

const inter = Inter({ subsets: ["latin"] });

export const metadata: Metadata = {
  title: "Create Next App",
  description: "Generated by create next app",
};

export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html lang="en">
      <body className={inter.className}>
        <ConfigureAmplifyClientSide />
        {children}
      </body>
    </html>
  );
}
```

### Configure Amplify Server Side

First, install the Amplify Next.js adapter by running `npm add @aws-amplify/adapter-nextjs` in your terminal.

Next, create a new file called `amplify-utils.ts` in the `utils` folder and add the following code:
```typescript
// utils/amplify-utils.ts
import { cookies } from "next/headers";
import { createServerRunner } from "@aws-amplify/adapter-nextjs";
import { generateServerClientUsingCookies } from "@aws-amplify/adapter-nextjs/api";
import { getCurrentUser } from "aws-amplify/auth/server";
import { type Schema } from "@/amplify/data/resource";
import outputs from "@/amplify_outputs.json";

export const { runWithAmplifyServerContext } = createServerRunner({
  config: outputs,
});

export const cookiesClient = generateServerClientUsingCookies<Schema>({
  config: outputs,
  cookies,
});

export async function AuthGetCurrentUserServer() {
  try {
    const currentUser = await runWithAmplifyServerContext({
      nextServerContext: { cookies },
      operation: (contextSpec) => getCurrentUser(contextSpec),
    });
    return currentUser;
  } catch (error) {
    console.error(error);
  }
}
```

### Add Server Authentication Routes

First, create a new file called `Login.tsx` in the `components` folder and add the following code:
```typescript
// components/Login.tsx
"use client";

import { withAuthenticator } from "@aws-amplify/ui-react";
import { redirect } from "next/navigation";
import { useEffect } from "react";

function Login() {
  useEffect(() => {
    redirect("/");
  }, []);

  return null;
}

export default withAuthenticator(Login);
```

Next, create a new file called `page.tsx` in the `app/login` folder and add the following code:
```typescript
// app/login/page.tsx
import Login from "@/components/Login";

export default function LoginPage() {
  return <Login />;
}
```

You can also customize the `Authenticator` component by creating a custom header. Here's an example:
```typescript
// app/login/page.tsx
"use client";

import {
  Authenticator,
  Text,
  View,
  useAuthenticator,
} from "@aws-amplify/ui-react";
import { redirect } from "next/navigation";
import { useEffect } from "react";

const components = {
  Header() {
    return (
      <View textAlign="center">
        <Text><span style={{color: "white"}}>Authenticator Header</span></Text>
      </View>
    );
  },
};

function CustomAuthenticator() {
  const { user } = useAuthenticator((context) => [context.user]);

  useEffect(() => {
    if (user) {
      redirect("/");
    }
  }, [user]);

  return <Authenticator components={components} />;
}

export default function Login() {
  return (
    <Authenticator.Provider>
      <CustomAuthenticator />
    </Authenticator.Provider>
  );
}
```

### Add Logout Component

Create a new file called `Logout.tsx` in the `components` folder and add the following code:
```typescript
// components/Logout.tsx
"use client";

import { signOut } from "aws-amplify/auth";
import { useRouter } from "next/navigation";

export default function Logout() {
  const router = useRouter();

  return (
    <button
      onClick={async () => {
        await signOut();
        router.push("/login");
      }}
      className="px-2 bg-white text-black"
    >
      Sign out
    </button>
  );
}
```

### Add Middleware for Server-Side Redirect

Create a new file called `middleware.ts` in the root of the project and add the following code:
```typescript
// middleware.ts
import { NextRequest, NextResponse } from "next/server";
import { fetchAuthSession } from "aws-amplify/auth/server";
import { runWithAmplifyServerContext } from "@/utils/amplify-utils";

export async function middleware(request: NextRequest) {
  const response = NextResponse.next();

  const authenticated = await runWithAmplifyServerContext({
    nextServerContext: { request, response },
    operation: async (contextSpec) => {
      try {
        const session = await fetchAuthSession(contextSpec, {});
        return session.tokens!== undefined;
      } catch (error) {
        console.log(error);
        return false;
      }
    },
  });

  if (authenticated) {
    return response;
  }

  return NextResponse.redirect(new URL("/login", request.url));
}

export const config = {
  matcher: [
    "/((?!api|_next/static|_next/image|favicon.ico|login).*)",
  ],
};
```

### View List of To-Do Items

To display the list of to-do items, update the `app/page.tsx` file with the following code:
```typescript
// app/page.tsx
import { cookiesClient } from "@/utils/amplify-utils";

async function App() {
  const { data: todos } = await cookiesClient.models.Todo.list();

  return (
    <>
      <h1>Hello, Amplify 👋</h1>
      <ul>
        {todos && todos.map((todo) => <li key={todo.id}>{todo.content}</li>)}
      </ul>
    </>
  );
}

export default App;
```

### Create a New To-Do Item

To create a new to-do item, update the `app/page.tsx` file with the following code:
```typescript
// app/page.tsx
import { revalidatePath } from "next/cache";
import { AuthGetCurrentUserServer, cookiesClient } from "@/utils/amplify-utils";
import Logout from "@/components/Logout";

async function App() {
  const user = await AuthGetCurrentUserServer();
  const { data: todos } = await cookiesClient.models.Todo.list();

  async function addTodo(data: FormData) {
    "use server";
    const title = data.get("title") as string;
    await cookiesClient.models.Todo.create({
      content: title,
      done: false,
      priority: "medium",
    });
    revalidatePath("/");
  }

  return (
    <>
      <h1>Hello, Amplify 👋</h1>
      {user && <Logout />}
      <form action={addTodo}>
        <input type="text" name="title" />
        <button type="submit">Add Todo</button>
      </form>

      <ul>
        {todos && todos.map((todo) => <li key={todo.id}>{todo.content}</li>)}
      </ul>
    </>
  );
}

export default App;
```

Run your application with `npm run dev` and navigate to `http://localhost:3000`. You should now see the authenticator, which is already configured and ready for your first sign-up. Create a new user account, confirm the account through email, and then sign in. Once you've signed in, you can view the list of to-do items and create new ones.

To use Amplify categories APIs from a React application, you need to set up the Amplify APIs plugin. Here's a step-by-step guide to get started:

First, ensure you have installed the relevant Amplify libraries. You can do this by following the manual installation guide.

Next, set up the Amplify APIs plugin. Since React doesn't have a built-in concept of plugins like Nuxt, you'll need to create a custom hook to make the Amplify APIs accessible throughout your application.

Here's an example implementation of the `useAmplify` hook:

```javascript
import { Amplify } from 'aws-amplify';
import {
  fetchAuthSession,
  fetchUserAttributes,
  signIn,
  signOut
} from 'aws-amplify/auth';
import { list } from 'aws-amplify/storage';
import { generateClient } from 'aws-amplify/api';

const config = {
  // your Amplify configuration
};

Amplify.configure(config);

const amplify = {
  Auth: {
    fetchAuthSession,
    fetchUserAttributes,
    signIn,
    signOut
  },
  Storage: {
    list
  },
  GraphQL: {
    client: generateClient()
  }
};

export const useAmplify = () => {
  return amplify;
};
```

You can then use the `useAmplify` hook in your React components to access the Amplify APIs. For example:

```javascript
import React from 'react';
import { useAmplify } from './useAmplify';

const MyComponent = () => {
  const { Auth, Storage, GraphQL } = useAmplify();

  const handleSignIn = async () => {
    try {
      const session = await Auth.signIn();
      console.log(session);
    } catch (error) {
      console.error(error);
    }
  };

  return (
    <div>
      <button onClick={handleSignIn}>Sign In</button>
    </div>
  );
};
```

To protect your routes with authentication, you can create a custom higher-order component (HOC) that checks if the user is authenticated before rendering the protected route.

Here's an example implementation of the `withAuth` HOC:

```javascript
import React from 'react';
import { useAmplify } from './useAmplify';

const withAuth = (WrappedComponent) => {
  const AuthenticatedComponent = () => {
    const { Auth } = useAmplify();

    const [authenticated, setAuthenticated] = React.useState(false);

    React.useEffect(() => {
      const checkAuth = async () => {
        try {
          const session = await Auth.fetchAuthSession();
          setAuthenticated(true);
        } catch (error) {
          setAuthenticated(false);
        }
      };
      checkAuth();
    }, [Auth]);

    if (!authenticated) {
      return <div>You are not authenticated</div>;
    }

    return <WrappedComponent />;
  };

  return AuthenticatedComponent;
};

export default withAuth;
```

You can then use the `withAuth` HOC to protect your routes:

```javascript
import React from 'react';
import withAuth from './withAuth';

const ProtectedRoute = () => {
  return <div>This is a protected route</div>;
};

const AuthenticatedRoute = withAuth(ProtectedRoute);

const App = () => {
  return (
    <div>
      <AuthenticatedRoute />
    </div>
  );
};
```

To set up server-side rendering (SSR) with Amplify, you'll need to create a custom server-side rendering function that uses the `runWithAmplifyServerContext` function from `aws-amplify/adapter-core`.

Here's an example implementation of the `ssr` function:

```javascript
import { runWithAmplifyServerContext } from 'aws-amplify/adapter-core';
import { parseAmplifyConfig } from 'aws-amplify/utils';

const config = {
  // your Amplify configuration
};

const amplifyConfig = parseAmplifyConfig(config);

const ssr = async (event) => {
  const libraryOptions = {
    Auth: {
      // your Auth configuration
    }
  };

  const result = await runWithAmplifyServerContext(
    amplifyConfig,
    libraryOptions,
    async (contextSpec) => {
      // your server-side rendering logic
    }
  );

  return result;
};

export default ssr;
```

You can then use the `ssr` function to render your React components on the server:

```javascript
import React from 'react';
import ReactDOMServer from 'react-dom/server';
import ssr from './ssr';

const App = () => {
  return <div>Hello World!</div>;
};

const html = ReactDOMServer.renderToString(<App />);

const result = await ssr({
  // your event object
});

console.log(result);
```

Note that this is just a basic example, and you'll need to modify it to fit your specific use case. Additionally, you may need to handle errors and edge cases that are not covered in this example.

To configure AWS for local development with Amplify, you need to set up temporary credentials with IAM Identity Center and AWS Organizations. This will enable you to define single-sign-on (SSO), users, groups, permission sets, and more for your team.

If you already have an AWS account and profile configured locally, you don't need to follow this guide. Just add the AmplifyBackendDeployFullAccess IAM role to your configured AWS profile.

To set up Identity Center, follow these steps:

1. Create a user with Amplify permissions: Sign in to the AWS Console, enable IAM Identity Center, and create a user with the necessary permissions.
2. Create a password for the user: Reset the password for the user and choose a password.
3. Install the AWS CLI: Download and install the AWS CLI on your local machine.
4. Set up a local AWS profile: Configure an AWS profile that uses the SSO user.
5. Bootstrap your AWS account: Use the AWS profile with AWS Amplify and complete the bootstrapping process.

The bootstrapping process provisions resources for the AWS CDK, including an Amazon S3 bucket and IAM roles. This is a one-time setup that allows you to deploy AWS CDK apps into an AWS environment.

To complete the bootstrapping process, sign in to the AWS Management Console as the account root user or a user with AdministratorAccess permissions. Then, return to the terminal and create a new Amplify sandbox environment using the configured AWS profile.

Here's an example of how to create a user with Amplify permissions using the AWS CLI:
```bash
aws sso-admin create-user --identity-store-id <identity-store-id> --user-name amplify-admin --display-name 'Amplify Admin' --name Formatted=string,FamilyName=Admin,GivenName=Amplify --emails '{"Type":"Work","Value":"<email-address>"}'
```
And here's an example of how to configure an AWS profile that uses the SSO user:
```console
aws configure sso
SSO session name (Recommended): amplify-admin
SSO start URL: <START SESSION URL>
SSO region: <your-region>
SSO registration scopes [sso:account:access]: 
```
Note that you need to replace `<identity-store-id>`, `<email-address>`, `<START SESSION URL>`, and `<your-region>` with the actual values for your AWS account.

To connect your application to AWS resources such as AWS AppSync, Amazon Cognito, Amazon S3, and more, you can use Amplify client libraries. These libraries provide a flexible way to directly connect your application to AWS resources.

To get started, you need to configure the client libraries. This can be done by using the amplify_outputs.json file generated by the Amplify backend tooling. However, using the client libraries does not require backend resources to be created by Amplify.

For JavaScript-based applications, such as React, you can configure the client library by using the generated outputs file or by configuring the library directly by passing a configuration object. For example, to configure the client library for use with Amazon Cognito, you can specify the Auth configuration:

```javascript
import { Amplify } from "aws-amplify"

Amplify.configure({
  Auth: {
    Cognito: {
      userPoolId: "<your-cognito-user-pool-id>",
      userPoolClientId: "<your-cognito-user-pool-client-id>",
      identityPoolId: "<your-cognito-identity-pool-id>",
      loginWith: {
        email: true,
      },
      signUpVerificationMethod: "code",
      userAttributes: {
        email: {
          required: true,
        },
      },
      allowGuestAccess: true,
      passwordFormat: {
        minLength: 8,
        requireLowercase: true,
        requireUppercase: true,
        requireNumbers: true,
        requireSpecialCharacters: true,
      },
    },
  },
})
```

By configuring the client library, Amplify automates the communication with the underlying AWS resources, and provides a friendly API to author your business logic. For example, you can use the signIn function to initiate the sign-in flow without passing information from your Cognito resource:

```javascript
import { signIn } from "aws-amplify/auth"

await signIn({
  username: "john.doe@example.com",
  password: "hunter2",
})
```

For more information about how to use the Amplify client libraries with existing AWS resources, you can visit the guides, such as the one on connecting to Cognito resources using Amplify Auth's client library.

To get started with AWS Amplify, it is recommended to use the quickstart starter template. However, for some use cases, it may be preferable to start from scratch. 

You can create a new project with `npm create amplify@latest` and follow the prompts to set up the project. This will create a lightweight Amplify project in your current directory.

If you prefer a manual setup, you can create your project's `package.json` with `npm init -y` and then install the Amplify dependencies with `npm add --save-dev @aws-amplify/backend@latest @aws-amplify/backend-cli@latest typescript`. TypeScript is not required but is recommended for an optimal experience.

Next, create the entry point for your backend, `amplify/backend.ts`, with the following code:
```
import { defineBackend } from '@aws-amplify/backend';

defineBackend({});
```
You can then run `npx ampx sandbox` to create your first backend. 

It's worth noting that Amplify Gen 2 requires your backend to be configured for use with ECMAScript modules (ESM). If you encounter an error during `ampx sandbox`, you can modify your `package.json` with `"type": "module"` or create a local file in the Amplify backend directory, `amplify/package.json`, with the following content:
```
{
  "type": "module"
}
```
To define your resources, you can use the `define*` functions. For example, to define authentication, you can use the following code:
```javascript
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true
  }
});
```
To define your data resource, you can use the following code:
```javascript
import { a, defineData, type ClientSchema } from '@aws-amplify/backend';

const schema = a.schema({
  Todo: a.model({
      content: a.string(),
      isDone: a.boolean()
    })
   .authorization(allow => [allow.publicApiKey()])
});

export type Schema = ClientSchema<typeof schema>;
export const data = defineData({
  schema
});
```
Each of these newly defined resources are then imported and set in the backend definition:
```javascript
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';

defineBackend({
  auth,
  data
});
```
If you have an existing project, you can update it by running `npm update @aws-amplify/backend @aws-amplify/backend-cli`. 

The recommended next steps are to learn more about defining authentication, defining data, get started with cloud sandbox, and deploy and host your first app.

Migrating from Gen 1 to Gen 2

AWS is actively developing migration tooling to aid in transitioning projects from Gen 1 to Gen 2. Until then, it is recommended to continue working with Gen 1 Amplify projects. Both Gen 1 and Gen 2 will be supported for the foreseeable future. For new projects, adopting Gen 2 is recommended to take advantage of its enhanced capabilities. 

Gen 1 vs Gen 2 Feature Matrix

The following tables present a feature matrix for Gen 1 customers who are considering Gen 2 for their apps. This will help determine the support availability for various features.

### Auth

Features like configuring username, email, and phone number are available in both Gen 1 and Gen 2, with some features requiring CDK in Gen 2. Social media sign-in options like Facebook, Google, and Amazon are available in both versions. Features like user pool groups, email verification, sign-up attributes, and auth trigger support are also available in both Gen 1 and Gen 2. 

However, some features like custom auth challenge flow are only available in Gen 1. First-class OIDC and SAML support are available in Gen 2, but not in Gen 1.

### Data

Features like model, primary key, secondary key, hasOne, hasMany, and belongsTo are available in both Gen 1 and Gen 2. However, manyToMany is only available in Gen 1. Auth configurations at the model and field levels are available in both versions, with some features requiring CDK in Gen 2.

Some features like searchable, predictions, and custom GraphQL transformer plugins are only available in Gen 1. However, MySQL and PostgreSQL support, as well as in-IDE end-to-end type safety, are only available in Gen 2.

### Storage

Features like provisioning S3 buckets, auth and guest access, and configuring CRUD access are available in both Gen 1 and Gen 2. Lambda triggers for S3 buckets and file browsers in the console are also available in both versions. However, visual configuration is only available in Gen 1.

### Functions

Features like function runtime, environment variables, and secrets are available in both Gen 1 and Gen 2. Function templates like AWS AppSync GraphQL API request and CRUD function for DynamoDB are also available in both versions. However, some features like function build options for Node.js and function logs in the console are only available in Gen 1.

Some features like custom function handlers and function resource access permissions are available in both Gen 1 and Gen 2, with some features requiring CDK in Gen 2.

### Other Categories

REST API, analytics, geo, predictions, and interactions features are available in both Gen 1 and Gen 2, with some variations depending on the platform. However, some features are only available in Gen 1 or Gen 2, or require custom CDK configurations. 

For example, in Android and Swift, REST API is not available in Gen 2, while in Flutter, it is available with custom CDK. In Angular, JavaScript, Next.js, React, React Native, and Vue, REST API is available with custom CDK in Gen 2. 

Similarly, analytics and geo features are available with custom CDK in Gen 2 for most platforms, while predictions and interactions are not available in Gen 2 for some platforms. 

In general, Gen 2 offers more features and capabilities than Gen 1, especially when it comes to authentication, data modeling, and storage. However, some features are only available in Gen 1 or require custom CDK configurations in Gen 2.

To set up your platform for Amplify, follow these steps for each operating system:

For iOS, make sure you have a minimum deployment target of 13.0 and Xcode 15.0 or higher. To do this, update the target iOS platform in your `ios/Podfile` to 13.0 or higher. Then, open your project in Xcode, select the Runner target, and update the "Minimum Deployments" section to 13.0 or higher. Also, update the "iOS Deployment Target" to 13.0 or higher.

For Android, Amplify supports API level 24+ (Android 7.0+), and requires Gradle 8+, Kotlin 1.9+, and Java 17+. To set this up, update the Android Gradle plugin and kotlin versions in your `android/settings.gradle` file. Then, update the Gradle `distributionUrl` in your `android/gradle/wrapper/gradle-wrapper.properties` file. Next, update the Java version and minimum Android SDK version in your `android/app/build.gradle` file. Additionally, you need to add the internet permission to your `android/app/src/main/AndroidManifest.xml` file to make network requests in release mode.

For web, there are no Amplify specific requirements or setup instructions. You just need to use a browser supported by Flutter.

For macOS, Amplify requires a minimum deployment target of 10.15 and Xcode 15.0 or higher. Update the target macOS platform in your `macos/Podfile` to 10.15 or higher. Then, open your project in Xcode, select the Runner target, and update the "Minimum Deployments" section to 10.15 or higher. Also, update the "macOS Deployment Target" to 10.15 or higher. You also need to enable networking and keychain entitlements in the "Signing and Capabilities" tab.

For Windows, there are no Amplify specific requirements or setup instructions. You just need to use a Windows version supported by Flutter.

For Linux, Amplify depends on the `libsecret` library. To run and debug an app, you need to install `libsecret-1-dev`. You can do this by running the command `sudo apt-get install -y libsecret-1-dev`. When packaging your app with Snapcraft, include the required dependencies in your `snapcraft.yaml` file.

Here is an example of how you might implement the networking permission in Android:
```java
<uses-permission android:name="android.permission.INTERNET"/>
```
And here is an example of how you might implement the minimum deployment target in iOS using React Native:
```jsx
import { Platform } from 'react-native';

if (Platform.OS === 'ios') {
  // update the minimum deployment target to 13.0 or higher
}
```
Note that the above code is just an example and may need to be adapted to your specific use case.

Welcome to AWS Amplify. This quickstart guide will walk you through how to build a Todo application using various frameworks, including Vanilla JavaScript, React, Next.js, Angular, Vue, Flutter, React Native, and Swift. 

To get started, you will need to deploy an Amplify backend database and authentication, then connect to the backend from your application, and finally make backend updates.

You can choose your preferred framework to follow the quickstart guide, including:

* Vanilla JavaScript
* React
* Next.js
* Angular
* Vue
* Flutter
* React Native
* Swift
* Android

Each framework has its own set of instructions, but the overall process involves the following steps:

1. Deploy an Amplify backend to AWS.
2. Add authentication to the application.
3. Add data to the application.
4. Make backend updates.

To deploy an Amplify backend, you will need to create a repository in your GitHub account using the Amplify Backend template, then deploy the repository to Amplify's CI/CD pipeline.

To add authentication, you will need to install the necessary dependencies and import the Authenticator component. The Authenticator component auto-detects your auth backend settings and renders the correct UI state based on the auth backend's authentication flow.

To add data, you will need to install the necessary dependencies, update the data schema, and implement the UI to create, list, and delete the to-do items.

To make backend updates, you will need to update the data schema, commit the changes to your git repository, and let Amplify's CI/CD system automatically pick up the changes and build and deploy the updates.

Once you have completed these steps, you will have a fully functional Todo application with authentication and data storage. You can then terminate the sandbox environment to clean up the project.

For more information on how to work with Amplify, you can refer to the conceptual guide on [how Amplify works](https://docs.amplify.aws/cli/sdk/quickstart/).

Here is an example of how to create a Todo application using React Native:
```typescript
import React, { useState, useEffect } from 'react';
import { View, Button, Text, StyleSheet } from 'react-native';

import { generateClient } from "aws-amplify/data";
import type { Schema } from "../amplify/data/resource";
import { GraphQLError } from "graphql";
const client = generateClient<Schema>();

const TodoList = () => {
  const dateTimeNow = new Date();
  const [todos, setTodos] = useState<Schema["Todo"]["type"][]>([]);
  const [errors, setErrors] = useState<GraphQLError>();

  useEffect(() => {
    const sub = client.models.Todo.observeQuery().subscribe({
      next: ({ items }) => {
        setTodos([...items]);
      },
    });

    return () => sub.unsubscribe();
  }, []);

  const createTodo = async () => {
    try {
      await client.models.Todo.create({
        content: `${dateTimeNow.getUTCMilliseconds()}`,
      });
    } catch (error: unknown) {
      if (error instanceof GraphQLError) {
        setErrors(error);
      } else {
        throw error;
      }
    }
  };

  if (errors) {
    return <Text>{errors.message}</Text>;
  }

  const renderItem = ({ item }: { item: Schema["Todo"]["type"] }) => (
    <TodoItem {...item} />
  );
  return (
    <View style={{ flex: 1 }}>
      <FlatList
        data={todos}
        renderItem={renderItem}
        keyExtractor={(item) => item.id}
        ItemSeparatorComponent={() => (
          <View style={styles.listItemSeparator} />
        )}
        ListEmptyComponent={() => <Text>The todo list is empty.</Text>}
        style={styles.listContainer}
      ></FlatList>
      <Button onPress={createTodo} title="Create Todo" />
    </View>
  );
};

const TodoItem = (todo: Schema["Todo"]["type"]) => (
  <View style={styles.todoItemContainer} key={todo.id}>
    <Text
      style={{
       ...styles.todoItemText,
        textDecorationLine: todo.isDone? "line-through" : "none",
        textDecorationColor: todo.isDone? "red" : "black",
      }}
    >
      {todo.content}
    </Text>
    <Button
      onPress={async () => {
        await client.models.Todo.delete(todo);
      }}
      title="Delete"
    />
    <Button
      onPress={() => {
        client.models.Todo.update({
          id: todo.id,
          isDone:!todo.isDone,
        });
      }}
      title={todo.isDone? "Undo" : "Done"}
    />
  </View>
);

const styles = StyleSheet.create({
  todoItemContainer: { flexDirection: "row", alignItems: "center", padding: 8 },
  todoItemText: { flex: 1, textAlign: "center" },
  listContainer: { flex: 1, alignSelf: "stretch", padding:8 },
  listItemSeparator: { backgroundColor: "lightgrey", height: 2 },
});
```

To get started with AWS Amplify Gen 2 using the Next.js App Router, you need to have Node.js version 14.x or later, npm version 6.14.4 or later, and git version 2.14.1 or later installed. If you are new to these technologies, it is recommended that you go through the official React, Next.js, and TypeScript tutorials first.

To deploy a full-stack app to AWS, you will create a repository in your GitHub account using the Amplify Next template. This template scaffolds a create-next-app with Amplify backend capabilities. After creating the repository, you will deploy it with Amplify by selecting "Start with an existing app" and then "GitHub". You will then give Amplify access to your GitHub account and pick the repository and main branch to deploy.

While waiting for your app to deploy, you can take a tour of the project structure in the starter repository. The starter application has pre-written code for a to-do list app and gives you a real-time database with a feed of all to-do list items and the ability to add new items.

Once the build completes, you can visit the newly deployed branch by selecting "View deployed URL". You will be able to create new to-do items, and since the build deployed an API, database, and authentication backend, you will be able to view the data entered in your database in the Amplify console.

To make frontend updates, you will set up a local development environment by cloning the repository locally, installing dependencies, and moving the amplify_outputs.json file to the root of your project. You will then implement a delete functionality by adding a new deleteTodo function and passing it into the onClick handler of the li element.

To implement login UI, you will use the Authenticator UI component from the Amplify UI library. You will import the Authenticator component, wrap the children or pages components with it, and add a button to enable users to sign out of the application.

To make backend updates, you will update the backend to implement per-user authorization rules. You will set up local AWS credentials, deploy a cloud sandbox, and implement per-user authorization by applying an owner-based authorization rule to your to-do items.

Finally, you will commit and push the changes to get them to the cloud, and once the build completes in the Amplify Console, the main backend will update to support the changes made within the cloud sandbox.

To build a task list application with TypeScript, Next.js, and React using AWS Amplify Gen 2, follow these steps:

First, ensure you have the necessary prerequisites installed, including Node.js, npm, and git. If you're new to these technologies, consider going through the official React, Next.js, and TypeScript tutorials.

To deploy a full-stack app to AWS, start by creating a repository in your GitHub account using the provided Next.js template. This template scaffolds a create-next-app with Amplify backend capabilities. Once the repository is created, deploy it to AWS using the Amplify console.

After deployment, view your deployed app by selecting the "View deployed URL" option. You can then interact with your app, creating new to-do items and viewing them in real-time.

To make frontend updates, set up your local development environment by cloning the repository and installing the necessary dependencies. Download the amplify_outputs.json file from the Amplify console and move it to the root of your project. This file contains backend endpoint information and is used by the Amplify client library to connect to your Amplify backend.

Implement the delete functionality by adding a new function to your pages/index.tsx file and passing it to the onClick handler of the li element. Try out the deletion functionality by starting the local dev server.

Next, implement the login UI by importing the Authenticator UI component and wrapping your app component with it. Add a button to enable users to sign out of the application using the useAuthenticator hook.

To make backend updates, set up local AWS credentials and deploy a cloud sandbox using the ampx sandbox command. This provides a separate backend environment for local development and testing. Implement per-user authorization by applying an owner-based authorization rule to your to-do items and rendering the username to distinguish different users.

Finally, commit and push your changes to get them to the cloud. Once your build completes in the Amplify Console, the main backend will update to support the changes made within the cloud sandbox.

Here is some example code to illustrate these steps:

To implement the delete functionality, add the following code to your pages/index.tsx file:
```tsx
function deleteTodo(id: string) {
  client.models.Todo.delete({ id })
}

return (
  <main>
    <h1>My todos</h1>
    <button onClick={createTodo}>+ new</button>
    <ul>
      {todos.map(todo => <li
        onClick={() => deleteTodo(todo.id)}
        key={todo.id}>
        {todo.content}
      </li>)}
    </ul> 
  </main>
)
```

To implement the login UI, add the following code to your pages/_app.tsx file:
```tsx
import { Authenticator } from '@aws-amplify/ui-react'
import '@aws-amplify/ui-react/styles.css'

export default function App({ Component, pageProps }: AppProps) {
  return(
    <Authenticator>
      <Component {...pageProps} />;
    </Authenticator>
  ) 
}
```

To implement per-user authorization, update your amplify/data/resource.ts file with the following code:
```ts
const schema = a.schema({
  Todo: a.model({
    content: a.string(),
  }).authorization(allow => [allow.owner()]),
});
```

And update your pages/index.tsx file with the following code:
```tsx
const { user, signOut } = useAuthenticator();

return (
  <main>
    <h1>{user?.signInDetails?.loginId}'s todos</h1>
    {/*... */}
  </main>
)
```

Customize authorization for your storage bucket by defining access to file paths for guests, authenticated users, and user groups. Access can also be defined for functions that require access to the storage bucket.

To customize authorization, you need to have authentication set up. If you haven't already, set it up by following the documentation.

Note that paths in access definitions cannot have a '/' at the beginning of the string. By default, all paths are denied to all types of users unless explicitly granted.

There are several access types, including guest users, authenticated users, user groups, owners, and functions. 

To grant all guest users read access to files under a certain path, use the following access values:
```javascript
export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'media/*': [
      allow.guest.to(['read']) 
    ]
  })
});
```

To grant all authenticated users read access to files under a certain path, use the following access configuration:
```javascript
export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'media/*': [
      allow.authenticated.to(['read']) 
    ]
  })
});
```

When a user is part of a group, they are assigned the group role, which means permissions defined for the authenticated role will not apply for this user. To grant access to users within a group, you must explicitly define access permissions for the group against the desired prefix.

If you have configured user groups when setting up auth, you can scope storage access to specific groups. For example, assume you have a `defineAuth` config with `admin` and `auditor` groups. With the following access definition, you can configure permissions such that auditors have read-only permissions to a certain path while admin has full permissions.
```javascript
export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'media/*': [
      allow.groups(['auditor']).to(['read']),
      allow.groups(['admin']).to(['read', 'write', 'delete'])
    ]
  })
});
```

In some use cases, you may want just the uploader of a file to be able to perform actions on it. You can do this by using the `entity_id` to represent the user which scopes files to individual users.

The `entity_id` is a reserved token that will be replaced with the users' identifier when the file is being uploaded. You can specify the method of identification when defining access to the path like `allow.entity(<identification_method>).to([..])`. 

For example, the following policy would allow authenticated users full access to a certain path that matches their identity id.
```javascript
export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'media/{entity_id}/*': [
      allow.entity('identity').to(['read', 'write', 'delete'])
    ]
  })
});
```

In addition to granting application users access to storage files, you may also want to grant a backend function access to storage files. This could be used to enable a use case like resizing images or automatically deleting old files.

For example, the following configuration is used to define function access.
```javascript
import { defineStorage, defineFunction } from '@aws-amplify/backend';

const demoFunction = defineFunction({});

export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'media/*': [allow.resource(demoFunction).to(['read', 'write', 'delete'])]
  })
});
```

There are some rules for the types of paths that can be specified at the same time in the storage access definition. All paths must end with `/*`. Only one level of nesting is allowed. Wildcards cannot conflict with the `{entity_id}` token. A path cannot be a prefix of another path with an `{entity_id}` token.

When one path is a subpath of another, the permissions on the subpath always override the permissions from the parent path. Permissions are not "inherited" from a parent path.

When you configure access to a particular path, you can scope the access to one or more CRUDL actions. The available actions are `read`, `get`, `list`, `write`, and `delete`. Note that `read` is a combination of `get` and `list` access definitions and hence cannot be defined in the presence of `get` or `list`.

To configure `defineStorage` in Amplify Gen 2 to behave the same way as the storage category in Gen 1, you can use the following definition.
```javascript
export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'public/*': [
      allow.guest.to(['read']),
      allow.authenticated.to(['read', 'write', 'delete']),
    ],
    'protected/{entity_id}/*': [
      allow.authenticated.to(['read']),
      allow.entity('identity').to(['read', 'write', 'delete'])
    ],
    'private/{entity_id}/*': [
      allow.entity('identity').to(['read', 'write', 'delete'])
    ]
  })
});
```

You can copy a file in Amplify Storage using the `copy` method. This method duplicates an existing file to a designated path and returns an object with the path of the copied file upon successful completion.

```javascript
import { copy } from 'aws-amplify/storage';

const copyFile = async () => {
  try {
    const response = await copy({
      source: {
        path: `album/2024/${encodeURIComponent('#1.jpg')}`,
      },
      destination: {
        path: 'shared/2024/#1.jpg',
      },
    });
  } catch (error) {
    console.error('Error', error);
  }
};
```

Note that you can only copy files up to 5GB in a single operation. Also, if there's a special character in the source path, you should URI encode the source path.

You can also specify a bucket or copy across buckets/regions by providing the `bucket` option. This option can be a string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

```javascript
import { copy } from 'aws-amplify/storage';

const copyFile = async () => {
  try {
    const response = await copy({
      source: {
        path: 'album/2024/1.jpg',
        bucket: 'assignedNameInAmplifyBackend',
        expectedBucketOwner: '123456789012'
      },
      destination: {
        path: 'shared/2024/1.jpg',
        bucket: {
          bucketName: 'generated-second-bucket-name',
          region: 'us-east-2'
        },
        expectedBucketOwner: '123456789013'
      }
    });
  } catch (error) {
    console.error('Error', error);
  }
};
```

To copy to or from a bucket other than your default, both source and destination must have `bucket` explicitly defined.

The `copy` method takes several options, including:

* `path`: a string or callback that represents the path in the source and destination bucket to copy the object to or from
* `bucket`: a string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console
* `eTag`: the copy source object entity tag (ETag) value
* `notModifiedSince`: copies the source object if it hasn't been modified since the specified time
* `expectedBucketOwner`: the account ID that owns the source or destination bucket

Cross-identity ID copying is only allowed if the destination path has the right access rules to allow other authenticated users writing to it.

In React, you can use the `copy` method as shown above to copy files in Amplify Storage. Make sure to handle errors and exceptions properly, and use the `bucket` option to specify the target bucket if necessary.

When submitting an app to the App Store, Apple requires developers to disclose the data usage policy of their app. The Amplify Library, used to interact with AWS resources, collects certain data types that need to be disclosed in the app's data usage policy.

The Amplify Library gathers API usage metrics from the AWS services accessed, which involves adding a user agent to the request made to the AWS service. The user-agent header includes information about the Amplify Library version, operating system name, and version. This data is collected to generate metrics related to library usage and is not linked to the user's identity or used for tracking purposes.

The Amplify Library collects various data types, including:

Contact Info:
- Name
- Email Address
- Phone Number

These data types are used for app functionality, such as authentication, and are linked to the user's identity but not used for tracking purposes.

User Content:
- Photos or Videos
- Audio Data

These data types are used for app functionality, such as storage and predictions, and are not linked to the user's identity or used for tracking purposes.

Identifiers:
- User ID
- Device ID

These data types are used for app functionality, such as authentication and analytics, and are linked to the user's identity but not used for tracking purposes.

Other Data:
- OS Version
- OS Name
- Locale Info
- App Version
- Min OS target of the app
- Timezone information
- Network information
- Has SIM card
- Cellular Carrier Name
- Device Model
- Device Name
- Device OS Version
- Device Height and Width
- Device Language
- identifierForVendor

These data types are used for analytics and app functionality and are not linked to the user's identity or used for tracking purposes.

The Amplify Library does not collect data related to:
- Health and Fitness
- Financial Info
- Location
- Sensitive Info
- Contacts
- Browsing History
- Search History
- Diagnostics

Some Amplify categories, such as Analytics, Auth, and DataStore, persist data to the local device. This data is automatically removed when a user uninstalls the app from the device. However, Auth information is stored in the local system keychain, which does not guarantee removal when an app is uninstalled. To clear this data, app developers should decide when to clear the data by signing out, for example, by using `Auth.signOut()` when the app is launched for the first time. 

For example in a React application using Amplify you could clear the Auth data as follows:
```javascript
import Amplify from 'aws-amplify';
import Auth from '@aws-amplify/auth';

// Check if the app is launching for the first time
// and sign out if it is
if (/* check if app is launching for the first time */) {
  Auth.signOut()
   .then(data => console.log(data))
   .catch(err => console.log(err));
}
```

You can easily display images in your app by using the cloud-connected Storage Image React UI component. This component fetches images securely from your storage resource and displays it on the web page.

To get started, you need to install the required packages by running the command `npm add @aws-amplify/ui-react-storage aws-amplify` in your terminal.

Here's an example of how to use the Storage Image component:
```tsx
import { StorageImage } from '@aws-amplify/ui-react-storage';

export const DefaultStorageImageExample = () => {
  return <StorageImage alt="cat" path="your-path/cat.jpg" />;
};
```
You can further customize the UI component by referring to the [Storage Image documentation](https://ui.docs.amplify.aws/react/connected-components/storage/storageimage).

To download files from your storage, you can use the `getUrl` API from the Amplify Library for Storage. This API generates a presigned URL that is valid for 900 seconds or 15 minutes by default. You can use this URL to create a download link for users to click on.

Here's an example of how to use the `getUrl` API:
```javascript
import { getUrl } from 'aws-amplify/storage';

const linkToStorageFile = await getUrl({
  path: "album/2024/1.jpg",
});
console.log('signed URL: ', linkToStorageFile.url);
console.log('URL expires at: ', linkToStorageFile.expiresAt);
```
You can then use the `url` property to create a link to the file:
```tsx
<a href={linkToStorageFile.url.toString()} target="_blank" rel="noreferrer">
  {fileName} 
</a>
```
Note that the `getUrl` API does not check if the file exists by default. As a result, the signed URL may fail if the file to be downloaded does not exist.

You can also customize the behavior of the `getUrl` API by passing in options. For example, you can specify a target bucket using the `bucket` option, or ensure that the object exists before getting the URL using the `validateObjectExistence` option.

Here's an example of how to use the `getUrl` API with options:
```typescript
import { getUrl } from 'aws-amplify/storage';

const linkToStorageFile = await getUrl({
  path: "album/2024/1.jpg",
  options: {
    bucket: 'assignedNameInAmplifyBackend',
    validateObjectExistence: true,
    expiresIn: 300,
    useAccelerateEndpoint: true,
    expectedBucketOwner: '123456789012',
  }
});
```
The available options for the `getUrl` API are:

* `bucket`: A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.
* `validateObjectExistence`: A boolean indicating whether to head object to make sure the object existence before downloading.
* `expiresIn`: A number representing the number of seconds till the URL expires.
* `useAccelerateEndpoint`: A boolean indicating whether to use accelerate endpoint.
* `expectedBucketOwner`: A string representing the account ID that owns the requested bucket.

To download a file locally, you can use the `downloadData` API from the Amplify Library for Storage. This API downloads the file content to memory.

Here's an example of how to use the `downloadData` API:
```javascript
import { downloadData } from 'aws-amplify/storage';

const { body, eTag } = await downloadData({
  path: "album/2024/1.jpg"
}).result;
```
You can then get the text value of the downloaded file using the `text()` method:
```javascript
const text = await body.text();
console.log('Succeed: ', text);
```
You can also download a file from a specified bucket by providing the `bucket` option. You can pass in a string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

Here's an example of how to use the `downloadData` API with a specified bucket:
```typescript
import { downloadData } from 'aws-amplify/storage';

const result = await downloadData({
  path: 'album/2024/1.jpg',
  options: {
    bucket: 'assignedNameInAmplifyBackend'
  }
}).result;
```
Alternatively, you can also pass in an object by specifying the bucket name and region from the console:
```typescript
import { downloadData } from 'aws-amplify/storage';

const result = await downloadData({
  path: 'album/2024/1.jpg',
  options: {
    bucket: {
      bucketName: 'bucket-name-from-console',
      region: 'us-east-2'
    }
  }
}).result;
```
You can monitor the download progress by using the `onProgress` option:
```javascript
import { downloadData } from 'aws-amplify/storage';

const { body, eTag } = await downloadData({
  path: "album/2024/1.jpg",
  options: {
    onProgress: (progress) => {
      console.log(`Download progress: ${(progress.transferredBytes/progress.totalBytes) * 100}%`);
    }
  }
}).result;
```
You can also cancel the download operation using the `cancel` method:
```javascript
import { downloadData, isCancelError } from 'aws-amplify/storage';

const downloadTask = downloadData({ path: 'album/2024/1.jpg' });
downloadTask.cancel();
try {
  await downloadTask.result;
} catch (error) {
  if (isCancelError(error)) {
    console.log('Download operation cancelled');
  }
}
```
The available options for the `downloadData` API are:

* `bucket`: A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.
* `onProgress`: A callback function tracking the upload/download progress.
* `bytesRange`: An object specifying the bytes range to download.
* `useAccelerateEndpoint`: A boolean indicating whether to use accelerate endpoint.
* `expectedBucketOwner`: A string representing the account ID that owns the requested bucket.

You can also frequently asked questions about the Storage API, such as:

* `downloadData` is cached; if you have recently modified a file you may not get the latest version right away. You can pass in `cacheControl: 'no-cache'` to get the latest version.
* `downloadData` only returns the latest cached version of the file; there is not yet an API to view prior versions.
* Image compression or CloudFront CDN caching for your S3 buckets is not yet possible.
* There is no API for Cognito Group-based access to files.
* There is currently no API for getting the `identityId` of other users; you have to retrieve this from elsewhere before calling `Storage.get`.

For Amplify-generated S3 resources, you can access the underlying Amazon S3 resources to customize your backend configuration using the AWS Cloud Developer Kit (AWS CDK). To enable Transfer Acceleration on the bucket, you need to unwrap the L1 CDK construct from the L2 CDK construct. Here is an example of how to do this in React:

```tsx
import * as s3 from 'aws-cdk-lib/aws-s3';
import { defineBackend } from '@aws-amplify/backend';
import { storage } from './storage/resource';

const backend = defineBackend({
  storage
});

const s3Bucket = backend.storage.resources.bucket;
const cfnBucket = s3Bucket.node.defaultChild as s3.CfnBucket;

cfnBucket.accelerateConfiguration = {
  accelerationStatus: "Enabled"
}
```

To upload files using the accelerated S3 endpoint, you can set the `useAccelerateEndpoint` parameter to `true` in the `AWSS3StorageUploadFileOptions`. However, since you are using React, you would use the `Amplify.Storage` API to upload files. Here is an example of how to upload a file using the accelerated S3 endpoint in React:

```tsx
import Amplify from 'aws-amplify';
import { Storage } from '@aws-amplify/storage';

// Initialize Amplify
Amplify.configure({
  // Your Amplify configuration
});

// Upload a file using the accelerated S3 endpoint
const file = new File(['file content'], 'example.txt', {
  type: 'text/plain',
});
const key = 'public/example';
const options = {
  useAccelerateEndpoint: true,
};

Storage.put(key, file, options)
 .then((result) => console.log(result))
 .catch((error) => console.error(error));
```

For manually configured S3 resources, you need to set up a CORS Policy for your S3 bucket to make calls to your S3 bucket from your app. You can do this by following these steps:

1. Go to the Amazon S3 console and click on your project's `userfiles` bucket.
2. Click on the **Permissions** tab for your bucket.
3. Click the edit button in the **Cross-origin resource sharing (CORS)** section.
4. Make the changes and click on Save Changes. You can add required metadata to be exposed in `ExposeHeaders` with `x-amz-meta-XXXX` format.

Here is an example of a CORS configuration:

```json
[
  {
    "AllowedHeaders": ["*"],
    "AllowedMethods": ["GET", "HEAD", "PUT", "POST", "DELETE"],
    "AllowedOrigins": ["*"],
    "ExposeHeaders": [
      "x-amz-server-side-encryption",
      "x-amz-request-id",
      "x-amz-id-2",
      "ETag",
      "x-amz-meta-foo"
    ],
    "MaxAgeSeconds": 3000
  }
]
```

Note that you can restrict access to your bucket by updating `AllowedOrigin` to include individual domains.

To listen to storage events in React, you can configure function triggers to enable event-based workflows when files are uploaded or deleted. This is achieved by modifying the defineStorage configuration in your storage definition.

First, add the following code to your storage definition to configure triggers for upload and delete events:

```javascript
const storage = defineStorage({
  name: 'myProjectFiles',
  triggers: {
    onUpload: defineFunction({
      entry: './on-upload-handler.ts'
    }),
    onDelete: defineFunction({
      entry: './on-delete-handler.ts'
    })
  }
});
```

Then, create function definitions for the upload and delete handlers. These handlers will be invoked when an object is uploaded or deleted from the bucket.

```javascript
// on-upload-handler.ts
import type { S3Handler } from 'aws-lambda';

export const handler: S3Handler = async (event) => {
  const objectKeys = event.Records.map((record) => record.s3.object.key);
  console.log(`Upload handler invoked for objects [${objectKeys.join(', ')}]`);
};
```

```javascript
// on-delete-handler.ts
import type { S3Handler } from 'aws-lambda';

export const handler: S3Handler = async (event) => {
  const objectKeys = event.Records.map((record) => record.s3.object.key);
  console.log(`Delete handler invoked for objects [${objectKeys.join(', ')}]`);
};
```

These handlers will be invoked whenever an object is uploaded or deleted from the bucket.

If you need more advanced triggers, you can use the addEventNotification method in your backend configuration. This allows you to define more complex event notifications, such as triggering a Lambda function when a file with a specific prefix and suffix is uploaded.

```javascript
// backend.ts
import { EventType } from 'aws-cdk-lib/aws-s3';
import { LambdaDestination } from 'aws-cdk-lib/aws-s3-notifications';
import { defineBackend } from '@aws-amplify/backend';
import { storage } from './storage/resource';
import { yourLambda } from './functions/yourLambda/resource';

const backend = defineBackend({
  storage,
  yourLambda,
});

backend.storage.resources.bucket.addEventNotification(
  EventType.OBJECT_CREATED_PUT,
  new LambdaDestination(backend.yourLambda.resources.lambda),
  {
    prefix: 'protected/uploads/',
    suffix: '-uploadManifest.json',
  }
);
```

This modification creates a new AWS CloudFormation handler that specifically handles checking the prefix and suffix, and triggers the Lambda function accordingly.

You can list files without having to download all the files by using the list API from the Amplify Library for Storage. You can also get properties individually for a file using the getProperties API.

## List Files

To list files, you can use the list function from the Amplify Storage library. This function returns a list of files in the specified path. 

```javascript
import { list } from 'aws-amplify/storage';

const result = await list({
  path: 'album/photos/',
});
```

Note the trailing slash `/` in the path. If you had requested `list({ path :  'album/photos' })` it would also match against files like `album/photos123.jpg` alongside `album/photos/123.jpg`.

The format of the response will look similar to the below example:

```js
{
  items: [
    {
      path: "album/photos/123.jpg",
      eTag: "30074401292215403a42b0739f3b5262",
      lastModified: "Thu Oct 08 2020 23:59:31 GMT+0800 (Singapore Standard Time)",
      size: 138256
    },
    //...
  ],
}
```

If the pageSize is set lower than the total file size, a single list call only returns a subset of all the files. To list all the files with multiple calls, users can use the nextToken flag:

```javascript
import { list } from 'aws-amplify/storage';

const PAGE_SIZE = 20;
let nextToken;
const loadNextPage = async () => {
  const response = await list({
    path: 'photos/',
    options: {
      pageSize: PAGE_SIZE,
      nextToken,
    },
  });
  if (response.nextToken) {
    nextToken = response.nextToken;
  } else {
    nextToken = undefined;
  }
  // render list items from response.items
};
```

### List All files

You can also list all files by setting the listAll option to true:

```javascript
import { list } from 'aws-amplify/storage';

const result = await list({
  path: 'album/photos/',
  options: {
    listAll: true,
  }
});
```

Manually created folders will show up as files with a size of 0. Since "folders" are a virtual concept in Amazon S3, any file may declare any depth of folder just by having a `/` in its name.

To access the contents and subpaths of a "folder", you have two options:

1. Request the entire path and parse the contents.
2. Use the subpathStrategy option to retrieve only the files within the specified path (i.e. exclude files under subpaths).

### Get all nested files within a path

This retrieves all files and folders under a given path. You may need to parse the result to get only the files within the specified path.

```javascript
function processStorageList(response) {
  let files = [];
  let folders = new Set();
  response.items.forEach((res) => {
    if (res.size) {
      files.push(res);
      // sometimes files declare a folder with a / within then
      let possibleFolder = res.path.split('/').slice(0, -1).join('/');
      if (possibleFolder) folders.add(possibleFolder);
    } else {
      folders.add(res.path);
    }
  });
  return { files, folders };
}
```

If you need the files and folders in terms of a nested object instead (for example, to build an explorer UI), you could parse it recursively:

```javascript
function processStorageList(response) {
  const filesystem = {};
  // https://stackoverflow.com/questions/44759750/how-can-i-create-a-nested-object-representation-of-a-folder-structure
  const add = (source, target, item) => {
    const elements = source.split('/');
    const element = elements.shift();
    if (!element) return; // blank
    target[element] = target[element] || { __data: item }; // element;
    if (elements.length) {
      target[element] =
        typeof target[element] === 'object'? target[element] : {};
      add(elements.join('/'), target[element], item);
    }
  };
  response.items.forEach((item) => add(item.path, filesystem, item));
  return filesystem;
}
```

This places each item's data inside a special `__data` key.

### Excluding subpaths

In addition to using the list API to get all the contents of a path, you can also use it to get only the files within a path while excluding files under subpaths.

For example, given the following keys in your path you may want to return only the jpg object, and not the "vacation" subpath and its contents:

```
photos/photo1.jpg
photos/vacation/
```

This can be accomplished with the subpathStrategy option:

```javascript
import { list } from "aws-amplify/storage";
const result = await list({ 
  path: "photos/",
  options:{
    subpathStrategy: { strategy:'exclude' }
  }
});
```

The response will include only the objects within the photos/ path and will also communicate any excluded subpaths:

```js
{
    excludedSubpaths: [
      'photos/vacation/'
    ],
    items: [
      {
        path: "photos/photo1.jpg",
        eTag: "30074401292215403a42b0739f3b5262",
        lastModified: "Thu Oct 08 2020 23:59:31 GMT+0800 (Singapore Standard Time)",
        size: 138256
      },
    ]
}
```

The default delimiter character is '/', but this can be changed by supplying a custom delimiter:

```javascript
const result = await list({
  // Path uses '-' character to organize files rather than '/'
  path: 'photos-',
  options: {
    subpathStrategy: {
      strategy: 'exclude',
      delimiter: '-'
    }
  }
});
```

### List files from a specified bucket

You can also perform a list operation to a specific bucket by providing the bucket option. This option can either be a string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

```javascript
import { list } from 'aws-amplify/storage';

const result = await list({
  path: 'photos/',
  options: {
    // Specify a target bucket using name assigned in Amplify Backend
    bucket: 'assignedNameInAmplifyBackend',
    // Alternatively, provide bucket name from console and associated region
    // bucket: {
    //   bucketName: 'generated-secondary-bucket-name',
    //   region: 'us-east-2'
    // }
  }
});
```

### More list options

| Option | Type | Default | Description |
| -- | :--: | :--: | ----------- |
| bucket | string \| <br />\{ bucketName: string;<br/> region: string; \} | Default bucket and region from Amplify configuration | A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.<br/><br/>Read more at [Configure additional storage buckets](/[platform]/build-a-backend/storage/set-up-storage/#configure-additional-storage-buckets) |
| listAll | boolean | false | Set to true to list all files within the specified path |
| pageSize | number | 1000 | Sets the maximum number of files to be return. The range is 0 - 1000 |
| nextToken | string | — | Indicates whether the list is being continued on this bucket with a token |
| subpathStrategy | \{ strategy: 'include' \} \|<br/>\{ 'exclude',<br />delimiter?: string \} | \{ strategy: 'include' \} | An object representing the subpath inclusion strategy and the delimiter used to group results for exclusion. <br/><br/> Read more at [Excluding subpaths](/[platform]/build-a-backend/storage/list-files/#excluding-subpaths) |
| useAccelerateEndpoint | boolean | false | Whether to use accelerate endpoint. <br/><br/> Read more at [Transfer Acceleration](/[platform]/build-a-backend/storage/extend-s3-resources/#example---enable-transfer-acceleration) |
| expectedBucketOwner | string | Optional | The account ID that owns requested bucket. |

## Get File Properties

You can also view the properties of an individual file.

```javascript
import { getProperties } from 'aws-amplify/storage';

try {
  const result = await getProperties({
    path: 'album/2024/1.jpg',
    options: {
      // Specify a target bucket using name assigned in Amplify Backend
      bucket: 'assignedNameInAmplifyBackend'
    }
  });
  console.log('File Properties ', result);
} catch (error) {
  console.log('Error ', error);
}
```

The properties and metadata will look similar to the below example

```js
{
  path: "album/2024/1.jpg",
  contentType: "image/jpeg",
  contentLength: 6873,
  eTag: "\"56b32cf4779ff6ca3ba3f2d455fa56a7\"",
  lastModified: Wed Apr 19 2023 14:20:55 GMT-0700 (Pacific Daylight Time) {},
  metadata: { owner: 'aws' }
}
```

### More getProperties options

Option | Type | Default | Description |
| -- | -- | -- | ----------- |
| bucket | string \| <br />\{ bucketName: string;<br/> region: string; \} | Default bucket and region from Amplify configuration | A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.<br/><br/>Read more at [Configure additional storage buckets](/[platform]/build-a-backend/storage/set-up-storage/#configure-additional-storage-buckets) |
| useAccelerateEndpoint | boolean | false | Whether to use accelerate endpoint. | [Transfer Acceleration](/[platform]/build-a-backend/storage/extend-s3-resources/#example---enable-transfer-acceleration) |

To get the metadata in result for all APIs you have to configure user defined metadata in CORS.

Learn more about how to setup an appropriate [CORS Policy](/[platform]/build-a-backend/storage/extend-s3-resources/#for-manually-configured-s3-resources).

The File storage page in the Amplify console provides a user-friendly interface for managing your application's backend file storage, allowing for efficient testing and management of your files.

If you haven't created a storage resource, you can visit the Storage setup guide to get started.

To access the File storage manager, follow these steps:
1. Log in to the Amplify console and choose your app.
2. Select the branch you want to access.
3. Select Storage from the left navigation bar.

To upload a file, you can either:
- Select the Upload button, choose the file you want to upload, and then select Done
- Drag and drop a file onto the Storage page

To delete a file:
1. Select the file you want to delete on the Storage page.
2. Select the Actions dropdown and then select Delete.

To copy a file:
1. Select the file you want to copy on the Storage page.
2. Select the Actions dropdown and then select Copy to.
3. Choose or create the folder where you want to save a copy of your file.
4. Select Copy to copy your file to the selected folder.

To move a file:
1. Select the file you want to move on the Storage page.
2. Select the Actions dropdown and then select Move to.
3. Choose or create the folder where you want to move your file.
4. Select Move to move your file to the selected folder.

Files can be removed from a storage bucket using the remove API. If a file is protected by an identity Id, only the user who owns the file will be able to remove it.

You can perform a remove operation from a specific bucket by providing the target bucket's assigned name from Amplify Backend in the bucket option. 

```javascript
import { remove } from 'aws-amplify/storage';

try {
  await remove({ 
    path: 'album/2024/1.jpg',
    bucket: 'assignedNameInAmplifyBackend', 
  });
} catch (error) {
  console.log('Error ', error);
}
```

Alternatively, you can also pass in an object by specifying the bucket name and region from the console.

```javascript
import { remove } from 'aws-amplify/storage';

try {
  await remove({ 
    path: 'album/2024/1.jpg',
    bucket: {
      bucketName: 'bucket-name-from-console',
      region: 'us-east-2'
    }
  });
} catch (error) {
  console.log('Error ', error);
}
```

There are additional options that can be used with the remove API. 

Option | Type | Default | Description 
| -- | :--: | :--: | ----------- 
| bucket | string or { bucketName: string; region: string; } | Default bucket and region from Amplify configuration | A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.
| expectedBucketOwner | string | Optional | The account ID that owns requested bucket. 

Note: The account ID of the owner of the bucket is required when removing objects from a bucket that is not owned by the account that is making the request.

In this guide, you will learn how to set up storage in your Amplify app. You will set up your backend resources, and enable listing, uploading, and downloading files.

If you have not yet created an Amplify app, visit the quickstart guide.

Amplify Storage seamlessly integrates file storage and management capabilities into frontend web and mobile apps, built on top of Amazon Simple Storage Service (Amazon S3). It provides intuitive APIs and UI components for core file operations, enabling developers to build scalable and secure file storage solutions without dealing with cloud service complexities.

First, create a file `amplify/storage/resource.ts`. This file will be the location where you configure your storage backend. Instantiate storage using the `defineStorage` function and providing a `name` for your storage bucket. This `name` is a friendly name to identify your bucket in your backend configuration. Amplify will generate a unique identifier for your app using a UUID, the name attribute is just for use in your app.

```javascript
export const storage = defineStorage({
  name: 'amplifyTeamDrive'
});
```

Import your storage definition in your `amplify/backend.ts` file that contains your backend definition. Add storage to `defineBackend`.

```javascript
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { storage } from './storage/resource';

defineBackend({
  auth,
  storage
});
```

Now when you run `npx ampx sandbox` or deploy your app on Amplify, it will configure an Amazon S3 bucket where your files will be stored. Before files can be accessed in your application, you must configure storage access rules.

To deploy these changes, commit them to git and push the changes upstream. Amplify's CI/CD system will automatically pick up the changes and build and deploy the updates.

```bash
git commit -am "add storage backend"
git push
```

By default, no users or other project resources have access to any files in the storage bucket. Access must be explicitly granted within `defineStorage` using the `access` callback.

The access callback returns an object where each key in the object is a file path and each value in the object is an array of access rules that apply to that path.

For example, you can set up your file storage structure for a generic photo sharing app. Here, guests have access to see all profile pictures and only the users that uploaded the profile picture can replace or delete them. Users are identified by their Identity Pool ID in this case i.e. identityID. There's also a general pool where all users can submit pictures.

```javascript
export const storage = defineStorage({
  name: 'amplifyTeamDrive',
  access: (allow) => ({
    'profile-pictures/{entity_id}/*': [
      allow.guest.to(['read']),
      allow.entity('identity').to(['read', 'write', 'delete'])
    ],
    'picture-submissions/*': [
      allow.authenticated.to(['read','write']),
      allow.guest.to(['read', 'write'])
    ],
  })
});
```

Amplify Storage gives you the flexibility to configure your backend to automatically provision and manage multiple storage resources. You can define additional storage buckets by using the same `defineStorage` function and providing a unique, descriptive `name` to identify the storage bucket. You can pass this `name` to the storage APIs to specify the bucket you want to perform the action to. Ensure that this `name` attribute is unique across the defined storage buckets in order to reliably identify the correct bucket and prevent conflicts.

It's essential to note that if additional storage buckets are defined, one of them must be marked as default with the `isDefault` flag.

```javascript
export const firstBucket = defineStorage({
  name: 'firstBucket',
  isDefault: true, 
});

export const secondBucket = defineStorage({
  name: 'secondBucket',
  access: (allow) => ({
    'private/{entity_id}/*': [
      allow.entity('identity').to(['read', 'write', 'delete'])
    ]
  })
})
```

Add additional storage resources to the backend definition.

```javascript
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { firstBucket, secondBucket } from './storage/resource';

defineBackend({
  auth,
  firstBucket,
  secondBucket
});
```

Additional storage buckets can be referenced from application code by passing the `bucket` option to Amplify Storage APIs. You can provide a target bucket's name assigned in Amplify Backend.

```javascript
import { downloadData } from 'aws-amplify/storage';

try {
  const result = downloadData({
    path: "album/2024/1.jpg",
    options: {
      bucket: "secondBucket"
    }
  }).result;
} catch (error) {
  console.log(`Error: ${error}`)
}
```

Alternatively, you can also pass in an object by specifying the bucket name and region from the console.

```javascript
import { downloadData } from 'aws-amplify/storage';

try {
  const result = downloadData({
    path: 'album/2024/1.jpg',
    options: {
      bucket: {
        bucketName: 'second-bucket-name-from-console',
        region: 'us-east-2'
      }
    }
  }).result;
} catch (error) {
  console.log(`Error: ${error}`);
}
```

To connect your app code to the storage backend, import and load the configuration file in your app. Initialize the Amplify Storage category by calling `Amplify.add(plugin:)`. To complete initialization, call `Amplify.configure()`.

```javascript
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
```

To upload your first file, you can use the `uploadData` function from `aws-amplify/storage`.

```jsx
import React from 'react';
import { uploadData } from 'aws-amplify/storage';

function App() {
  const [file, setFile] = React.useState();

  const handleChange = (event) => {
    setFile(event.target.files?.[0]);
  };

  const handleClick = () => {
    if (!file) {
      return;
    }
    uploadData({
      path: `picture-submissions/${file.name}`,
      data: file,
    });
  };

  return (
    <div>
      <input type="file" onChange={handleChange} />
      <button onClick={handleClick}>Upload</button>
    </div>
  );
}
```

After successfully publishing your storage backend and connecting your project with client APIs, you can manage files and folders in the Amplify console. You can perform on-demand actions like upload, download, copy, and more under the Storage tab in the console.

Congratulations! You finished the Set up Amplify Storage guide. In this guide, you set up and connected to backend resources, customized your file paths and access definitions, and connected your application to the backend to implement features like file uploads and downloads.

Now that you have completed setting up storage in your Amplify app, you can proceed to add file management features to your app. You can use the following guides to implement upload and download functionality, or you can access more capabilities from the side navigation.

- Upload Files
- Download Files

You can implement upload functionality in your app by either using the File Uploader UI component or further customizing the upload experience using the upload API.

To use the File Uploader UI component, you need to install the required packages by running the command `npm add @aws-amplify/ui-react-storage aws-amplify` in your terminal. Then, you can use the component in your app like this:

```tsx
import { FileUploader } from '@aws-amplify/ui-react-storage';
import '@aws-amplify/ui-react/styles.css';

export const DefaultFileUploaderExample = () => {
  return (
    <FileUploader
      acceptedFileTypes={['image/*']}
      path="public/"
      maxFileCount={1}
      isResumable
    />
  );
};
```

To implement upload functionality using the upload API, you can use the `uploadData` function from the `aws-amplify/storage` module. Here's an example of how to upload a file from a file object:

```jsx
import React from 'react';
import { uploadData } from 'aws-amplify/storage';

function App() {
  const [file, setFile] = React.useState();

  const handleChange = (event) => {
    setFile(event.target.files?.[0]);
  };

  const handleClick = () => {
    if (!file) {
      return;
    }
    uploadData({
      path: `photos/${file.name}`,
      data: file,
    });
  };

  return (
    <div>
      <input type="file" onChange={handleChange} />
      <button onClick={handleClick}>Upload</button>
    </div>
  );
}
```

You can also upload data from a data object. Here's an example:

```javascript
import { uploadData } from 'aws-amplify/storage';

try {
  const result = await uploadData({
    path: "album/2024/1.jpg",
    data: file,
  }).result;
  console.log('Succeeded: ', result);
} catch (error) {
  console.log('Error : ', error);
}
```

Additionally, you can monitor the progress of an upload by using the `onProgress` option. Here's an example:

```javascript
import { uploadData } from 'aws-amplify/storage';

const monitorUpload = async () => {
  try {
    const result = await uploadData({
      path: "album/2024/1.jpg",
      data: file,
      options: {
        onProgress: ({ transferredBytes, totalBytes }) => {
          if (totalBytes) {
            console.log(
              `Upload progress ${Math.round(
                (transferredBytes / totalBytes) * 100
              )} %`
            );
          }
        },
      },
    }).result;
    console.log("Path from Response: ", result.path);
  } catch (error) {
    console.log("Error : ", error);
  }
}
```

You can also pause, resume, and cancel uploads using the `pause`, `resume`, and `cancel` methods.

```javascript
import { uploadData, isCancelError } from 'aws-amplify/storage';

const uploadTask = uploadData({ path, data: file });
uploadTask.pause();
uploadTask.resume();
uploadTask.cancel();
try {
  await uploadTask.result;
} catch (error) {
  if (isCancelError(error)) {
    console.log("Upload was cancelled");
  }
}
```

You can customize the behavior of `uploadData` and the properties of the uploaded object by passing in additional options. Here are some of the available options:

* `bucket`: a string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.
* `contentType`: the default content-type header value of the file when downloading it.
* `contentEncoding`: the default content-encoding header value of the file when downloading it.
* `contentDisposition`: specifies presentational information for the object.
* `metadata`: a map of metadata to store with the object in S3.
* `useAccelerateEndpoint`: whether to use accelerate endpoint.
* `expectedBucketOwner`: the account ID that owns the requested bucket.
* `preventOverwrite`: whether to check if an object with the same key already exists before completing the upload.
* `checksumAlgorithm`: whether to compute the checksum for the data to be uploaded, so the S3 can verify the data integrity.

Note that uploads that were initiated over one hour ago will be cancelled automatically. It is recommended to setup a S3 lifecycle rule to automatically cleanup incomplete upload requests.

To access the S3Client instance for advanced use cases where Amplify does not provide the functionality, you can retrieve the escape hatch. 

For Android, you would use the following Java or Kotlin code to get the escape hatch. 

In Java:
```java
AWSS3StoragePlugin plugin = (AWSS3StoragePlugin) Amplify.Storage.getPlugin("awsS3StoragePlugin");
S3Client client = plugin.getEscapeHatch();
```
In Kotlin:
```kotlin
val plugin = Amplify.Storage.getPlugin("awsS3StoragePlugin") as AWSS3StoragePlugin
val client = plugin.escapeHatch
```
In React, you would use the following code to get the escape hatch:
```javascript
const plugin = Amplify.Storage.getPlugin('awsS3StoragePlugin');
const client = plugin.getEscapeHatch();
```
For iOS, you would use the following Swift code to get the escape hatch:
```swift
do {
    let plugin = try Amplify.Storage.getPlugin(for: "awsS3StoragePlugin")
    guard let storagePlugin = plugin as? AWSS3StoragePlugin else {
        return
    }
    let s3Client = storagePlugin.getEscapeHatch()
    // Make requests using s3Client...
} catch {
    print("Get escape hatch failed with error - \(error)")
}
```
In React, the equivalent code would be:
```javascript
try {
  const plugin = await Amplify.Storage.getPlugin('awsS3StoragePlugin');
  const s3Client = plugin.getEscapeHatch();
  // Make requests using s3Client...
} catch (error) {
  console.log('Get escape hatch failed with error - ', error);
}
```
For additional client documentation and S3Client code examples, see the AWS SDK documentation.

You can use Amplify Storage APIs with your own S3 buckets instead of the ones created by Amplify. 

To do this, you must have Amplify Auth configured in your project. 

First, you need to add necessary permissions to the S3 bucket by going to the Amazon S3 console, selecting the S3 bucket, and editing the bucket policy. 

The policy should look something like this:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "Statement1",
      "Principal": { "AWS": "arn:aws:iam::<AWS-account-ID>:role/<role-name>" },
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:DeleteObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::<bucket-name>/*"
      ]
    }
  ]
}
```
Replace `<AWS-account-ID>` with your AWS account ID, `<role-name>` with the IAM role associated with your Amplify Auth setup, and `<bucket-name>` with the S3 bucket name.

Next, you need to specify the S3 bucket in Amplify's backend config by using the `addOutput` method from the backend definition object in your `amplify/backend.ts` file:
```javascript
const backend = defineBackend({
  auth,
  data,
});

backend.addOutput({
  storage: {
    aws_region: "<region>",
    bucket_name: "<bucket-name>"
  },
});
```
Replace `<region>` with the region of the bucket and `<bucket-name>` with the S3 bucket name.

After configuring the necessary permissions, you can start using the storage APIs with your chosen S3 bucket.

If you're not using an Amplify backend, you can still use existing storage resources with Amplify Storage by configuring your storage options manually and ensuring Amplify Auth is properly configured in your project.

You can configure the Amplify Storage client library to interact with the additional resources by passing the resource metadata to `Amplify.configure`:
```typescript
import { Amplify } from 'aws-amplify';

Amplify.configure({
  Auth: {
    // add your auth configuration
  },
  Storage: {
    S3: {
      bucket: '<your-default-bucket-name>',
      region: '<your-default-bucket-region>',
      buckets: {
        '<your-default-bucket-friendly-name>': {
          bucketName: '<your-default-bucket-name>',
          region: '<your-default-bucket-region>'
        },
        '<your-additional-bucket-friendly-name>': {
          bucketName: '<your-additional-bucket-name>',
          region: '<your-additional-bucket-region>'
        }
      }
    }
  }
});
```
Alternatively, you can create or modify the `amplify_outputs.json` file directly:
```json
{
  "auth": {
    // add your auth configuration
  },
  "storage": {
    "aws_region": "<your-default-bucket-region>", 
    "bucket_name": "<your-default-bucket-name>",
    "buckets": [
      {
        "name": "<your-default-bucket-friendly-name>", 
        "bucket_name": "<your-default-bucket-name>", 
        "aws_region": "<your-default-bucket-region>" 
      },
      {
        "name": "<your-additional-bucket-friendly-name>",
        "bucket_name": "<your-additional-bucket-name>",
        "aws_region": "<your-additional-bucket-region>"
      }
    ]
  }
}
```