Tools allow LLMs to query information to respond with current and relevant information. They are invoked only if the LLM requests to use one based on the user's message and the tool's description.

There are a few different ways to define LLM tools in the Amplify AI kit: 
1. Model tools 
2. Query tools 
3. Lambda tools

The easiest way to define tools for your conversation route is with `a.ai.dataTool()` for data models and custom queries in your data schema. When you define a tool for a conversation route, Amplify takes care of the heavy lifting, describing the tools to the LLM, invoking the tool with the right parameters, and maintaining the caller identity and authorization.

Model tools give the LLM access to your data models by referencing them in an `a.ai.dataTool()` with a reference to a model in your data schema. This requires that the model uses at least one of the following authorization strategies: 
- Per user data access, using `owner()`, `ownerDefinedIn()`, or `ownersDefinedIn()`
- Any signed-in user data access, using `authenticated()`
- Per user group data access, using `group()`, `groupsDefinedIn()`, `groups()`, or `groupsDefinedIn()`

For example, you can define a model tool like this:
```typescript
const schema = a.schema({
  Post: a.model({
    title: a.string(),
    body: a.string(),
  })
  .authorization(allow => allow.owner()),

  chat: a.conversation({
    aiModel: a.ai.model('Claude 3.5 Haiku'),
    systemPrompt: 'Hello, world!',
    tools: [
      a.ai.dataTool({
        name: 'PostQuery',
        description: 'Searches for Post records',
        model: a.ref('Post'),
        modelOperation: 'list',
      }),
    ],
  }),
})
```

Query tools give the LLM access to custom queries defined in your data schema. To do so, define a custom query with a function or custom handler and then reference that custom query as a tool. This requires that the custom query uses the `allow.authenticated()` authorization strategy.

For example, you can define a query tool like this:
```typescript
export const getWeather = defineFunction({
  name: 'getWeather',
  entry: './getWeather.ts',
  environment: {
    API_ENDPOINT: 'MY_API_ENDPOINT',
    API_KEY: secret('MY_API_KEY'),
  },
});

const schema = a.schema({
  getWeather: a.query()
    .arguments({ city: a.string() })
    .returns(a.customType({
      value: a.integer(),
      unit: a.string()
    }))
    .handler(a.handler.function(getWeather))
    .authorization((allow) => allow.authenticated()),

  chat: a.conversation({
    aiModel: a.ai.model('Claude 3.5 Haiku'),
    systemPrompt: 'You are a helpful assistant',
    tools: [
      a.ai.dataTool({
        name: 'get_weather',
        description: 'Gets the weather for a given city',
        query: a.ref('getWeather'),
      }),
    ]
  })
    .authorization((allow) => allow.owner()),
})
```

You can also define a Lambda function handler for the custom query. For example:
```typescript
export const handler: Schema["getWeather"]["functionHandler"] = async (
  event
) => {
  const { city } = event.arguments;
  if (!city) {
    throw new Error('City is required');
  }

  const url = `${env.API_ENDPOINT}?city=${encodeURIComponent(city)}`;
  const request = new Request(url, {
    headers: {
      Authorization: `Bearer ${env.API_KEY}`
    }
  });

  const response = await fetch(request);
  const weather = await response.json();
  return weather;
}
```

You can connect to any AWS service by defining a custom query and calling that service in the function handler. To properly authorize the custom query function to call the AWS service, you will need to provide the Lambda with the proper permissions.

Custom Lambda tools can be defined to execute in the conversation handler AWS Lambda function. This is useful if you want to define a tool that is not related to your data schema or that does simple tasks within the Lambda function runtime.

To define a custom Lambda tool, first install the `@aws-amplify/backend-ai` package. Then, define a custom conversation handler function in your data schema and reference the function in the `handler` property of the `a.conversation()` definition.

For example:
```typescript
export const chatHandler = defineConversationHandlerFunction({
  entry: './chatHandler.ts',
  name: 'customChatHandler',
  models: [
    { modelId: a.ai.model("Claude 3.5 Haiku") }
  ]
});

const schema = a.schema({
  chat: a.conversation({
    aiModel: a.ai.model('Claude 3.5 Haiku'),
    systemPrompt: "You are a helpful assistant",
    handler: chatHandler,
  })
    .authorization((allow) => allow.owner()),
})
```

Next, define the executable tool(s) and handler. For example:
```typescript
const jsonSchema = {
  json: {
    type: 'object',
    properties: {
      'operator': {
        'type': 'string',
        'enum': ['+', '-', '*', '/'],
        'description': 'The arithmetic operator to use'
      },
      'operands': {
        'type': 'array',
        'items': {
          'type': 'number'
        },
        'minItems': 2,
        'maxItems': 2,
        'description': 'Two numbers to perform the operation on'
      }
    },
    required: ['operator', 'operands']
  }
} as const;

const calculator = createExecutableTool(
  'calculator',
  'Returns the result of a simple calculation',
  jsonSchema,
  (input) => {
    const [a, b] = input.operands;
    switch (input.operator) {
      case '+': return Promise.resolve({ text: (a + b).toString() });
      case '-': return Promise.resolve({ text: (a - b).toString() });
      case '*': return Promise.resolve({ text: (a * b).toString() });
      case '/':
        if (b === 0) throw new Error('Division by zero');
        return Promise.resolve({ text: (a / b).toString() });
      default:
        throw new Error('Invalid operator');
    }
  },
);

export const handler = async (event: ConversationTurnEvent) => {
  await handleConversationTurnEvent(event, {
    tools: [calculator],
  });
};
```

Finally, update your backend definition to include the newly defined `chatHandler` function.

Best practices for using tools include:
- Validate and sanitize any input from the LLM before using it in your application
- Handle errors gracefully and provide meaningful error messages
- Log and monitor tool usage to detect potential misuse or issues